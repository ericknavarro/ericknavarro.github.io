{"posts":[{"title":"Mi primer proyecto utilizando Jlex y Cup (Linux)","text":"Se desarrollará un intérprete que recibe como entrada varias expresiones aritméticas y presenta como salida el resultado de dichas expresiones. Las tecnologías a utilizar son: Jlex: Generador de analizadores léxicos Cup: Generador de analizadores sintácticos Ubuntu 14.04: Sistema operativo basado en GNU/Linux Netbeans 8.0: IDE (entorno de desarrollo integrado) El proyecto completo del ejemplo puede descargarse del siguiente enlace: Mi primer proyecto utilizando Jlex y Cup (Linux) JLexJLex es un generador de analizadores léxicos, escrito en Java, para Java. JLex fue desarrollado por Elliot Berk en la Universidad de Princeton. Para más información visitar la página oficial de JLex.La principal tarea de un analizador léxico es leer los caracteres de entrada del programa fuente, agruparlos en lexemas y producir como salida una secuencia de tokens. Un token es un par que consiste en un nombre de token y un valor de atributo opcional. Un lexema es una secuencia de caracteres en el programa fuente, que coinciden con el patrón para un token y que el analizador léxico identifica como una instancia de este tóken. Un patrón es una descripción de la forma que pueden tomar los lexemas de un token. En JLex se definen los patrones de los diferentes tokens que se desean reconocer, estos patrones pueden definirse a través de expresiones regulares. Además JLex cuenta con múltiples opciones, una muy imporante es su capacidad para integrarse con generadores de analizadores sintácticos como Cup. CupCup es un generador de analizadores sintácticos de tipo LALR para Java. El analizador sintáctico obtiene una cadena de tokens del analizador léxico y verifica que dicha cadena pueda generase con la gramática para el lenguaje fuente. Una gramática proporciona una especificación precisa y fácil de entender de un lenguaje de programación. Pre-requisitosPara este ejemplo hace falta que tengamos instalado: Java Development Kit (JDK) Netbeans Instalación y configuración de las herramientasLo primero que haremos será instalar JLex, para ello abrimos una terminal, en Ubuntu puede hacerse con la combinación de teclas Ctrl+Alt+t o en Aplicaciones → Accesorios → Terminal, una vez abierta la terminal ingresamos el comando “sudo apt-get install jlex”, autenticamos ingresando nuestra contraseña y aceptamos la descarga e instalación, con esto quedará instalado JLex. Luego instalamos cup, ejecutando en la terminal el comando “sudo apt-get install cup”, autenticamos ingresando nuestra contraseña y aceptamos la descarga e instalación, con esto quedará instalado Cup. Abrimos Netbeans y creamos un nuevo proyecto de Java (File → New Project). Creamos un paquete llamado analizadores, este almacenará todo el código fuente relacionado con el analizador léxico y sintáctico (Clic derecho en Source Packages → New → Java Package). Creamos tres archivos en el paquete analizadores, el primero “Lexico”, que almacenará el código fuente con el cual JLex generará el analizador léxico que queremos, el segundo “Sintactico”, que almacenará el código fuente con el cual Cup generará el analizador sintáctico que queremos y el tercero “compilar.sh”, que guardará los comandos que deben ejecutarse para solicitarle a JLex y a Cup que generen los analizadores. Para crear cada uno de los archivos hacemos clic derecho en el paquete analizadores → New → Other → en la ventana que despliegue, seleccionar Categories: Other y File Types: Empty File, seleccionamos siguiente, indicamos el nombre para el archivo y finalizamos. De tal modo que al final tendremos los tres archivos archivos. Ahora importaremos la llibrería de Cup a nuestro proyecto de netbeans, para ello descargamos el archivo “java-cup-bin-11b-&lt;versión&gt;.tar.gz” de la página oficial de Cup. En este caso el archivo descargado fue el “java-cup-bin-11b-20150326.tar.gz”. Lo descomprimimos y veremos que contiene dos archivos .jar, el que nos interesa es el archivo “java-cup-11b-runtime.jar”. Creamos una carpeta lib dentro de la carpeta de nuestro proyecto. Dentro de la carpeta lib pegamos el archivo “java-cup-11b-runtime.jar”. Para importar el archivo jar, vamos a Netbeans y damos clic derecho en la pestaña Libraries de nuestro proyecto → Add JAR/Folder… luego buscamos el archivo jar en la carpeta lib que acabamos de crear y lo seleccionamos. Código fuente para el analizador léxicoEn el archivo “Lexico” incluiremos todo el código que le indicará a Jlex lo que debe hacer. El código se muestra a continuación: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/* * Ejemplo desarrollado por Erick Navarro * GitHub Page: ericknavarro.github.io * Septiembre - 2015 */package analizadores;import java_cup.runtime.Symbol; %% %class Lexico%public %line %char %cup %unicode%ignorecase%init{ yyline = 1; yychar = 1; %init} BLANCOS=[ \\r\\t]+D=[0-9]+DD=[0-9]+(&quot;.&quot;[ |0-9]+)?%%&quot;Evaluar&quot; {return new Symbol(sym.REVALUAR,yyline,yychar, yytext());} &quot;;&quot; {return new Symbol(sym.PTCOMA,yyline,yychar, yytext());} &quot;(&quot; {return new Symbol(sym.PARIZQ,yyline,yychar, yytext());} &quot;)&quot; {return new Symbol(sym.PARDER,yyline,yychar, yytext());} &quot;[&quot; {return new Symbol(sym.CORIZQ,yyline,yychar, yytext());} &quot;]&quot; {return new Symbol(sym.CORDER,yyline,yychar, yytext());} &quot;+&quot; {return new Symbol(sym.MAS,yyline,yychar, yytext());} &quot;-&quot; {return new Symbol(sym.MENOS,yyline,yychar, yytext());} &quot;*&quot; {return new Symbol(sym.POR,yyline,yychar, yytext());} &quot;/&quot; {return new Symbol(sym.DIVIDIDO,yyline,yychar, yytext());} \\n {yychar=1;}{BLANCOS} {} {D} {return new Symbol(sym.ENTERO,yyline,yychar, yytext());} {DD} {return new Symbol(sym.DECIMAL,yyline,yychar, yytext());} . { System.out.println(&quot;Este es un error lexico: &quot;+yytext()+ &quot;, en la linea: &quot;+yyline+&quot;, en la columna: &quot;+yychar);} Explicación del código fuente para el analizador léxicoEn las primeras líneas indicamos a Jlex que la clase estará en el paquete analizadores y que es necesario que se importe la clase Symbol. 12package analizadores;import java_cup.runtime.Symbol; Posteriormente indicamos a Jlex que: La clase del analizador se llamará “Lexico” La clase será pública Debe llevar el conteo de las líneas Debe llevar el conteo de los caracteres reconocidos Debe integrarse con cup El set de caracteres que debe utilizar es el unicode El analizador no será case sensitive, es decir, no le importa si las letras son mayúsculas o minúsculas 12345678%% %class Lexico%public %line %char %cup %unicode%ignorecase Luego viene el bloque init, dentro del init, se ejecutan las acciones de inicialización, es decir, lo que va dentro del constructor del analizador léxico.En este caso indicamos dentro del init que: La variable yyline, que lleva la cuenta del número de linea por el que va el analizador valdrá inicialmente 1. La variable yychar, que lleva la cuenta del número de carácter por el que va el analizador valdrá inicialmente 1. 1234%init{ yyline = 1; yychar = 1; %init} Luego se escriben algunas expresiones regulares que son almacenadas en macros, que básicamente son variables que almacenan los patrones, en este caso se definen las macros: BLANCOS, D y DD. Los patrones para cada una son los siguientes: BLANCOS: Expresión regular que reconoce uno o muchos espacios en blanco, retornos de carro o tabuladores. D: Expresión regular que reconoce números enteros. DD: Expresión regular que reconoce números con punto decimal. 1234BLANCOS=[ \\r\\t]+D=[0-9]+DD=[0-9]+(&quot;.&quot;[ |0-9]+)?%% Por último se definen todas las reglas léxicas, en las que indicamos los patrones que reconocerá y dentro de llaves lo que debe hacer cuando los reconozca. En la mayoría de los casos se retorna un objeto de tipo Symbol, que vendría siendo un token, este se instancia con el tipo, la fila en la que se encontró, la columna en la que se encontró y el lexema en específico que se reconoció, este se obtiene mediante yytext(). Dentro de las llaves podríamos incluir el código java que quisiéramos. Vemos que al reconocer el patrón BLANCOS no se hace nada porque esperamos que ignore los espacios en blanco. También vemos que al encontrar un salto de linea reinicia la variable yychar, es decir, reinicia el conteo de caracteres para que se lleve la cuenta del número de columna en cada fila. 123456789101112131415161718192021222324&quot;Evaluar&quot; {return new Symbol(sym.REVALUAR,yyline,yychar, yytext());} &quot;;&quot; {return new Symbol(sym.PTCOMA,yyline,yychar, yytext());} &quot;(&quot; {return new Symbol(sym.PARIZQ,yyline,yychar, yytext());} &quot;)&quot; {return new Symbol(sym.PARDER,yyline,yychar, yytext());} &quot;[&quot; {return new Symbol(sym.CORIZQ,yyline,yychar, yytext());} &quot;]&quot; {return new Symbol(sym.CORDER,yyline,yychar, yytext());} &quot;+&quot; {return new Symbol(sym.MAS,yyline,yychar, yytext());} &quot;-&quot; {return new Symbol(sym.MENOS,yyline,yychar, yytext());} &quot;*&quot; {return new Symbol(sym.POR,yyline,yychar, yytext());} &quot;/&quot; {return new Symbol(sym.DIVIDIDO,yyline,yychar, yytext());} \\n {yychar=1;}{BLANCOS} {} {D} {return new Symbol(sym.ENTERO,yyline,yychar, yytext());} {DD} {return new Symbol(sym.DECIMAL,yyline,yychar, yytext());} . { System.out.println(&quot;Este es un error lexico: &quot;+yytext()+ &quot;, en la linea: &quot;+yyline+&quot;, en la columna: &quot;+yychar);} Código fuente para el analizador sintácticoEn el archivo “Sintáctico” incluiremos todo el código que le indicará a Cup lo que debe hacer. El código se muestra a continuación: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970/* * Ejemplo desarrollado por Erick Navarro * GitHub Page: ericknavarro.github.io * Septiembre - 2015 */package analizadores; import java_cup.runtime.*;parser code {: /** * Método al que se llama automáticamente ante algún error sintactico. **/ public void syntax_error(Symbol s){ System.out.println(&quot;Error Sintáctico en la Línea &quot; + (s.left) + &quot; Columna &quot;+s.right+ &quot;. No se esperaba este componente: &quot; +s.value+&quot;.&quot;); } /** * Método al que se llama automáticamente ante algún error sintáctico * en el que ya no es posible una recuperación de errores. **/ public void unrecovered_syntax_error(Symbol s) throws java.lang.Exception{ System.out.println(&quot;Error síntactico irrecuperable en la Línea &quot; + (s.left)+ &quot; Columna &quot;+s.right+&quot;. Componente &quot; + s.value + &quot; no reconocido.&quot;); } :} terminal String PTCOMA,PARIZQ,PARDER,CORIZQ,CORDER;terminal String MAS,MENOS,POR,DIVIDIDO;terminal String ENTERO;terminal String DECIMAL;terminal String UMENOS;terminal String REVALUAR;non terminal ini;non terminal instrucciones;non terminal instruccion;non terminal Double expresion;precedence left MAS,MENOS;precedence left POR,DIVIDIDO;precedence right UMENOS; start with ini; ini::=instrucciones;instrucciones ::= instruccion instrucciones | instruccion | error instrucciones; instruccion ::= REVALUAR CORIZQ expresion:a CORDER PTCOMA{:System.out.println(&quot;El valor de la expresión es: &quot;+a);:};expresion ::= MENOS expresion:a {:RESULT=a*-1;:}%prec UMENOS | expresion:a MAS expresion:b {:RESULT=a+b;:} | expresion:a MENOS expresion:b {:RESULT=a-b;:} | expresion:a POR expresion:b {:RESULT=a*b;:} | expresion:a DIVIDIDO expresion:b {:RESULT=a/b;:} | ENTERO:a {:RESULT=new Double(a);:} | DECIMAL:a {:RESULT=new Double(a);:} | PARIZQ expresion:a PARDER {:RESULT=a;:}; Explicación del código fuente para el analizador sintácticoEn las primeras líneas indicamos a Cup que la clase estará en el paquete analizadores y que es necesario que se importe todo el contenido de “java_cup.runtime”. 12package analizadores; import java_cup.runtime.*; Luego viene la sección “parser code”, en la que se programan acciones propias del parser o analizador sintáctico que se va a generar, en este caso se programa lo que se debe hacer ante un error sintáctico y ante un error sintáctico irrecuperable. 1234567891011121314151617181920parser code {: /** * Método al que se llama automáticamente ante algún error sintactico. **/ public void syntax_error(Symbol s){ System.out.println(&quot;Error Sintáctico en la Línea &quot; + (s.left) + &quot; Columna &quot;+s.right+ &quot;. No se esperaba este componente: &quot; +s.value+&quot;.&quot;); } /** * Método al que se llama automáticamente ante algún error sintáctico * en el que ya no es posible una recuperación de errores. **/ public void unrecovered_syntax_error(Symbol s) throws java.lang.Exception{ System.out.println(&quot;Error síntactico irrecuperable en la Línea &quot; + (s.left)+ &quot; Columna &quot;+s.right+&quot;. Componente &quot; + s.value + &quot; no reconocido.&quot;); } :} Luego se definen los terminales, a estos se les puede indicar un tipo, en este caso todos son de tipo *String, *si no se indicara un tipo, los terminales serían por defecto de tipo Object. 123456terminal String PTCOMA,PARIZQ,PARDER,CORIZQ,CORDER;terminal String MAS,MENOS,POR,DIVIDIDO;terminal String ENTERO;terminal String DECIMAL;terminal String UMENOS;terminal String REVALUAR; Existe un terminal por cada tipo de token que el analizador léxico devuelve. Todos estos tipos estarán definidos en la clase “sym”, que se genera automáticamente y de la que se hablará más adelante. Luego viene la declaración de los no terminales, a los que también se les puede indicar un tipo específico, si no se les indica un tipo, estos son por defecto de tipo Object. 1234non terminal ini;non terminal instrucciones;non terminal instruccion;non terminal Double expresion; Posteriormente, podemos indicar la precedencia de los operadores, ya que la gramática escrita es ambigua, es necesario definir una precedencia para que el analizador no entre en conflicto al analizar, en este caso la precedencia es la misma que la de los operadores aritméticos, la precedencia más baja la tienen la suma y la resta, luego están la multiplicación y la división que tienen una precedencia más alta y por último está el signo menos de las expresiones negativas que tendría la precedencia más alta. 123precedence left MAS,MENOS;precedence left POR,DIVIDIDO;precedence right UMENOS; Por último viene el conjunto de reglas de escritura de la gramática o producciones, al final de cada producción puede incluirse código java entre llaves y dos puntos “{:&lt;código java&gt;:}”. Podemos ver que en las producciones del no terminal “expresion”, se utiliza la variable RESULT, esta variable es propia de Cup y nos permite sintetizar cierto atributo para ese no terminal que se encuentra del lado izquierdo de la producción, recordemos que Cup trabaja con analizadores LALR, que son de tipo ascendente, lo que significa que nos permiten manipular atributos sintetizados. Básicamente eso es RESULT, un atributo sintetizado. RESULT puede ser cualquier objeto, por ejemplo si quisiéramos que RESULT almacenara varios números enteros hacemos una clase Nodo que contenga muchas variables de tipo entero y declaramos los no terminales para que sean de tipo Nodo, entonces el RESULT que sintetizarán dichos no terminales serán de tipo Nodo. 123456789101112131415161718192021222324start with ini; ini::=instrucciones;instrucciones ::= instruccion instrucciones | instruccion | error instrucciones; instruccion ::= REVALUAR CORIZQ expresion:a CORDER PTCOMA{:System.out.println(&quot;El valor de la expresión es: &quot;+a);:};expresion ::= MENOS expresion:a {:RESULT=a*-1;:}%prec UMENOS | expresion:a MAS expresion:b {:RESULT=a+b;:} | expresion:a MENOS expresion:b {:RESULT=a-b;:} | expresion:a POR expresion:b {:RESULT=a*b;:} | expresion:a DIVIDIDO expresion:b {:RESULT=a/b;:} | ENTERO:a {:RESULT=new Double(a);:} | DECIMAL:a {:RESULT=new Double(a);:} | PARIZQ expresion:a PARDER {:RESULT=a;:}; El archivo de compilaciónEn el archivo “compilar.sh”, ejecutamos dos líneas, la primera indica a Jlex que debe generar un analizador léxico en base al código fuente que se encuentra en el archivo “Lexico”, la segunda indica a Cup que la clase que debe generar para el analizador sintáctico se llamará “Sintactico” y que debe generarse en base al código fuente que se encuentra en el archivo “Sintactico”. 12jlex Lexicocup -parser Sintactico Sintactico Para ejecutarlo solo vamos a Netbeans, damos clic derecho sobre el archivo y seleccionamos la opción Run. Al finalizar la ejecución del archivo, veremos en la consola de Netbeans una salida como la siguiente: 123456789101112131415161718192021222324Processing first section -- user code.Processing second section -- JLex declarations.Processing third section -- lexical rules.Creating NFA machine representation.NFA comprised of 67 states.Working on character classes.:::::.:::::::::::::.:::.NFA has 24 distinct character classes.Creating DFA transition table.Working on DFA states...........................Minimizing DFA transition table.24 states after removal of redundant states.Outputting lexical analyzer code.------- CUP v0.11a beta 20060608 Parser Generation Summary ------- 0 errors and 0 warnings 15 terminals, 4 non-terminals, and 14 productions declared, producing 28 unique parse states. 0 terminals declared but not used. 0 non-terminals declared but not used. 0 productions never reduced. 0 conflicts detected (0 expected). Code written to &quot;Sintactico.java&quot;, and &quot;sym.java&quot;.---------------------------------------------------- (v0.11a beta 20060608)RUN SUCCESSFUL (total time: 757ms) Que nos confirma que la generación del analizador léxico fue exitosa y que la del analizador sintáctico también. Veremos que se han creado tres nuevos archivos en el paquete analizadores. Estos archivos son las clases: Lexico.java, Sintactico.java y sym.java. La clase sym.java, sirve como puente entre la clase Lexico.java y Sintactico.java, por ejemplo, cuando el analizador léxico reconoce un número entero, instancia un objeto de la clase Symbol e indica que es de tipo número entero por medio de la constante “sym.ENTERO”, que se genera dentro de la clase sym.java y esta constante se genera porque en el archivo de entrada para Cup se indicó que existe un terminal llamado ENTERO. Entonces tanto el analizador léxico como el sintáctico hacen referencia a los tokens de tipo número entero con la constante “sym.ENTERO”. Básicamente eso es sym.java, una clase con muchas constantes estáticas a las que acceden ambos analizadores para poder integrarse y ejecutar sus tareas exitosamente. Archivo de entradaDentro de la carpeta del proyecto crearé un archivo de entrada llamado “entrada.txt”. Que contendrá el archivo de entrada que reconocerán nuestros analizadores. El archivo de “entrada.txt” contiene lo siguiente: 12345Evaluar[1+1];Evaluar[1+1*2];Evaluar[-(1+1*6/3-5+7)];Evaluar[-(1+1*6/3-5+1*-2)];Evaluar[-(1+1)]; Clase principalDentro de la clase principal solo tenemos el método main y el método interpretar que lee el contenido del archivo que se encuentra en el path que se le indica y ejecuta análisis léxico y análisis sintáctico, en el transcurso del analisis sintáctico se mandan a imprimir en consola los resultados de las expresiones aritméticas analizadas, por lo que al final del análisis tendremos todos los resultados de las operaciones en consola. A continuación se muestra el código de la clase principal. 12345678910111213141516171819202122232425262728293031323334353637/* * Ejemplo desarrollado por Erick Navarro * GitHub Page: ericknavarro.github.io * Septiembre - 2015 */package proyectocupjlex;import java.io.FileInputStream;/** * Clase principal de la aplicación * @author Erick */public class ProyectoCupJlex { /** * @param args argumentos de la linea de comando */ public static void main(String[] args) { interpretar(&quot;entrada.txt&quot;); } /** * Método que interpreta el contenido del archivo que se encuentra en el path * que recibe como parámentro * @param path ruta del archivo a interpretar */ private static void interpretar(String path) { analizadores.Sintactico pars; try { pars=new analizadores.Sintactico(new analizadores.Lexico(new FileInputStream(path))); pars.parse(); } catch (Exception ex) { System.out.println(&quot;Error fatal en compilación de entrada.&quot;); System.out.println(&quot;Causa: &quot;+ex.getCause()); } } } Ejecutando nuestra aplicaciónAl ejecutar la aplicación obtenemos los resultados de las operaciones evaluadas en consola. Si les gusto este tutorial, puede que también estén interesados en este otro: Intérprete sencillo utilizando Java, Jlex y Cup. Fuentes consultadas:Compiladores, principios, técnicas y herramientas. Aho, Lam, Sethi y Ullman. Segunda Edición.","link":"/2019/04/25/01-Mi-primer-proyecto-utilizando-Jlex-y-Cup-Linux/"},{"title":"Analizador léxico en Visual Basic","text":"En esta publicación se muestra un ejemplo sencillo de la implementación de un analizador léxico a partir de un autómata finito determinista. Este proyecto se desarrolló utilizando Visual Studio 2013. El proyecto completo del ejemplo puede descargarse del siguiente enlace: Analizador léxico en Visual Basic. Todo el código dentro del proyecto está documentado con comentarios que contienen explicaciones sobre su funcionamiento. Funcionamiento del proyectoEste ejemplo ilustra la implementación de un analizador léxico a partir de un Autómata Finito Determinista (AFD). No se utiliza ningún generador de analizadores léxicos que genere el analizador, ni se realiza el proceso de análisis léxico con ninguna librería. Los errores identificados en el proceso de análisis léxico se muestran en consola, si en el entorno de Visual Studio no aparece la consola, esta pueden abrirse desde el menú ver, en la opción resultados o con Ctrl+Alt+O. Inicialmente se muestra una expresión aritmética de ejemplo que puede utilizarse como entrada, del lado izquierdo. Al presionar el botón Realizar Análisis Léxico se ejecuta el análisis de la entrada y del lado derecho se despliega la lista de tokens identificada, en la que se indica el tipo de token y el valor específico que este tiene. Si existiera algún error léxico en la entrada, por ejemplo, si pusiéramos al final de la expresión una arroba en lugar del uno, entonces se desplegaría en consola un mensaje de error y se mostraría en la lista de tokens todos aquellos tokens válidos. Autómata Finito Determinista utilizadoEn este ejemplo se reconocen los componentes léxicos propios de una expresión aritmética, por ello el ejemplo se realizó a partir del siguiente autómata finito determinista: El estado inicial del autómata es E_0. En el autómata podemos observar que existen tres estados de aceptación, el primero (EA_1) reconoce todos los componentes léxicos de un carácter y a nivel programación se clasifican los tokens según el carácter que se haya reconocido, el segundo estado de aceptación (EA_2) reconoce los números enteros y el tercero (EA_3) reconoce los números reales, es decir, los números con punto decimal. Se pueden desplegar dos tipos de mensajes de error, ya que se cuentan con dos estados de error, el primero es cuando se reconoce un carácter desconocido estando en el estado 1, el segundo se da cuando estando en el estado 2, correspondiente a los números reales, se esperaban más dígitos después del punto decimal, pero se obtiene un carácter que no es un dígito. A un lado de algunos estados se coloca un asterisco (*), que indica que debe retrocederse la entrada en una posición, esto se hace porque los tokens se dan como aceptados con el primer carácter del siguiente token, entonces para que no se pierda ese carácter del siguiente token en el análisis debe retrocederse una posición en la entrada, esta notación es la misma que se utiliza en el libro de Aho, Lam, Sethi y Ullman. El secreto tras la implementación del autómataEl secreto es encontrar la forma de ejecutar en código las acciones que un reconocedor haría basado en el autómata finito determinista, es lógico que la función core del analizador léxico debe estar dentro de un ciclo ya que deben recorrerse los caracteres de izquierda a derecha y agruparse en componentes léxicos. Este ciclo se encuentra en la función escanear de la clase AnalizadorLexico, dentro de dicho ciclo debe haber un select case en el que cada caso representa a uno de los estados del conjunto de estados para cada caso (o estado) hay un if elseif elseif … else que representan el conjunto de transiciones que salen de dicho estado. Fuentes consultadas: Compiladores, principios, técnicas y herramientas. Aho, Lam, Sethi y Ullman. Segunda Edición. Págs. 111, 130 y 131 Teoría de la computación. Lenguajes formales, autómatas y complejidad. J. Glenn Brookshear. Pág. 24","link":"/2019/04/26/03-Analizador-lexico-en-Visual-Basic/"},{"title":"Mi primer proyecto utilizando Jlex y Cup (Windows)","text":"Se desarrollará un intérprete que recibe como entrada varias expresiones aritméticas y presenta como salida el resultado de dichas expresiones. Las tecnologías a utilizar son: Jlex: Generador de analizadores léxicos Cup: Generador de analizadores sintácticos Windows 10: Sistema operativo Netbeans 8.2: IDE (entorno de desarrollo integrado) El proyecto completo del ejemplo puede descargarse del siguiente enlace: Mi primer proyecto utilizando Jlex y Cup (Windows) JLexJLex es un generador de analizadores léxicos, escrito en Java, para Java. JLex fue desarrollado por Elliot Berk en la Universidad de Princeton. Para más información visitar la página oficial de JLex. La principal tarea de un analizador léxico es leer los caracteres de entrada del programa fuente, agruparlos en lexemas y producir como salida una secuencia de tokens. Un token es un par que consiste en un nombre de token y un valor de atributo opcional. Un lexema es una secuencia de caracteres en el programa fuente, que coinciden con el patrón para un token y que el analizador léxico identifica como una instancia de este tóken. Un patrón es una descripción de la forma que pueden tomar los lexemas de un token. En JLex se definen los patrones de los diferentes tokens que se desean reconocer, estos patrones pueden definirse a través de expresiones regulares. Además JLex cuenta con múltiples opciones, una muy imporante es su capacidad para integrarse con generadores de analizadores sintácticos como Cup. CupCup es un generador de analizadores sintácticos de tipo LALR para Java. El analizador sintáctico obtiene una cadena de tokens del analizador léxico y verifica que dicha cadena pueda generase con la gramática para el lenguaje fuente. Una gramática proporciona una especificación precisa y fácil de entender de un lenguaje de programación. Pre-requisitosPara este ejemplo hace falta que tengamos instalado: Java Development Kit (JDK) Netbeans Debemos asegurarnos que la carpeta bin del JDK haya sido agregada a nuestra variable de entorno Path, para ello vamos a la configuración de dicha variable de entorno (Clic derecho en This PC → Properties → Advanced system settings → Environment Variables → Variable Path → Edit) y si no existe agregamos la ruta a la carpeta bin del JDK, que en mi caso es: C:\\Program Files\\Java\\jdk1.8.0_152\\bin Descargar JLex Lo primero que haremos será descargar JLex, para ello vamos a la página oficial y descargamos la versión actual del software: Vamos a obtener el archivo Main.java: Descargar CupPara descargar Cup, vamos a la página oficial y descargamos la última versión del software: Descomprimimos el archivo descargado, para ello se recomienda la herramienta PeaZip y vamos a obtener los siguientes archivos: Crear nuestro proyectoAbrimos Netbeans y creamos un nuevo proyecto de Java (File → New Project). Creamos un paquete llamado analizadores, este almacenará todo el código fuente relacionado con el analizador léxico y sintáctico (Clic derecho en Source Packages → New → Java Package). Creamos tres archivos en el paquete analizadores, el primero “Lexico”, que almacenará el código fuente con el cual JLex generará el analizador léxico que queremos, el segundo “Sintactico”, que almacenará el código fuente con el cual Cup generará el analizador sintáctico que queremos y el tercero “compilar.sh”, que guardará los comandos que deben ejecutarse para solicitarle a JLex y a Cup que generen los analizadores. Para crear cada uno de los archivos hacemos clic derecho en el paquete analizadores → New → Other → en la ventana que despliegue, seleccionar Categories: Other y File Types: Empty File, seleccionamos siguiente, indicamos el nombre para el archivo y finalizamos. De tal modo que al final tendremos los tres archivos archivos. Importar la librería de Cup en nuestro proyecto para poder ejecutar el analizador sintáctico que generemosPara ello creamos una carpeta lib dentro de la carpeta de nuestro proyecto. Dentro de la carpeta lib pegamos el archivo “java-cup-11b-runtime.jar” que descargamos anteriormente. Para importar el archivo jar, vamos a Netbeans y damos clic derecho en la pestaña Libraries de nuestro proyecto → Add JAR/Folder… luego buscamos el archivo jar en la carpeta lib que acabamos de copiar en la carpeta lib y lo seleccionamos. Código fuente para el analizador léxicoEn el archivo “Lexico” incluiremos todo el código que le indicará a Jlex lo que debe hacer. El código se muestra a continuación: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/* * Ejemplo desarrollado por Erick Navarro * GitHub Page: ericknavarro.github.io * Julio - 2018 */package analizadores;import java_cup.runtime.Symbol; %% %class Lexico%public %line %char %cup %unicode%ignorecase%init{ yyline = 1; yychar = 1; %init} BLANCOS=[ \\r\\t]+D=[0-9]+DD=[0-9]+(&quot;.&quot;[ |0-9]+)?%%&quot;Evaluar&quot; {return new Symbol(sym.REVALUAR,yyline,yychar, yytext());} &quot;;&quot; {return new Symbol(sym.PTCOMA,yyline,yychar, yytext());} &quot;(&quot; {return new Symbol(sym.PARIZQ,yyline,yychar, yytext());} &quot;)&quot; {return new Symbol(sym.PARDER,yyline,yychar, yytext());} &quot;[&quot; {return new Symbol(sym.CORIZQ,yyline,yychar, yytext());} &quot;]&quot; {return new Symbol(sym.CORDER,yyline,yychar, yytext());} &quot;+&quot; {return new Symbol(sym.MAS,yyline,yychar, yytext());} &quot;-&quot; {return new Symbol(sym.MENOS,yyline,yychar, yytext());} &quot;*&quot; {return new Symbol(sym.POR,yyline,yychar, yytext());} &quot;/&quot; {return new Symbol(sym.DIVIDIDO,yyline,yychar, yytext());} \\n {yychar=1;}{BLANCOS} {} {D} {return new Symbol(sym.ENTERO,yyline,yychar, yytext());} {DD} {return new Symbol(sym.DECIMAL,yyline,yychar, yytext());} . { System.out.println(&quot;Este es un error lexico: &quot;+yytext()+ &quot;, en la linea: &quot;+yyline+&quot;, en la columna: &quot;+yychar);} Explicación del código fuente para el analizador léxicoEn las primeras líneas indicamos a Jlex que la clase estará en el paquete analizadores y que es necesario que se importe la clase Symbol. 12package analizadores;import java_cup.runtime.Symbol; Posteriormente indicamos a Jlex que: La clase del analizador se llamará “Lexico” La clase será pública Debe llevar el conteo de las líneas Debe llevar el conteo de los caracteres reconocidos Debe integrarse con cup El set de caracteres que debe utilizar es el unicode El analizador no será case sensitive, es decir, no le importa si las letras son mayúsculas o minúsculas 12345678%% %class Lexico%public %line %char %cup %unicode%ignorecase Luego viene el bloque init, dentro del init, se ejecutan las acciones de inicialización, es decir, lo que va dentro del constructor del analizador léxico.En este caso indicamos dentro del init que: La variable yyline, que lleva la cuenta del número de linea por el que va el analizador valdrá inicialmente 1. La variable yychar, que lleva la cuenta del número de carácter por el que va el analizador valdrá inicialmente 1. 1234%init{ yyline = 1; yychar = 1; %init} Luego se escriben algunas expresiones regulares que son almacenadas en macros, que básicamente son variables que almacenan los patrones, en este caso se definen las macros: BLANCOS, D y DD. Los patrones para cada una son los siguientes: BLANCOS: Expresión regular que reconoce uno o muchos espacios en blanco, retornos de carro o tabuladores. D: Expresión regular que reconoce números enteros. DD: Expresión regular que reconoce números con punto decimal. 1234BLANCOS=[ \\r\\t]+D=[0-9]+DD=[0-9]+(&quot;.&quot;[ |0-9]+)?%% Por último se definen todas las reglas léxicas, en las que indicamos el patrón que reconocerá y dentro de llaves lo que debe hacer cuando lo reconozca. En la mayoría de los casos se retorna un objeto de tipo Symbol, que vendría siendo un token, este se instancia con el tipo, la fila en la que se encontró, la columna en la que se encontró y el lexema en específico que se reconoció, este se obtiene mediante yytext(). Dentro de las llaves podríamos incluir el código java que quisiéramos. Vemos que al reconocer el patrón BLANCOS no se hace nada porque esperamos que ignore los espacios en blanco. También vemos que al encontrar un salto de linea reinicia la variable yychar, es decir, reinicia el conteo de caracteres para que se lleve la cuenta del número de columna en cada fila. 123456789101112131415161718192021222324&quot;Evaluar&quot; {return new Symbol(sym.REVALUAR,yyline,yychar, yytext());} &quot;;&quot; {return new Symbol(sym.PTCOMA,yyline,yychar, yytext());} &quot;(&quot; {return new Symbol(sym.PARIZQ,yyline,yychar, yytext());} &quot;)&quot; {return new Symbol(sym.PARDER,yyline,yychar, yytext());} &quot;[&quot; {return new Symbol(sym.CORIZQ,yyline,yychar, yytext());} &quot;]&quot; {return new Symbol(sym.CORDER,yyline,yychar, yytext());} &quot;+&quot; {return new Symbol(sym.MAS,yyline,yychar, yytext());} &quot;-&quot; {return new Symbol(sym.MENOS,yyline,yychar, yytext());} &quot;*&quot; {return new Symbol(sym.POR,yyline,yychar, yytext());} &quot;/&quot; {return new Symbol(sym.DIVIDIDO,yyline,yychar, yytext());} \\n {yychar=1;}{BLANCOS} {} {D} {return new Symbol(sym.ENTERO,yyline,yychar, yytext());} {DD} {return new Symbol(sym.DECIMAL,yyline,yychar, yytext());} . { System.out.println(&quot;Este es un error lexico: &quot;+yytext()+ &quot;, en la linea: &quot;+yyline+&quot;, en la columna: &quot;+yychar);} Código fuente para el analizador sintácticoEn el archivo “Sintáctico” incluiremos todo el código que le indicará a Cup lo que debe hacer. El código se muestra a continuación: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970/* * Ejemplo desarrollado por Erick Navarro * GitHub Page: ericknavarro.github.io * Julio - 2018 */package analizadores; import java_cup.runtime.*;parser code {: /** * Método al que se llama automáticamente ante algún error sintactico. **/ public void syntax_error(Symbol s){ System.out.println(&quot;Error Sintáctico en la Línea &quot; + (s.left) + &quot; Columna &quot;+s.right+ &quot;. No se esperaba este componente: &quot; +s.value+&quot;.&quot;); } /** * Método al que se llama automáticamente ante algún error sintáctico * en el que ya no es posible una recuperación de errores. **/ public void unrecovered_syntax_error(Symbol s) throws java.lang.Exception{ System.out.println(&quot;Error síntactico irrecuperable en la Línea &quot; + (s.left)+ &quot; Columna &quot;+s.right+&quot;. Componente &quot; + s.value + &quot; no reconocido.&quot;); } :} terminal String PTCOMA,PARIZQ,PARDER,CORIZQ,CORDER;terminal String MAS,MENOS,POR,DIVIDIDO;terminal String ENTERO;terminal String DECIMAL;terminal String UMENOS;terminal String REVALUAR;non terminal ini;non terminal instrucciones;non terminal instruccion;non terminal Double expresion;precedence left MAS,MENOS;precedence left POR,DIVIDIDO;precedence right UMENOS; start with ini; ini::=instrucciones;instrucciones ::= instruccion instrucciones | instruccion | error instrucciones; instruccion ::= REVALUAR CORIZQ expresion:a CORDER PTCOMA{:System.out.println(&quot;El valor de la expresión es: &quot;+a);:};expresion ::= MENOS expresion:a {:RESULT=a*-1;:}%prec UMENOS | expresion:a MAS expresion:b {:RESULT=a+b;:} | expresion:a MENOS expresion:b {:RESULT=a-b;:} | expresion:a POR expresion:b {:RESULT=a*b;:} | expresion:a DIVIDIDO expresion:b {:RESULT=a/b;:} | ENTERO:a {:RESULT=new Double(a);:} | DECIMAL:a {:RESULT=new Double(a);:} | PARIZQ expresion:a PARDER {:RESULT=a;:}; Explicación del código fuente para el analizador sintácticoEn las primeras líneas indicamos a Cup que la clase estará en el paquete analizadores y que es necesario que se importe todo el contenido de “java_cup.runtime”. 12package analizadores; import java_cup.runtime.*; Luego viene la sección “parser code”, en la que se programan acciones propias del parser o analizador sintáctico que se va a generar, en este caso se programa lo que se debe hacer ante un error sintáctico y ante un error sintáctico irrecuperable. 1234567891011121314151617181920parser code {: /** * Método al que se llama automáticamente ante algún error sintactico. **/ public void syntax_error(Symbol s){ System.out.println(&quot;Error Sintáctico en la Línea &quot; + (s.left) + &quot; Columna &quot;+s.right+ &quot;. No se esperaba este componente: &quot; +s.value+&quot;.&quot;); } /** * Método al que se llama automáticamente ante algún error sintáctico * en el que ya no es posible una recuperación de errores. **/ public void unrecovered_syntax_error(Symbol s) throws java.lang.Exception{ System.out.println(&quot;Error síntactico irrecuperable en la Línea &quot; + (s.left)+ &quot; Columna &quot;+s.right+&quot;. Componente &quot; + s.value + &quot; no reconocido.&quot;); } :} Luego se definen los terminales, a estos se les puede indicar un tipo, en este caso todos son de tipo *String, *si no se indicara un tipo, los terminales serían por defecto de tipo Object. 123456terminal String PTCOMA,PARIZQ,PARDER,CORIZQ,CORDER;terminal String MAS,MENOS,POR,DIVIDIDO;terminal String ENTERO;terminal String DECIMAL;terminal String UMENOS;terminal String REVALUAR; Existe un terminal por cada tipo de token que el analizador léxico devuelve. Todos estos tipos estarán definidos en la clase “sym”, que se genera automáticamente y de la que se hablará más adelante. Luego viene la declaración de los no terminales, a los que también se les puede indicar un tipo específico, si no se les indica un tipo, estos son por defecto de tipo Object. 1234non terminal ini;non terminal instrucciones;non terminal instruccion;non terminal Double expresion; Posteriormente podemos indicar la precedencia de los operadores, ya que la gramática escrita es ambigua, es necesario definir una precedencia para que el analizador no entre en conflicto al analizar, en este caso la precedencia es la misma que la de los operadores aritméticos, la precedencia más baja la tienen la suma y la resta, luego están la multiplicación y la división que tienen una precedencia más alta y por último está el signo menos de las expresiones negativas que tendría la precedencia más alta. 123precedence left MAS,MENOS;precedence left POR,DIVIDIDO;precedence right UMENOS; Por último viene el conjunto de reglas de escritura de la gramática o producciones, al final de cada producción puede incluirse código java entre llaves y dos puntos “{:&lt;código java&gt;:}”. Podemos ver que en las producciones del no terminal “expresion”, se utiliza la variable RESULT, esta variable es propia de Cup y nos permite sintetizar cierto atributo para ese no terminal que se encuentra del lado izquierdo de la producción, recordemos que Cup trabaja con analizadores LALR, que son de tipo ascendente, lo que significa que nos permiten manipular atributos sintetizados. Básicamente eso es RESULT, un atributo sintetizado. RESULT puede ser cualquier objeto, por ejemplo si quisiéramos que RESULT almacenara varios números enteros hacemos una clase Nodo que contenga muchas variables de tipo entero y declaramos los no terminales para que sean de tipo Nodo, entonces el RESULT que sintetizarán dichos no terminales serán de tipo Nodo. 123456789101112131415161718192021222324start with ini; ini::=instrucciones;instrucciones ::= instruccion instrucciones | instruccion | error instrucciones; instruccion ::= REVALUAR CORIZQ expresion:a CORDER PTCOMA{:System.out.println(&quot;El valor de la expresión es: &quot;+a);:};expresion ::= MENOS expresion:a {:RESULT=a*-1;:}%prec UMENOS | expresion:a MAS expresion:b {:RESULT=a+b;:} | expresion:a MENOS expresion:b {:RESULT=a-b;:} | expresion:a POR expresion:b {:RESULT=a*b;:} | expresion:a DIVIDIDO expresion:b {:RESULT=a/b;:} | ENTERO:a {:RESULT=new Double(a);:} | DECIMAL:a {:RESULT=new Double(a);:} | PARIZQ expresion:a PARDER {:RESULT=a;:}; Incluír JLex para generar el analizador léxico de nuestro proyectoCreamos un paquete llamado JLex dentro del paquete analizadores, este almacenará la herramienta JLex (Clic derecho en el paquete analizadores → New → Java Package). En la carpeta del paquete JLex copiamos el archivo Main.java que descargamos de la página oficial de JLex. Incluír Cup para generar el analizador sintáctico de nuestro proyectoCreamos un paquete llamado Cup dentro del paquete analizadores, este almacenará la herramienta Cup (Clic derecho en el paquete analizadores → New → Java Package). En la carpeta del paquete Cup copiamos el archivo “java-cup-11b-runtime.jar” que descargamos de la página oficial de Cup. El archivo de compilaciónEn el archivo “compilar.bat”, ejecutamos tres líneas, la primera indica a compila Main.java para poder disponer de la herramienta para generar nuestro analizador léxico, la segunda le indica a la herramienta Jlex que debe generar un analizador léxico en base al código fuente que se encuentra en el archivo “Lexico”, la tercera indica a Cup que la clase que debe generar para el analizador sintáctico se llamará “Sintactico” y que debe generarse en base al código fuente que se encuentra en el archivo “Sintactico”. 123javac JLex/Main.javajava JLex.Main Lexicojava -jar Cup/java-cup-11b.jar -parser Sintactico Sintactico Para ejecutarlo solo vamos a Netbeans, damos clic derecho sobre el archivo y seleccionamos la opción Run. Al finalizar la ejecución del archivo, veremos en la consola de Netbeans una salida como la siguiente: 12345678910111213141516171819202122232425262728293031323334cd 'C:/Users/erick/OneDrive/Documentos/NetBeansProjects/ProyectoCupJlexWindows/src/analizadores'C:/Users/erick/OneDrive/Documentos/NetBeansProjects/ProyectoCupJlexWindows/src/analizadores/compilar.bat C:\\Users\\erick\\OneDrive\\Documentos\\NetBeansProjects\\ProyectoCupJlexWindows\\src\\analizadores&gt;javac JLex/Main.java Note: JLex\\Main.java uses unchecked or unsafe operations.Note: Recompile with -Xlint:unchecked for details.C:\\Users\\erick\\OneDrive\\Documentos\\NetBeansProjects\\ProyectoCupJlexWindows\\src\\analizadores&gt;java JLex.Main Lexico Processing first section -- user code.Processing second section -- JLex declarations.Processing third section -- lexical rules.Creating NFA machine representation.NFA comprised of 67 states.Working on character classes.:::::.:::::::::::::.:::.NFA has 24 distinct character classes.Creating DFA transition table.Working on DFA states...........................Minimizing DFA transition table.24 states after removal of redundant states.Outputting lexical analyzer code.C:\\Users\\erick\\OneDrive\\Documentos\\NetBeansProjects\\ProyectoCupJlexWindows\\src\\analizadores&gt;java -jar Cup/java-cup-11b.jar -parser Sintactico Sintactico ------- CUP v0.11b 20160615 (GIT 4ac7450) Parser Generation Summary ------- 0 errors and 0 warnings 15 terminals, 4 non-terminals, and 14 productions declared, producing 28 unique parse states. 0 terminals declared but not used. 0 non-terminals declared but not used. 0 productions never reduced. 0 conflicts detected (0 expected). Code written to &quot;Sintactico.java&quot;, and &quot;sym.java&quot;.---------------------------------------------------- (CUP v0.11b 20160615 (GIT 4ac7450))RUN SUCCESSFUL (total time: 3s) Que nos confirma que la generación del analizador léxico fue exitosa y que la del analizador sintáctico también. Veremos que se han creado tres nuevos archivos en el paquete analizadores. Estos archivos son las clases: Lexico.java, Sintactico.java y sym.java. La clase sym.java, sirve como puente entre la clase Lexico.java y Sintactico.java, por ejemplo, cuando el analizador léxico reconoce un número entero, instancia un objeto de la clase Symbol e indica que es de tipo número entero por medio de la constante “sym.ENTERO”, que se genera dentro de la clase sym.java y esta constante se genera porque en el archivo de entrada para Cup se indicó que existe un terminal llamado ENTERO. Entonces tanto el analizador léxico como el sintáctico hacen referencia a los tokens de tipo número entero con la constante “sym.ENTERO”. Básicamente eso es sym.java, una clase con muchas constantes estáticas a las que acceden ambos analizadores para poder integrarse y ejecutar sus tareas exitosamente. Creando un archivo de entrada para nuestros analizadoresDentro de la carpeta del proyecto crearé un archivo de entrada llamado “entrada.txt”. Que contendrá el archivo de entrada que reconocerán nuestros analizadores. El archivo de “entrada.txt” contiene lo siguiente: 12345Evaluar[1+1];Evaluar[1+1*2];Evaluar[-(1+1*6/3-5+7)];Evaluar[-(1+1*6/3-5+1*-2)];Evaluar[-(1+1)]; Clase principalDentro de la clase principal solo tenemos el método main y el método interpretar que lee el contenido del archivo que se encuentra en el path que se le indica y ejecuta análisis léxico y análisis sintáctico, en el transcurso del analisis sintáctico se mandan a imprimir en consola los resultados de las expresiones aritméticas analizadas, por lo que al final del análisis tendremos todos los resultados de las operaciones en consola. A continuación se muestra el código de la clase principal. 123456789101112131415161718192021222324252627282930313233343536373839/* * Ejemplo desarrollado por Erick Navarro * GitHub Page: ericknavarro.github.io * Julio - 2018 */package proyectocupjlexwindows;import java.io.FileInputStream;/** * Clase principal de la aplicación * @author Erick */public class ProyectoCupJlexWindows { /** * @param args argumentos de la linea de comando */ public static void main(String[] args) { interpretar(&quot;entrada.txt&quot;); } /** * Método que interpreta el contenido del archivo que se encuentra en el path * que recibe como parámentro * @param path ruta del archivo a interpretar */ private static void interpretar(String path) { analizadores.Sintactico pars; try { pars=new analizadores.Sintactico(new analizadores.Lexico(new FileInputStream(path))); pars.parse(); } catch (Exception ex) { System.out.println(&quot;Error fatal en compilación de entrada.&quot;); System.out.println(&quot;Causa: &quot;+ex.getCause()); } } } Ejecutando nuestra aplicaciónAl ejecutar la aplicación obtenemos los resultados de las operaciones evaluadas en consola. Si les gusto este tutorial, puede que también estén interesados en este otro: Intérprete sencillo utilizando Java, Jlex y Cup. Fuentes consultadas:Compiladores, principios, técnicas y herramientas. Aho, Lam, Sethi y Ullman. Segunda Edición.","link":"/2019/04/26/02-Mi-primer-proyecto-utilizando-Jlex-y-Cup-Windows/"},{"title":"Analizador sintáctico en Visual Basic","text":"En esta publicación se muestra un ejemplo sencillo de la implementación de un analizador sintáctico a partir de una gramática independiente del contexto. Este proyecto se desarrolló utilizando Visual Studio 2013. El proyecto completo puede descargarse del siguiente enlace: Analizador sintáctico en Visual Basic. Todo el código dentro del proyecto está documentado con comentarios que contienen explicaciones sobre su funcionamiento. Funcionamiento del proyectoEste ejemplo ilustra la implementación de un analizador sintáctico a partir de una gramática independiente del contexto. No se utiliza ningún generador de analizadores sintácticos que genere el analizador, ni se realiza el proceso de análisis sintáctico con ninguna librería. Los errores identificados en el proceso de análisis sintáctico se muestran en consola, si en el entorno de Visual Studio no aparece la consola, esta puede abrirse desde el menú ver, en la opción resultados o con Ctrl+Alt+O. Inicialmente se muestra una expresión aritmética de ejemplo que puede utilizarse como entrada, esta entrada contiene una expresión incompleta que léxicamente es correcta pero sintácticamente no, su estructura es incorrecta porque le hace falta un numero y un paréntesis derecho al final. Al presionar el botón Analizar se ejecuta el análisis de la entrada y en consola se despliegan los mensajes de error. El fundamento teórico que sirvió de soporte para el desarrollo de este ejemplo es el descrito en la sección 4.4.1 titulada Análisis sintáctico de descenso recursivo del libro: Compiladores, principios, técnicas y herramientas. Aho, Lam, Sethi y Ullman. Segunda Edición. Gramática independiente del contexto utilizadaLa gramática utilizada reconoce expresiones aritméticas respetando la precedencia de operadores, no es ambigua y no tiene recursividad por la izquierda. La gramática es la siguiente: 12345678910E → T E'E' → + T E'E' → - T E'E' → εT → F T'T' → * F T'T' → / F T'T' → εF → ( E )F → numero Método utilizado para el desarrollo del analizadorSe desarrolló un analizador sintáctico predictivo recursivo. Los analizadores predictivos o descendentes consisten en la construcción de un árbol de análisis sintáctico para la cadena de entrada, partiendo desde la raíz y creando los nodos del árbol de análisis sintáctico en pre-orden. En este caso no se construye un árbol en memoria, ya que no es necesario guardar lo que se analiza, pero las llamadas recursivas a los diferentes métodos del analizador crean un árbol en pila mientras se ejecutan. La construcción de este analizador sintáctico predictivo recursivo sigue los siguientes principios: Consiste en un conjunto de procedimientos, uno para cada no terminal. La ejecución empieza con el procedimiento para el símbolo inicial. Se detiene y anuncia que tuvo éxito si el cuerpo de su procedimiento explora la cadena completa de entrada. Para cada no terminal del lado derecho de las producciones se hace una llamada al método que le corresponde. Para cada terminal del lado derecho de las producciones se hace una llamada al método match enviando como parámetro el terminal. El método match valida si el terminal que se recibe es el que se esperaba, de no ser así despliega un mensaje de error. La gramática a utilizar reconoce expresiones aritméticas y cumple con lo siguiente: No es ambigua No tiene recursividad por la izquierda Sobre la recuperación de errores sintácticosEste ejemplo es bastante básico, por lo que no tiene implementado un sistema de recuperación de errores sintácticos, para hacerlo existen muchas estrategias, como las siguientes: Recuperación en modo pánico Recuperación a nivel de frase Producción de errores Corrección global Se recomienda la recuperación en modo pánico por ser la más sencilla de implementar Fuentes consultadas: Compiladores, principios, técnicas y herramientas. Aho, Lam, Sethi y Ullman. Segunda Edición. Sección 4.4.1.","link":"/2019/04/26/04-Analizador-sintactico-en-Visual-Basic/"},{"title":"Intérprete sencillo utilizando Java, Jlex y Cup","text":"En los cursos de compiladores de la universidad, es bastante común que se solicite al estudiante desarrollar un intérprete, una herramienta que reciba como entrada cierto lenguaje de programación y lo ejecute, pero la mayoría de documentación al respecto solo muestra ejemplos de cosas sencillas, como una calculadora o un lenguaje que imprime cadenas en consola. Pero qué pasa si lo que deseamos es que se ejecuten sentencias de control como el IF o ciclos como la sentencia WHILE y que además estas sentencias soporten muchos niveles de anidamiento, que se declaren variables y se asigne valores a estas variables, que se tenga control de los ámbitos de las variables, en fin, que tenga las funciones básicas de un lenguaje de programación. No es común encontrar este tipo de ejemplos, en lo personal, puedo asegurar que nunca encontré un tutorial en el que se mostrara un ejemplo documentado y bien explicado sobre esto. Es por eso que les traigo este ejemplo, espero que les sea útil. Funcionamiento de la aplicaciónEn este tutorial se desarrolla un intérprete que recibe como entrada un archivo de texto que contiene varias sentencias en un lenguaje programación diseñado especialmente para esta aplicación, primero se hace análisis léxico y sintáctico de dicha entrada, durante el análisis sintáctico se carga en memoria un Árbol de Sintaxis Abstracta (AST) que se utiliza posteriormente para ejecutar las sentencias. Los analizadores se generan con Jlex y Cup. Se desarrollaron dos versiones del proyecto, una utilizando Windows 10 y otra utilizando Ubuntu 14.04. El proyecto completo del ejemplo puede descargarse de los siguientes enlaces: Intérprete sencillo utilizando Java, Jlex y Cup (Linux)Intérprete sencillo utilizando Java, Jlex y Cup (Windows) Todo el código dentro del proyecto está documentado con comentarios que contienen explicaciones sobre su funcionamiento. Si desean una pequeña introducción al uso de Jlex y Cup pueden visitar mi post: Mi primer proyecto utilizando Jlex y Cup (Linux) o bien Mi primer proyecto utilizando Jlex y Cup (Windows). El lenguaje de entradaDentro de la carpeta del proyecto, hay un archivo de entrada llamado “entrada.txt”, en él se muestran ejemplos de todas las funciones del lenguaje diseñado para esta aplicación, al leerlo se puede tener una idea clara de las funciones con las que el lenguaje cuenta, este archivo contiene lo siguiente: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364/****************************************** * Ejemplo desarrollado por Erick Navarro * * GitHub Page: ericknavarro.github.io * * Septiembre - 2015 * ******************************************///Se imprime el encabezadoimprimir(&quot;Tablas de&quot; &amp; &quot; multiplicar&quot;);//Se declara la variable a, de tipo numeronumero a;//Se asigna a la variable a el valor 0a=0;//Se declara la variable c, de tipo numeronumero c;//Se asigna a la variable c el valor 0c=1;//Se imprime un separadorimprimir(&quot;----------------&quot;);/** * Se imprimen las tablas del 1 al 5 y * para cada tabla, se imprimen los resultados * desde el uno hasta el 5, esto se hace con * dos ciclos while anidados. **/mientras(a&lt;4+c){ a=a+1; numero b; b=0; mientras(b&lt;4+c){ b=b+1; imprimir(a &amp; &quot; * &quot; &amp; b &amp; &quot; = &quot; &amp; a * b); } imprimir(&quot;----------------&quot;);}//Se asigna a la variable a el valor de 11a=11;/** * La variable b ya había sido declarada pero * dentro del ámbito del primer ciclo while, * entonces no existe en este ámbito por lo que * debe declararse. **/numero b;//Se asigna valor de 12 a b y valor de 13 a cb=12;c=13;/** * Se evalua si el valor de la variable a es * mayor que 10, si el b es mayor que 11 y si * el de c es mayor que 12. **/If(a&gt;10){ imprimir(&quot;a es mayor que 10.&quot;); if(b&gt;11){ imprimir(&quot;a es mayor que 10 y b es mayor que 11.&quot;); if(c&gt;12){ imprimir(&quot;a es mayor que 10, b es mayor que 11 y c es mayor que 12.&quot;); } }}else{ imprimir(&quot;a es menor o igual que 10.&quot;);} Como se puede observar, el lenguaje acepta: Comentarios de muchas líneas (//). Comentarios de una línea (//). Concatenación de cadenas, mediante el operador “&amp;”. Función “imprimir”: que recibe como parámetro una cadena e imprime en consola dicha cadena. Declaración de variables: el único tipo de variables que el lenguaje soporta es “numero”, que es una variable de tipo numérico que suporta números enteros o con punto decimal (Dentro del rango del tipo Double de Java). Asignación de variables, a cualquier variable se le puede asignar cualquier expresión que tenga como resultado un número. Instrucción “mientras”: tiene el comportamiento clásico del ciclo while, ejecuta el ciclo mientras la expresión booleana que recibe sea verdadera. Esta instrucción soporta anidamiento. Instrucción “if” e instrucción “if-else”: si la expresión booleana que recibe es verdadera entonces ejecuta las instrucciones contenidas en el “if”, si es falsa y la instrucción tiene un “else” entonces se ejecutan las instrucciones contenidas en el “else”. Esta instrucción soporta anidamiento. Expresiones aritméticas: Estas expresiones soportan sumas, restas, divisiones, multiplicaciones, expresiones negativas y paréntesis para agrupar operaciones. Tiene la precedencia habitual de las expresiones aritméticas. Expresiones booleanas: comparan dos expresiones que tengan como resultado un número y soportan únicamente los operadores mayor que y menor que (&lt;, &gt;). El resultado de la ejecuciónAl ejecutar el archivo de entrada mostrado anteriormente se obtiene el siguiente resultado en consola: 12345678910111213141516171819202122232425262728293031323334353637run:Tablas de multiplicar----------------1.0 * 1.0 = 1.01.0 * 2.0 = 2.01.0 * 3.0 = 3.01.0 * 4.0 = 4.01.0 * 5.0 = 5.0----------------2.0 * 1.0 = 2.02.0 * 2.0 = 4.02.0 * 3.0 = 6.02.0 * 4.0 = 8.02.0 * 5.0 = 10.0----------------3.0 * 1.0 = 3.03.0 * 2.0 = 6.03.0 * 3.0 = 9.03.0 * 4.0 = 12.03.0 * 5.0 = 15.0----------------4.0 * 1.0 = 4.04.0 * 2.0 = 8.04.0 * 3.0 = 12.04.0 * 4.0 = 16.04.0 * 5.0 = 20.0----------------5.0 * 1.0 = 5.05.0 * 2.0 = 10.05.0 * 3.0 = 15.05.0 * 4.0 = 20.05.0 * 5.0 = 25.0----------------a es mayor que 10.a es mayor que 10 y b es mayor que 11.a es mayor que 10, b es mayor que 11 y c es mayor que 12.BUILD SUCCESSFUL (total time: 0 seconds) Sobre la tabla de símbolosLa tabla de símbolos es una parte importante en el proceso de ejecución del código, es en esta estructura de datos en donde guardamos información de las variables como su tipo, identificador y valor. A esta estructura podemos pedirle el valor de una variable, o pedirle que le asigne cierto valor a una variable. Es importante mencionar que en el proceso de ejecución la tabla de símbolos va cambiando de forma dinámica, esto con el objetivo de manejar los ámbitos, por ejemplo, la instrucción WHILE tiene su propio ámbito, lo que significa que su tabla de símbolos contiene información de las variables declaradas en ámbitos superiores y la información de las variables declaradas en el ámbito local de la instrucción, al terminar de ejecutar la instrucción, todas las variables declaradas en el ámbito local se eliminan de la tabla de símbolos que almacena la información de los ámbitos superiores, de tal manera que los ámbitos superiores no tendrán acceso a las variables declaradas dentro del WHILE. La magia detrás de todo esto: Árbol de sintaxis abstracta (AST)Un árbol de sintaxis abstracta (AST) es una representación simplificada de la estructura sintáctica del código fuente. A nivel de programación un AST es una estructura de datos que se genera durante el proceso de análisis sintáctico. En este ejemplo el AST es la pieza más importante porque al recorrerlo pueden ejecutarse las acciones del código de entrada y ese es el principal objetivo de la aplicación. En el código fuente de Cup se observa que la mayoría de las acciones se enfocan en cargar el AST, básicamente es lo único que hace el analizador, además de verificar que la sintaxis de la entrada sea correcta La estructura en este caso es un tanto compleja ya que cada nodo puede tener muchos hijos, en el caso de las instrucciones IF-ELSE y WHILE, el número de hijos es incierto ya que estas instrucciones pueden contener muchas otras instrucciones dentro, lo cierto es que el árbol se acopla muy bien al lenguaje de programación porque en el árbol se tiene bien claro qué instrucciones están contenidas dentro de otras instrucciones, porque cada nodo esta directamente ligado a sus hijos, entonces la ejecución de instrucciones anidadas no representa mayor problema. Hacemos análisis sintáctico una sola vez para cargar el árbol, posteriormente recorremos ese árbol para ejecutar el código. El árbol es una representación exacta de lo que el código de entrada contiene. Las únicos tres paquetes del proyecto son: analizadores: que contiene los archivos de Cup y JLex y los analizadores que con estas herramientas se generaron. arbol: que contiene todas las clases que forman parte del AST, que se utiliza como estructura primaria en la aplicación. interpretesencillo: que contiene la clase principal de la aplicación. Fuentes consultadas:Compiladores, principios, técnicas y herramientas. Aho, Lam, Sethi y Ullman. Segunda Edición.","link":"/2019/04/26/05-Interprete-sencillo-utilizando-Java-Jlex-y-Cup/"},{"title":"Chat con Sockets en Java","text":"El chat que se muestra en esta publicación utiliza sockets para la comunicación, se desarrolló utilizando Java 1.8 y NetBeans 8.0. El ejemplo está formado por dos aplicaciones, el cliente y el servidor, ambas pueden descargarse de los siguientes enlaces: Chat con Sockets en Java (Servidor). Chat con Sockets en Java (Cliente). Todo el código dentro ambos proyectos está documentado con comentarios que explican su funcionamiento. Funcionamiento del chatPara que el chat funcione correctamente, debe ejecutarse primero la aplicación servidor, en la que el cliente debe ingresar el puerto por el cual el servidor escuchara las conexiones de los clientes que participen en el chat. Puede dejarse el puerto por defecto o puede indicarse uno diferente, que no esté siendo utilizado por ninguna otra aplicación. Si el servidor inicia correctamente se mostrará una ventana como la siguiente. En este punto ya podremos ejecutar aplicaciones cliente que se conecten al chat, al ejecutar la aplicación cliente nos pedirá la IP de la máquina en la que se ejecuta la aplicación servidor, por defecto tiene la dirección de localhost, en este caso se utiliza esta porque el servidor y todos los clientes se están ejecutando en la misma máquina. Además de la dirección IP, se debe ingresar el puerto por el que el servidor escucha las conexiones de los clientes y el nombre del usuario que se desea conectar. Si la conexión es correcta, entonces se muestra una ventana que tiene una JTextArea en la que se muestra el historial de las conversaciones, un JComboBox que muestra el listado de los usuarios conectados a los que se puede enviar mensajes, un JTextField en el que se puede ingresar los mensajes a enviar y un JButton para enviar el mensaje. Si solamente está conectado un cliente, no habrá nadie a quien se le pueda enviar mensajes, si el cliente intentara enviar uno se mostraría el siguiente mensaje de información. Al ejecutar más de un cliente estos ya podrán comunicarse entre sí. Luego de que los clientes envíen y reciban múltiples mensajes se tiene algo como lo siguiente. Si se cierran las ventanas, la aplicación cliente considerará que el usuario está cerrando sesión y enviará una notificación al servidor para elimine a este cliente de la lista de clientes y notifique al resto de los usuarios conectados que deben eliminarlo de su lista de contactos. En la aplicación servidor se muestra un log, en el que se informa cuando un usuario inicia o cierra sesión. Si el servidor se cierra repentinamente, mientras aún hay clientes conectados, estas aplicaciones cliente se cerrarán luego de mostrar el siguiente mensaje. Si se intenta ejecutar una aplicación cliente sin haber ejecutado antes la aplicación servidor o se ingresa una dirección IP o un puerto equivocado se mostrará el siguiente mensaje. Lógica del chatEl chat consiste de dos aplicaciones, el cliente y el servidor, el servidor se ejecuta una vez y el cliente se ejecuta N veces, donde N es el número de usuarios que participarán en el chat, todos los mensajes que los usuarios del chat se envían entre sí pasan a través del servidor, cuando un cliente quiere enviar un mensaje a otro, le envía el mensaje al servidor indicándole su destinatario y el servidor se encarga de reenviar este mensaje, el servidor también se encarga de indicarle a todos los usuarios cuando un usuario nuevo se conecta al chat, para que puedan incluirlo en su lista de contactos y por ende en la conversación. Asimismo, cuando un cliente se desconecta, el servidor se encarga de informar a todos los usuarios que deben eliminar al cliente que cerró su sesión de la lista de contactos porque ya no podrán enviarle mensajes. No hay comunicación directa entre clientes, el servidor siempre es intermediario entre la comunicación de los clientes. Si se ejecutara el servidor y luego se ejecutaran cuatro clientes que se conectaran a dicho servidor, la comunicación sería como se muestra en la siguiente imagen. Funcionamiento del servidorEl servidor tiene tres clases, que se describen a continuación: VentanaS: esta clase gestiona la interfaz gráfica del servidor, que básicamente muestra un log de las principales acciones del servidor (conexión y desconexión de clientes). Servidor: Esta clase gestiona a los clientes que se conectan al servidor, es un hilo que tiene como principal función escuchar constantemente en caso de que algún nuevo cliente quiera conectarse al chat. HiloCliente: Cada vez que un nuevo cliente se conecta, dentro de la clase servidor se instancia un nuevo *HiloCliente *y se agrega a la lista de clientes. Este hilo cuenta con un socket con el que puede enviar y recibir mensajes del cliente con el que está conectado y tiene como principal función escuchar constantemente en caso de que el cliente envíe mensajes. A continuación se muestra una imagen que ilustra el funcionamiento de la aplicación servidor. Funcionamiento del clienteEl cliente tiene dos clases, que se describen a continuación: VentanaC: esta clase gestiona la interfaz gráfica del servidor, que básicamente muestra una lista de contactos, un historial de conversación, una caja de texto para ingresar nuevos mensajes y un botón que permite enviar mensajes. Cliente: Cuando el cliente se instancia y se conecta con el servidor, se crea un hilo que está escuchar constantemente en caso de que el servidor envíe mensajes. Este cliente cuenta con un socket con el que puede enviar y recibir mensajes del servidor con el que está conectado. A continuación se muestra una imagen que ilustra el funcionamiento de la aplicación cliente.","link":"/2019/04/26/06-Chat-con-Sockets-en-Java/"},{"title":"Graficar expresiones aritméticas con Graphviz, Java, Jlex y Cup","text":"En este tutorial se desarrolla un ejemplo sencillo de un intérprete que recibe como entrada un archivo de texto que contiene varias expresiones aritméticas que son evaluadas y posteriormente graficadas por Graphviz, para ello se hace análisis léxico y sintáctico de dicha entrada, los analizadores se generan con Jlex y Cup. Es importante mencionar que para que el ejemplo funcione correctamente debe estar instalado Graphviz. Para desarrollar el proyecto se utilizó Ubuntu 14.04 y Netbeans 8.0. El proyecto completo del ejemplo puede descargarse del siguiente enlace: Graficar expresiones aritméticas con Graphviz, Java, Jlex y Cup Todo el código dentro del proyecto está documentado con comentarios que contienen explicaciones sobre su funcionamiento. Si desean, una pequeña introducción al uso de Jlex y Cup pueden visitar alguno de mis posts: Mi primer proyecto utilizando Jlex y Cup (Linux) Mi primer proyecto utilizando Jlex y Cup (Windows) Instalación de GraphvizLo primero que haremos será instalar Graphviz, para ello abrimos una terminal, en Ubuntu puede hacerse con la combinación de teclas Ctrl+Alt+t o en Aplicaciones → Accesorios → Terminal, una vez abierta la terminal ingresamos el comando “sudo apt-get install graphviz”, autenticamos ingresando nuestra contraseña y aceptamos la descarga e instalación, con esto quedará instalado Graphviz. Funcionamiento del proyectoLa aplicación recibe como entrada un archivo que se encuentra en la carpeta del proyecto, dicho archivo se llama “entrada.txt” y contiene lo siguiente: 12345Evaluar[1+1];Evaluar[1+1*2];Evaluar[1.5+1.25*6.4/3.3-5.2+7.1];Evaluar[1.1+1.2*6.3/3.4-5+1*-2.12345];Evaluar[(2+2)*3+(1-1)]; Al ejecutar la aplicación, esta le hace análisis léxico y sintáctico al archivo de entrada, evalúa las expresiones aritméticas e indica el resultado de la expresión y el nombre del archivo en el que se generó la imagen. Veremos que se generan una serie de archivos .dot y una serie de archivos .jpg, los archivos dot, contienen el código con el que Graphviz genera la imagen jpg correspondiente. A continuación se muestra el detalle de las imágenes que se generaron para cada línea del archivo de entrada. 1Evaluar[1+1]; 1Evaluar[1+1*2]; 1Evaluar[1.5+1.25*6.4/3.3-5.2+7.1]; 1Evaluar[1.1+1.2*6.3/3.4-5+1*-2.12345]; 1Evaluar[(2+2)*3+(1-1)]; La magia detrás de todo esto: Árbol de sintaxis abstracta (AST)Un árbol de sintaxis abstracta (AST) es una representación simplificada de la estructura sintáctica del código fuente. A nivel de programación un AST es una estructura de datos que se genera durante el proceso de análisis sintáctico. En este ejemplo el AST es la pieza más importante porque con él pueden ejecutarse las principales funciones que son: evaluar la expresión y graficar la expresión. En este ejemplo el AST se construye al hacer análisis sintáctico al archivo de entrada, esta estructura es un árbol binario, ya que cada nodo puede tener como máximo dos hijos y modela bien el funcionamiento de las expresiones aritméticas porque todas sus operaciones tienen dos operandos y el caso del operador “-” de las expresiones negativas que tiene un solo operando. Hacemos análisis sintáctico una sola vez para cargar el árbol, posteriormente podemos recorrer ese árbol las veces que deseemos, podemos manipularlo y hacer muchas cosas sin necesidad de hacer nuevamente análisis sintáctico al archivo de entrada. En este caso, el árbol se carga y posteriormente se recorre para evaluar la expresión aritmética y mostrar en consola el resultado. Se recorre nuevamente el árbol para generar el código de Graphviz y guardarlo en un archivo .dot, con el archivo .dot podemos pedirle a Graphviz que cree el diagrama de la expresión aritmética. Todos los métodos que realizan estas acciones luego de cargar el árbol se encuentran en la clase “Nodo”, del paquete “arbol”. El método getValor, devuelve el resultado de la expresión aritmética evaluada. El método graficar, genera el diagrama de la expresión aritmética y devuelve el nombre del archivo generado. Si les gusto este tutorial, puede que también estén interesados en este otro: Intérprete sencillo utilizando Java, Jlex y Cup Fuentes consultadas:Compiladores, principios, técnicas y herramientas. Aho, Lam, Sethi y Ullman. Segunda Edición.","link":"/2019/04/26/07-Graficar-expresiones-aritmeticas-con-Graphviz-Java-Jlex-y-Cup/"},{"title":"Graficar árboles AVL con Graphviz y Java","text":"En este tutorial se desarrolla un ejemplo sencillo en el que se grafica un árbol AVL con ayuda de la herramienta Graphviz. Es importante mencionar que para que ejemplo funcione correctamente debe estar instalado Graphviz. Este proyecto se desarrolló utilizando Ubuntu 14.04 y Netbeans 8.0. El proyecto completo del ejemplo puede descargarse del siguiente enlace: Graficar árboles AVL con Graphviz y Java. Todo el código dentro del proyecto está documentado con comentarios que contienen explicaciones sobre su funcionamiento. Instalación de GraphvizLo primero que haremos será instalar Graphviz, en caso de que no lo hayamos instalado todavía, para ello abrimos una terminal, en Ubuntu puede hacerse con la combinación de teclas Ctrl+Alt+t o en Aplicaciones → Accesorios → Terminal, una vez abierta la terminal ingresamos el comando “sudo apt-get install graphviz”, autenticamos ingresando nuestra contraseña y aceptamos la descarga e instalación, con esto quedará instalado Graphviz. Funcionamiento del proyectoEl proyecto cuenta con la clase ArbolAVL, en el método principal de la aplicación, se instancian dos objetos de esta clase, es decir, dos árboles AVL, el primero almacena únicamente texto y el segundo únicamente números. El código de la clase principal de la aplicación es el siguiente: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768/* * Ejemplo desarrollado por Erick Navarro * GitHub Page: ericknavarro.github.io * Octubre - 2015 */package avlgraphviz;import avl.ArbolAVL;/** * Clase principal de la aplicación. * @author Erick Navarro */public class AVLGraphviz { /** * Método principal de la aplicación * @param args los argumentos de la línea de comando. */ public static void main(String[] args) { //Creamos un árbol cuyos nodos contendrán solamente texto ArbolAVL arbol_texto=new ArbolAVL(); //Llenamos con información el árbol arbol_texto.insertar(&quot;Juan&quot;); arbol_texto.insertar(&quot;Pedro&quot;); arbol_texto.insertar(&quot;María&quot;); arbol_texto.insertar(&quot;Roberto&quot;); arbol_texto.insertar(&quot;Teodoro&quot;); arbol_texto.insertar(&quot;Manuel&quot;); arbol_texto.insertar(&quot;Diego&quot;); arbol_texto.insertar(&quot;Alejandro&quot;); arbol_texto.insertar(&quot;Margarita&quot;); arbol_texto.insertar(&quot;Luis&quot;); arbol_texto.insertar(&quot;Hernán&quot;); arbol_texto.insertar(&quot;Jaime&quot;); arbol_texto.insertar(&quot;Ana&quot;); arbol_texto.insertar(&quot;Francisco&quot;); arbol_texto.insertar(&quot;Andrea&quot;); //Graficamos el árbol generando la imagen arbol_texto.jpg arbol_texto.graficar(&quot;arbol_texto.jpg&quot;); //Imprimimos el contenido del árbol ordenado arbol_texto.inorden(); System.out.println(); //Creamos un árbol cuyos nodos contendrán solamente numeros ArbolAVL arbol_numeros=new ArbolAVL(); //Llenamos con información el árbol arbol_numeros.insertar(12); arbol_numeros.insertar(5); arbol_numeros.insertar(26); arbol_numeros.insertar(33); arbol_numeros.insertar(59); arbol_numeros.insertar(27); arbol_numeros.insertar(15); arbol_numeros.insertar(47); arbol_numeros.insertar(74); arbol_numeros.insertar(84); arbol_numeros.insertar(88); arbol_numeros.insertar(90); arbol_numeros.insertar(124); arbol_numeros.insertar(612); //Graficamos el árbol generando la imagen arbol_numeros.jpg arbol_numeros.graficar(&quot;arbol_numeros.jpg&quot;); //Imprimimos el contenido del árbol ordenado arbol_numeros.inorden(); } } Al ser ejecutada la aplicación, se generan dos imagenes, una para cada árbol la primera arbol_texto.jpg corresponde al árbol que solo almacena texto en sus nodos. La segunda arbol_numeros.jpg corresponde al árbol que solo almacena números. En la consola se verán los elementos de ambos árboles impresos en orden, esto se logra haciendo un recorrido enorden de los arboles AVL. Árbol AVLEl árbol AVL es un árbol binario de búsqueda equilibrado. Recibió el nombre del árbol AVL en honor de Adelson, Velskii y Landis, que fueron los primeros científicos en estudiar esta estructura de datos. “Un árbol AVL es un árbol binario de búsqueda en el que las alturas de los subárboles izquierdo y derecho de cualquier nodo difieren como máximo en 1.” Fuente: Algoritmos y estructuras de datos, una perspectiva en C. Luis Joyanes Aguilar, Ignacio Zahonero Martínez. En este árbol únicamente se desarrolla el método para insertar nodos, porque el objetivo de la aplicación es únicamente graficar el árbol, adicionalmente, podrían desarrollarse métodos para eliminar nodos, buscar nodos, vaciar el árbol, calcular la profundidad del árbol, etc. El único recorrido que se hace del árbol es el enorden, que muestra los nodos del árbol ordenados, pero existen otros recorridos que también podrían implementarse como el recorrido preorden, postorden o el recorrido por anchura. Interfaz Comparable: El secreto tras la flexibilidad de este árbolLa razón por la cual este árbol puede utilizarse para almacenar cadenas o bien para almacenar números es la interfaz Comparable. Lo que almacena el nodo es la instancia de una clase que implementa la interfaz Comparable, por supuesto que todos los nodos tienen que poder compararse satisfactoriamente, por ejemplo no se podrían almacenar números enteros y también cadenas de caracteres en un mismo árbol, ya que no podrían comparase satisfactoriamente porque se daría un problema de tipos. Pero si todos los nodos almacenan números, el árbol funciona sin problemas, al igual cuando todos los nodos almacenan cadenas. Si deseáramos almacenar otro tipo de información podríamos programar una clase que contenga los atributos que deseamos y que implemente la interfaz Comparable, entonces sin modificar el árbol podríamos almacenar esta información. Fuentes consultadasAlgoritmos y estructuras de datos, una perspectiva en C. Luis Joyanes Aguilar, Ignacio Zahonero Martínez.","link":"/2019/04/26/08-Graficar-arboles-AVL-con-Graphviz-y-Java/"},{"title":"Graficar árboles binarios de búsqueda con Graphviz y Java","text":"En este tutorial se desarrolla un ejemplo sencillo en el que se grafica un árbol binario de búsqueda con ayuda de la herramienta Graphviz. Es importante mencionar que para que ejemplo funcione correctamente debe estar instalado Graphviz. Este proyecto se desarrolló utilizando Ubuntu 14.04 y Netbeans 8.0. El proyecto completo del ejemplo puede descargarse del siguiente enlace: Graficar árboles binarios de búsqueda con Graphviz y Java. Todo el código dentro del proyecto está documentado con comentarios que contienen explicaciones sobre su funcionamiento. Instalación de GraphvizLo primero que haremos será instalar Graphviz, en caso de que no lo hayamos instalado todavía, para ello abrimos una terminal, en Ubuntu puede hacerse con la combinación de teclas Ctrl+Alt+t o en Aplicaciones → Accesorios → Terminal, una vez abierta la terminal ingresamos el comando “sudo apt-get install graphviz”, autenticamos ingresando nuestra contraseña y aceptamos la descarga e instalación, con esto quedará instalado Graphviz. Funcionamiento del proyectoEl proyecto cuenta con la clase ArbolBinarioBusqueda, en el método principal de la aplicación, se instancian dos objetos de esta clase, es decir, dos árboles binarios de búsqueda, el primero almacena únicamente texto y el segundo únicamente números. El código de la clase principal de la aplicación es el siguiente: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/* * Ejemplo desarrollado por Erick Navarro * GitHub Page: ericknavarro.github.io * Octubre - 2015 */package abbgraphviz;import abb.ArbolBinarioBusqueda;/** * Clase principal de la aplicación. * @author Erick Navarro */public class ABBGraphviz { /** * Método principal de la aplicación * @param args los argumentos de la línea de comando */ public static void main(String[] args) { //Creamos un árbol cuyos nodos contendrán solamente texto ArbolBinarioBusqueda arbol_texto=new ArbolBinarioBusqueda(); //Llenamos con información el árbol arbol_texto.insertar(&quot;Juan&quot;); arbol_texto.insertar(&quot;Pedro&quot;); arbol_texto.insertar(&quot;María&quot;); arbol_texto.insertar(&quot;Roberto&quot;); arbol_texto.insertar(&quot;Teodoro&quot;); arbol_texto.insertar(&quot;Manuel&quot;); arbol_texto.insertar(&quot;Diego&quot;); arbol_texto.insertar(&quot;Alejandro&quot;); //Graficamos el árbol generando la imagen arbol_texto.jpg arbol_texto.graficar(&quot;arbol_texto.jpg&quot;); //Imprimimos el contenido del árbol ordenado arbol_texto.inorden(); System.out.println(); //Creamos un árbol cuyos nodos contendrán solamente numeros ArbolBinarioBusqueda arbol_numeros=new ArbolBinarioBusqueda(); //Llenamos con información el árbol arbol_numeros.insertar(12); arbol_numeros.insertar(5); arbol_numeros.insertar(26); arbol_numeros.insertar(33); arbol_numeros.insertar(59); arbol_numeros.insertar(27); arbol_numeros.insertar(15); //Graficamos el árbol generando la imagen arbol_numeros.jpg arbol_numeros.graficar(&quot;arbol_numeros.jpg&quot;); //Imprimimos el contenido del árbol ordenado arbol_numeros.inorden(); } } Al ser ejecutada la aplicación, se generan dos imagenes, una para cada árbol la primera *arbol_texto.jpg *corresponde al árbol que solo almacena texto en sus nodos. La segunda arbol_numeros.jpg corresponde al árbol que solo almacena números. En la consola se verán los elementos de ambos árboles impresos en orden, esto se logra haciendo un recorrido enorden de los arboles binarios de búsqueda. Árbol binario de búsquedaEn un árbol binario, todos los nodos tienen como máximo dos hijos. “Un árbol binario de búsqueda es aquel que dado un nodo, todos los datos del subárbol izquierdo son menores que los datos de ese nodo, mientras que todos los datos del subárbol derecho son mayores que sus propios datos.” Fuente: Programación en Java 2. Luis Joyanes Aguilar, Ignacio Zahonero Martínez. En este árbol únicamente se desarrolla el método para insertar nodos, porque el objetivo de la aplicación es únicamente graficar el árbol, adicionalmente, podrían desarrollarse métodos para eliminar nodos, buscar nodos, vaciar el árbol, calcular la profundidad del árbol, etc. El único recorrido que se hace del árbol es el enorden, que muestra los nodos del árbol ordenados, pero existen otros recorridos que también podrían implementarse como el recorrido preorden, postorden o el recorrido por anchura. Interfaz Comparable: El secreto tras la flexibilidad de este árbolLa razón por la cual este árbol puede utilizarse para almacenar cadenas o bien para almacenar números es la interfaz Comparable. Lo que almacena el nodo es la instancia de una clase que implementa la interfaz Comparable, por supuesto que todos los nodos tienen que poder compararse satisfactoriamente, por ejemplo no se podrían almacenar números enteros y también cadenas de caracteres en un mismo árbol, ya que no podrían comparase satisfactoriamente porque se daría un problema de tipos. Pero si todos los nodos almacenan números, el árbol funciona sin problemas, al igual cuando todos los nodos almacenan cadenas. Si deseáramos almacenar otro tipo de información podríamos programar una clase que contenga los atributos que deseamos y que implemente la interfaz Comparable, entonces sin modificar el árbol podríamos almacenar esta información. Fuentes consultadas:Programación en Java 2. Algoritmos, estructuras de datos y programación orientada a objetos. Luis Joyanes Aguilar, Ignacio Zahonero Martínez.","link":"/2019/04/26/09-Graficar-arboles-binarios-de-busqueda-con-Graphviz-y-Java/"},{"title":"Publicar un sitio estático en Amazon S3","text":"Amazon Simple Storage Service (Amazon S3) es un servicio de almacenamiento de objetos que ofrece escalabilidad, disponibilidad de datos, seguridad y rendimiento líderes en el sector. Un beneficio importante de S3 es la posibilidad de publicar sitios estáticos, sitios para los que no tenemos que configurar un servidor web, sitios serverless. Lo primero es buscar el servicio S3 en la consola de AWS. Los sitios estáticos que son publicados en S3 deben tener su propio bucket, por lo que crearemos uno para nuestro sitio, hacemos click en create bucket. En el asistente de creación del bucket: Name and Region: Indicamos el nombre del bucket, en mi caso es ericknavarro.io, este nombre debe ser único en todo el universo de buckets de AWS, puede que el nombre del bucket ya exista, si es ese el caso recibiremos un mensaje de error y tendremos que modificar el nombre del bucket, dejamos los valores por defecto para el resto de opciones. Configure options: Dejamos los valores por defecto para estas opciones. Set permissions: Nos aseguramos que las restricciones para asignar permisos publicos no estén chequeadas, estas opciones aparecen en la siguiente imagen encerradas en dos recuadros amarillos, podemos dejar las opciones de configuración por defecto. Review: Validamos que toda la configuración realizada corresponda con lo que necesitamos y creamos el bucket. Una vez creado el bucket veremos una imagen como la siguiente en nuestra consola, hacemos click en el bucket e incresamos a las opciones. Una vez dentro nos movemos a la pestaña de Properties y hacemos click en la sección Static website hosting. Una vez dentro se nos indica el Endpoint que es la URL con la que llegamos al sitio publicado, además tenemos que indicar el nombre de nuestro documento index y de nuestro documento error, en nuestro caso se llamarán index.html y error.html, pero podrían ser otros documentos con nombres diferentes. 12Endpoint:[http://ericknavarro.io.s3-website-us-east-1.amazonaws.com/](http://ericknavarro.io.s3-website-us-east-1.amazonaws.com/) Posteriormente nos movemos a la pestaña de permisos y configuraremos una política en la pestaña Bucket Policy para que todos los archivos que se carguen al bucket sean públicos, esta política será: 123456789101112{ &quot;Version&quot;: &quot;2012-10-17&quot;, &quot;Statement&quot;: [ { &quot;Sid&quot;: &quot;PublicReadGetObject&quot;, &quot;Effect&quot;: &quot;Allow&quot;, &quot;Principal&quot;: &quot;*&quot;, &quot;Action&quot;: &quot;s3:GetObject&quot;, &quot;Resource&quot;: &quot;arn:aws:s3:::**ericknavarro.io**/*&quot; } ]} Es importante cambiar el nombre del bucket dentro de la política, en este caso el nombre de mi bucket es ericknavarro.io, pero este debe reemplazarse con el nombre del bucket que se usará para publicar el sitio. Ahora procedemos a cargar los archivos HTML de nuestra página estática, en primero es index.html, que es nuestra página principal: 12345678910&lt;!doctype html&gt;&lt;html lang=&quot;es&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;title&gt;Erick Navarro&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;Esta es una página estática publicada en S3.&lt;/h1&gt; &lt;/body&gt;&lt;/html&gt; El segundo es error.html, que es una página secundaria a la que se redirigirá ante cualquier error, por ejemplo, que el usuario intente ingresar a una página inexistente dentro del bucket: 12345678910&lt;!doctype html&gt;&lt;html lang=&quot;es&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;title&gt;Erick Navarro&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;Hemos tenido un error.&lt;/h1&gt; &lt;/body&gt;&lt;/html&gt; En nuestro bucket tenemos la opción de cargar archivos (Upload) en la vista Overview: Seleccionamos los archivos Tendremos nuestro sitio cargado Visitamos el endpoint de nuestra página: 12Endpoint:[http://ericknavarro.io.s3-website-us-east-1.amazonaws.com/](http://ericknavarro.io.s3-website-us-east-1.amazonaws.com/) Podremos observar el contenido de la página index.html. Luego de intentar ingresar a una página que no existe en nuestro sitio, S3 nos redirige a la página de error que publicamos: Con lo anterior tenemos nuestro sitio estático publicado en S3. Si quieres asignar un dominio personalizado a tu sitio, revisa mi post: Agregar un dominio personalizado a tu sitio utilizando Amazon Route 53","link":"/2019/05/02/10-Publicar-un-sitio-estatico-en-Amazon-S3/"},{"title":"Agregar un dominio personalizado a tu sitio utilizando Amazon Route 53","text":"En este tutorial se asume que tienes un sitio estático publicado en S3, al que deseas apuntar un dominio personalizado. Si quieres saber más sobre este tema, puedes revisar mi post: Publicar un sitio estático en Amazon S3. Para agregar un dominio personalizado a nuestro sitio, utilizaremos el servicio Amazon Route 53. Lo primero es buscar el servicio Route 53 en la consola de AWS. Una vez dentro de la consola Route 53, escribimos el nombre de dominio que deseamos comprar, presionamos check y verificamos su existencia. Si no estuviera disponible, AWS nos recomendará otros dominios similares disponibles. Luego de comprarlo vamos a Registered domains, en donde encontraremos el dominio comprado. Posteriormente vamos a hosted zones, encontraremos una hosted zone para nuestro dominio, ingresamos al hosted zone de nuestro dominio. Una vez dentro encontraremos la configuración actual de nuestro dominio, para hacer que nuestro dominio apunte hacia el bucket de S3 que contiene nuestro sitio debemos crear un nuevo Record Set. Dentro del wizard, configuramos un Record Set de tipo A, que sea un alias cuyo target sea nuestro bucket de S3 que almacena el sitio estático, si entramos en este campo, nuestro bucket debería aparecer en el listado. &nbsp; &nbsp; Una vez creado el record set, ya podemos cargar nuestra página estática mediante el nombre de dominio que compramos. Vemos que la página de error funciona correctamente siempre sobre el dominio configurado. Con esto nuestro sitio estático está listo con un dominio personalizado.","link":"/2019/05/06/11-Agregar-un-dominio-personalizado-a-tu-sitio-utilizando-Amazon-Route-53/"},{"title":"Servir un sitio estático a través de HTTPS utilizando S3, Route 53, Certificate Manager y CloudFront","text":"En este tutorial se utilizarán las siguientes tecnologías: AWS S3: Almacenamiento en la nube en el que alojaremos nuestro sitio estático. AWS Route 53: DNS que resolverá el dominio personalizado que utilizaremos en nuestro sitio. AWS Certificate Manager: Servicio con el que obtendremos el certificado SSL/TLS público que será utilizado para servir el sitio a través de HTTPS. AWS CloudFront: Servicio CDN con el que serviremos nuestro contenido, es decir, nuestra página no será servida directamente de S3. Para desarrollar este tutorial es necesario que ya hayan completado los siguientes tutoriales: Publicar un sitio estático en Amazon S3 Agregar un dominio personalizado a tu sitio utilizando Amazon Route 53 O bien, que tengas un sitio estático publicado en S3 y un dominio registrado en Route 53. 1. Obtener el certificado SSL/TLS público que será utilizado para servir el sitio a través de HTTPS.Buscamos el servicio AWS Certificate Manager en nuestra consola. Una vez dentro seleccionamos **Get Started **para obtener nuestro primer certificado. Pedimos un certificado publico para nuestro sitio, estos son gratuitos en AWS. Ingresamos los records para nuestro dominio. Seleccionamos DNS validation. Confirmamos nuestros datos y hacemos la solicitud. Luego nos aparecen pendientes de validación ambos records. Procedemos a crear los records que nos solicitan en Route 53 para validar que somos dueños del dominio en cuestión. Creamos el record. Luego de crearlo tenemos que esperar algun tiempo para que la validación se haga efectiva. Al finalizar tendremos ambos records validados y nuestro certificado podrá ser utilizado. 2. Configurar nuestro CDN en AWS CloudFrontEn la consola de AWS buscamos el servicio Cloudfront. Una vez dentro seleccionamos Create Distribution para crear nuestro primer CDN. Seleccionamos Get Started en el segmento de Web distribution, pues es una distribución de este tipo la que queremos crear. Ingresamos el nombre en Origin Domain Name y automáticamente se asignará un Origin ID, podemos dejar ese que se asigne, este es un nombre que nos permitira identificar el origen dentro de la distribución. Seleccionamos la opción Restrict Bucket Access: Yes, esto hará que nuestro bucket que inicialmente era público deje de serlo para que podamos acceder a los archivos del bucket solamente a través de nuestro CDN, de nuestra distribución de CloudFront. Seleccionamos Origin Access Identity: Create a New Identity, esto creará un identificador que se usará para crear una política en S3 que permita a nuestro CDN acceder a los recursos de S3, que ya no serán públicos debido a la configuración anterior. Seleccionamos Grant Read Permissions on Bucket: Yes, Update Bucket Policy, esta opción actualizará la política de nuestro bucket y la cambiará para que deje de ser público y comience a ser solamente accesible para nuestro CDN. En la configuración Viewer Protocol Policy, seleccionamos la opción Redirect HTTP to HTTPS, pues este el principal objetivo en este tutorial, servir la página con a través de HTTPS. En la configuración Compress Objects Automatically seleccionamos la opción Yes. En la sección Distribution Settings, hacemos lo siguiente: Configuramos nuestros nombres de dominio en la opción **Alternate Domain Names **(En este caso agregaré ericknavarro.io, y adicionalmente www.ericknavarro.io, para que también funcione con esta dirección). Configuramos el certificado SSL generado anteriormente seleccionando Custom SSL Certificate (example.com), al entrar en la caja de texto nos lo desplegará automáticamente y podremos seleccionarlo: Configuramos en Default Root Object, nuestra página principal, en este caso index.html. El resto de configuraciones las dejamos con sus valores por defecto y procedemos a hacer click en Create Distribution. Al finalizar la creación, el status será Deployed y el state será Enabled. Al visitar el nombre de dominio, que en este caso es: 1d22ckq6fuymrpu.cloudfront.net Veremos nuestra página, que está siendo servida a través de HTTPS: 3. Apuntar nuestro dominio hacia el CDN creadoLo primero es buscar el servicio Route 53 en la consola de AWS. Posteriormente vamos a hosted zones, encontraremos una hosted zone para nuestro dominio, ingresamos a él haciendo click en su identificador. Una vez dentro encontraremos la configuración actual, en mi caso tenía un record set que apuntaba directamente a S3, eliminé ese record set y procedí a crear uno nuevo, para ello hacemos click en Create Record Set. Dentro del wizard, configuramos un Record Set de tipo A, que sea un alias cuyo target sea nuestro CDN de CloudFront, si entramos en este campo, nuestro CDN debería aparecer en el listado. Hacemos click en Create y listo, tenemos creado el primer record set. Es necesario que creemos 3 record sets más, hasta completar los siguientes 4 recordsets, los A para IPv4 y los AAAA para IPv6, en mi caso estos record sets quedarán de la siguiente manera: 12345Record Domain Alias TargetA | ericknavarro.io | d22ckq6fuymrpu.cloudfront.netAAAA | ericknavarro.io | d22ckq6fuymrpu.cloudfront.netA | www.ericknavarro.io | d22ckq6fuymrpu.cloudfront.netAAAA | www.ericknavarro.io | d22ckq6fuymrpu.cloudfront.net Al finalizar tendremos algo como lo siguiente: Si consultamos nuevamente nuestro dominio ericknavarro.io, podremos observar que la página ya está siendo servida a través de HTTPS: En este momento hemos alcanzado nuestro objetivo, que era servir un sitio estático a través de HTTPS utilizando S3, Route 53, Certificate Manager y CloudFront. Algunas anotaciones sobre lo configurado: Si por algún motivo necesitaramos cambiar el contenido de la página, además de actualizar los archivos en S3, deberíamos hacer un invalidate en nuestra distribución, pues la distribución guarda en cache la información de la página y lo que nos muestra es siempre información que tiene cacheada, esta información se cachea la primera vez que accedemos a la página. Hacer un invalidate, se puede traducir a borrar la cache. Si vamos a nuestro bucket veremos que la política ha cambiado y el único recurso con permisos para acceder al bucket es nuestra distribución, lo que significa que el bucket ya no es público y no podemos acceder a él directamente desde el navegador, tenemos que hacerlo a través de nuestra distribución. Con esto hemos llegado al final de nuestro tutorial.","link":"/2019/05/13/12-Servir-un-sitio-estatico-a-traves-de-HTTPS-utilizando-S3-Route-53-Certificate-Manager-y-CloudFront/"},{"title":"Construcción de un sitio serverless simple con Route 53, API Gateway, Lambda y S3","text":"En este tutorial se creará un sitio serverless que consume una función Lambda sencilla. Para ello se utilizarán las siguientes tecnologías: AWS S3: Almacenamiento en la nube en el que alojaremos nuestro sitio estático. AWS Route 53: DNS que resolverá el dominio personalizado que utilizaremos en nuestro sitio. API Gateway: Servicio que actuará como “puerta delantera” para que las aplicaciones obtengan acceso a datos, lógica de negocio o funcionalidades desde sus servicios backend, en este caso, código ejecutado en AWS Lambda. AWS Lambda: Servicio que permite ejecutar código sin aprovisionar ni administrar servidores. Solo pagará por el tiempo informático que consuma. No se cobra nada cuando el código no se está ejecutando. 1. Creación del bucket que almacenará nuestra página webAbrimos la consola de S3. Creamos un nuevo bucket, nos aseguramos de que el nombre sea válido (que no exista en todo el universo de S3, un bucket con ese nombre). Nos aseguramos de remover las opciones que bloqueen la posibilidad de hacer el bucket público desmarcando estas restricciones. Una vez creado nuestro bucket hacemos click sobre su nombre para acceder a sus configuraciones. Nos dirigimos a la sección Static website hosting. Configuramos como página principal index.html y como página de error error.html. 2. Creación nuestra función lambdaAbrimos la consola de AWS Lambda. Creamos una nueva función con la opción Author from scratch. Colocamos un nombre a la función y escogemos Python como lenguaje de la función, en el momento del tutorial, está disponible Python 3.6 por lo que escogeré este. Incrustamos el código que devolverá la función, en este caso simplemente devuelve mi nombre. Con esto finalizamos la creación de nuestra función. 3. Creación nuestro API GatewayDentro de la barra izquierda en el segmento Add triggers, encontraremos API Gateway, lo seleccionamos. Seleccionamos el bloque recién creado. En la parte inferior veremos que tenemos que configurar el API Gateway. Seleccionamos Create a new API, en este caso para fines de prueba la seguridad seleccionada sera Open, colocamos el nombre de nuestro API y en Deployment stage colocamos prod, que sería la abreviatura de producción. Para el resto de configuraciones dejamos los valores por default. Guardamos los cambios en nuestra función. Al seleccionar el API y dirigirnos a la parte inferior veremos el API endpoint. Siempre en la parte inferior hacemos click sobre el nombre de nuestro API Gateway, para poder llegar a sus configuraciones. Seleccionamos el método ANY. Eliminamos el método ANY. Creamos un nuevo método. El nuevo método será GET. En las configuraciones del nuevo método, seleccionaremos Integration type: Lambda funcion, Use Lambda Proxy Integration: check. Nuestra Lambda region y el nombre de nuestra Lambda function. Nos preguntará si queremos dar permisos al API para acceder a nuestra función lambda, seleccionamos que sí estamos de acuerdo. Vamos nuevamente a acciones y seleccionamos Deploy API. En Depoyment stage: prod nuevamente y colocamos una descripción relacionada con nuestro deploy. Al finalizar nos indica un Invoke URL, que será utilizado para invocar la función. Si colocamos el URL en un navegador estaremos invocando el método GET de nuestro API Gateway y se nos mostrará el resultado de la función, que era mi nombre. Vamos al bucket que creamos index.html. 1234567891011121314151617181920212223242526&lt;html&gt; &lt;head&gt; &lt;script&gt; function myFunction() { var xhttp = new XMLHttpRequest(); xhttp.onreadystatechange = function() { if (this.readyState == 4 &amp;&amp; this.status == 200) { document.getElementById(&quot;my-demo&quot;).innerHTML = this.responseText; } }; xhttp.open(&quot;GET&quot;, &quot;YOUR-API-GATEWAY-LINK-HERE&quot;, true); xhttp.send(); } &lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;div align=&quot;center&quot;&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;h1&gt;Hola &lt;span id=&quot;my-demo&quot;&gt;lectores&lt;/span&gt;&lt;/h1&gt; &lt;button onclick=&quot;myFunction()&quot;&gt;Haz click&lt;/button&gt; &lt;/div&gt; &lt;/body&gt;&lt;/html&gt; Es importante que en index.html, reemplacemos YOUR-API-GATEWAY-LINK-HERE, por el enlace con el que invocamos a nuestra función lambda. Y error.html. 123456&lt;html&gt; &lt;head&gt;&lt;/head&gt; &lt;body&gt; &lt;h1&gt;¡Hemos tenido un problema!&lt;/h1&gt; &lt;/body&gt;&lt;/html&gt; Estos archivos se cargan con la opción Upload. Cargamos directamente, sin modificar ninguna configuración, dejamos todos los valores por default. Seleccionamos ambos archivos y los hacemos públicos. Confirmamos que queremos hacer los archivos públicos. Accedemos al endpoint de nuestra página. Se nos mostrará el saludo por defecto. Luego de hacer click en el botón se cambiará el saludo con mi nombre, que es el valor que devuelve nuestra función Lambda. 4. Personalizar el dominio de nuestra páginaPara personalizar el dominio de nuestra página debemos ir a la consola de Route 53. En Route 53 podemos comprar un dominio o transferir un dominio. Vamos a la sección Registered domains y podremos ver nuestro dominio. Vamos a la sección Hosted zones y hacemos click en el nombre de nuestro dominio para acceder a su configuración. Hacemos click en Create Record Set para asociar nuestro nombre de dominio a con nuestro sitio web. Creamos un record set de tipo A, escogemos la opción Alias y configuramos como Alias Target el nombre de nuestro S3 bucket. Procedemos a crear el Record Set. Con esto tenemos creado nuestro Record Set. Si ingresamos nuestro dominio en el navegador se desplegará nuestra página. Hacemos click y vemos que la función opera correctamente. Con esto hemos llegado al final de nuestro tutorial.","link":"/2019/05/15/13-Construccion-de-un-sitio-serverless-simple-con-Route-53-API-Gateway-Lambda-y-S3/"},{"title":"Creación de un CloudFront distribution","text":"En este tutorial se creará un CDN utilizando AWS CloudFront. Para ello se utilizarán las siguientes tecnologías: AWS CloudFront: Servicio CDN con el que serviremos nuestro contenido, es decir, nuestra página no será servida directamente de S3. AWS S3: Almacenamiento en la nube en el que alojaremos nuestros recursos. Lo primero es buscar el servicio S3 en la consola de AWS, una vez en la consola de S3, procedemos a crear un nuevo bucket, haciendo click en la opción Create Bucket. En el asistente de creación del bucket: Name and Region: Indicamos el nombre del bucket, en mi caso es 20190416-sydney-cloudfront-origin, este nombre debe ser único en todo el universo de buckets de AWS, puede que el nombre del bucket ya exista, si es ese el caso recibiremos un mensaje de error y tendremos que modificar el nombre del bucket, dejamos los valores por defecto para el resto de opciones. Además escogemos una región que geográficamente esté muy lejos de nosotros, en mi caso la región más alejada es la de Asia Pacific (Sydney). Configure options: Dejamos los valores por defecto para estas opciones. Set permissions: Nos aseguramos que las restricciones para asignar permisos publicos no estén chequeadas, estas opciones aparecen en la siguiente imagen encerradas en dos recuadros amarillos, podemos dejar las opciones de configuración por defecto. Review: Validamos que toda la configuración realizada corresponda con lo que necesitamos y creamos el bucket. Posteriormente procedemos a cargar una imagen en alta definición, haciendo click en el boton Upload, en mi caso cargué una fotografía de 4.3 MB. Dentro del asistente nos aseguramos de hacer público el archivo cargado. Continuamos con las siguientes fases del asistente dejando el resto de las configuraciones con sus valores por defecto. Hacemos click en el nombre de la imagen recién cargada y en el Overview del objeto veremos la URL con la que podemos acceder a él. Copiamos la URL y la pegamos en el navegador, veremos cómo la imagen carga lentamente, esto debido a que físicamente la región de Sydney está muy lejos de mí. Procedemos a crear nuestro CDN, para ello buscamos el servicio CloudFront en la consola de AWS, una vez en la consola de CloudFront, hacemos click en el boton Create Distribution. En la sección **Web, **hacemos click en el botón Get Started. Configuramos como Origen el bucket que recientemente creamos en la región de Sydney. Luego de seleccionar nuestro bucket para la opción Origin Domain Name, se asigna automáticamente un Origin ID, este es un nombre que nos permitirá identificar el origen dentro de la distribución. Seleccionamos la opción Restrict Bucket Access: Yes, esto hará que nuestro bucket que inicialmente era público deje de serlo para que podamos acceder a los archivos del bucket solamente a través de nuestro CDN, de nuestra distribución de CloudFront. Seleccionamos Origin Access Identity: Create a New Identity, esto creará un identificador que se usará para crear una política en S3 que permita a nuestro CDN acceder a los recursos de S3, que ya no serán públicos debido a la configuración anterior. Seleccionamos Grant Read Permissions on Bucket: Yes, Update Bucket Policy, esta opción actualizará la política de nuestro bucket y la cambiará para que deje de ser público y comience a ser solamente accesible para nuestro CDN. En la configuración Viewer Protocol Policy, seleccionamos la opción Redirect HTTP to HTTPS, pues este el principal objetivo en este tutorial, servir la página con a través de HTTPS. El resto de configuraciones las dejamos con sus valores por defecto y procedemos a hacer click en Create Distribution. Al finalizar la creación, el status será Deployed y el state será Enabled. Vamos a S3 y en las propiedades de la imagen cargada, en la sección Permissions, validamos que la imagen sea pública. Vamos a CloudFront y hacemos click en el identificador de nuestro recién creado CDN, con esto accederemos a sus propiedades, una vez dentro copiamos el dominio del CDN. Vamos un navegador e ingresamos el nombre dominio de la distribución recién creada, seguida de slash y el nombre de nuestra imagen. Veremos que nuestra imagen cargará lentamente la primera vez, pero si hacemos muchas veces Ctrl+F5. Veremos que solo la primera vez fue lenta, todas las demás cargo más rápido, esto porque la primera vez que se carga, la imagen queda guardada en la cache de nuestra distribución, en un Edge Location que físicamente está cerca de nosotros, mucho más cerca que la región de nuestro bucket (Sydney). Esta es una de las utilidades más importantes de CloudFront. Por otro lado si cargamos nuestra imagen consultando directamente el bucket de S3, veremos que nuestra imagen cargará lentamente la primera vez, pero si hacemos muchas veces Ctrl+F5. Veremos que todas las veces la imagen carga lentamente, esto porque con cada solicitud, vamos a traer la imagen hasta la región de Sydney, que físicamente está lejos de nosotros. Con esto llegamos al fin de nuestro tutorial, en el que claramente pudimos apreciar como el uso de una distribución o CDN tiene un impacto positivo en el performance cuando nuestra página o recursos web son consumidos desde muchos lugares diferentes a lo largo y ancho del mundo.","link":"/2019/05/15/14-Creacion-de-un-CloudFront-distribution/"},{"title":"Crear un Alexa Skill","text":"En este tutorial crearemos un Alexa Skill, pero nuestro principal objetivo es explorar estas herramientas de AWS y familiarizarnos con su uso para poder elaboraro soluciones más complejas y determinar cómo podemos usarlas para nuestros fines. Antes de comenzar vale la pena hacer una aclaración sobre la diferencia entre Alexa y Echo: Alexa es el servicio de voz ubicado en la nube de Amazon disponible en los dispositivos de Amazon y dispositivos tercios con Alexa integrada. Amazon Echo es un altavoz inteligente, es un dispositivo de hardware producido por Amazon. Sucede a menudo que los usuarios utilizan el término alexa para referirse indiscriminadamente a ambas cosas, pero lo cierto es que tecnicamente son diferentes. A lo anterior debemos agregar que Alexa está presente en muchos dispositivos de Amazon. Luego de la aclaración anterior comenzaremos con el tutorial. 1. Crear un S3 bucket público Ingresamos a la consola de AWS Buscamos el servicio S3 Seleccionamos la opción create bucket Asignamos un nombre válido para el nuevo bucket, un nombre que no haya sido usado para ningun otro bucket (recibiremos un mensaje de error si el nombre no fuera válido). Seleccionamos la opción create Posteriormente hacemos todo el contenido del bucket público, para ello seleccionamos nuestro bucket creado y hacemos click en el boton Edit public access settings Validamos que todas las opciones no esten seleccionadas y hacemos click en save. Escribimos el texto solicitado y hacemos click en confirm. Entramos al bucket cerado, nos movemos a la pesataña properties y en la opción Bucket Policy, configuramos la siguiente política: 123456789101112{ &quot;Version&quot;: &quot;2012-10-17&quot;, &quot;Statement&quot;: [ { &quot;Sid&quot;: &quot;PublicReadGetObject&quot;, &quot;Effect&quot;: &quot;Allow&quot;, &quot;Principal&quot;: &quot;*&quot;, &quot;Action&quot;: &quot;s3:GetObject&quot;, &quot;Resource&quot;: &quot;ARN here/*&quot; } ] } Es impotante cambiar la parte de “ARN here” por el ARN de nuestro bucket, posteriormente hacemos click en save y nuestra política será aplicada: 2. Explorar Amazon PollyEn este segmento del tutorial podremos explorar el servicio de Amazon Polly a nivel general, lo haremos creando un audio a partir de cierto texto, este audio será almacenado en S3, lo primero es buscar el servicio Amazon Polly : Una vez dentro de la consola de Amazon Polly, hacemos click en Get Started: Posteriormente nos encontraremos con un panel en el que podemos escribir texto que será leído según las configuraciones que hagamos, podemos por ejemplo configurar el idioma del texto y la persona que lo leerá, es decir, si esta persona leerá con un tono de voz masculino o femenino y el tono de voz de la persona en específico, incluso tenemos para el mismo idioma diferentes acentos, por ejemplo, yo incrusté cierto texto que será leído en español mexicano, con una voz femenina perteneciente a Mia. Luego vamos a hacer click en synthesize to S3, para poder exportar el audio correspondiente a este texto en nuestro bucket de S3. Al hacerlo nos desplegará una ventana en la que debemos ingresar el nombre de nuestro bucket. Seleccionamos Synthesize y se creará una tarea para sintetizar el audio correspondiente al texto ingresado. En la pestaña de S3 synthesis tasks podemos ver el estado de esta tarea para determinar si ya fue completada o no. Al completar la tarea, tendremos este audio en el bucket que indicamos. 3. Crear una función LambdaBuscamos el servicio AWS Lambda en la consola de aws. Una vez en la consola de AWS Lambda, procedemos a crear una nueva función, es importante crear esta función en una region en donde Alexa trigger esté habilitado, yo lo haré en **US East (N. Virginia). **Esto puede verse en la esquina superior derecha de nuestra consola. Luego de hacer click en Create function, encontraremos en el panel 3 opciones, Author from scratch, Use a blueprint y Browse serverless app repository, nosotros seleccionaremos esta última y buscaremos el repositorio alexa-skills-kit-nodejs-factskill. Escogemos el respositorio y dejamos todas sus configuraciones con los valores por defecto, posteriormente hacemos click en deploy y esperamos hasta que termine el proceso de deploy de nuestra función: Ingresamos a la función y vemos que ya cuenta con un alexa trigger, esto porque hicimos el deploy de la función en una región que lo soporta, en este caso N. Virginia. En el código autogenerado por la función veremos que hay un set de oraciones aleatoreas, agregaré mi nombre en el listado, luego procedí a hacer click en Save, para guardar los cambios en la función. Vamos a https://developer.amazon.com/ e ingresamos a Amazon Alexa: Una vez registrados y dentro de nuestra cuenta, procedemos a buscar el Alexa Skills kit: En la consola de Alexa, escogemos la opción Create Skill. Luego de crearla nos da la opción de escoger un template, escogemos Fact Skill y continuamos: Luego estaremos en el Alexa Development Console: Vamos a la sección de invocations, asignamos un nombre a nuestra invocation, en este caso coloque el nombre Cloud Facts y seleccionamos la opción save model: Regresamos a la consola de Lambda, a la función anteriormente creada e identificamos y copiamos el ARN de nuestra función: Vamos de nuevo a Alexa Developer Console, a la sección Endpoint y configuramos el ARN de nuestra función, de tal manera que nuestro Alexa Skill apuntará a la fución Lambda anteriormente creada. Luego de agregar el ARN, seleccionamos Save Endpoints. Vamos a la sección GetNewFactIntent, incresamos un nuevo fact, **a cloud fact **en este caso, luego agregamos este fact y seleccionamos Save Model para guardar el modelo. Y luego Build Model para construir nuestro modelo. Al finalizar el Build recibiremos una notificación. Luego de terminar el Build, vamos a la sección Test,** **cambiamos el modo a Development e ingresamos la instrucción open cloud facts. Luego vamos a obtejer un fact de la función asociada. En este caso recibí el siguiente: Here’s your fact: A year on Mercury is just 88 days long. Con lo anterior tenemos que nuestra Alexa Skill funciona y que nuestra función lambda también lo hace. Regresamos a la consola de Lambda y seleccionamos todos los facts del arreglo. Los eliminamos, dejamos solamente nuestro nombre y guardamos los cambios haciendo click en el boton Save. Vamos nuevamente a Alexa Developer Console e ingresamso open cloud facts. Luego de ingresarlo el único resultado posible es nuestro nombre, pues eliminamos el resto de facts. Ahora en lugar de usar mi nombre como Fact, usaremos el archio de audio generado anteriormente con Polly, para ello vamos a nuestro bucket, a nuestro archivo de audio y en sus propiedades de la pestaña Overview encontraremos el URL del file. Vamos a la consola de Lambda y modificamos el fact, en lugar de ser nuestro nombre introducimos el URL de nuestro audio con el siguiente formato para indicar que se trata de un audio 1'&lt;audio src=\\&quot;https://s3.amazonaws.com/ericknavarropolly2019/c4c0a83c-3718-49b4-bb72-0ee529ddf95b.mp3\\&quot;/&gt;' Y hacemos click en Save. Antes de ejecutar nuestro Skill, es importante que nos aseguremos de que el file en el bucket es público, para ello vamos a la consola de S3, seleccionamos nuestro bucket, seleccionamos nuestro archivo y seleccionamos la opción Make Public. Posteriormente vamos a nuestro Skill, ingresamos la instrucción open cloud facts y obtendremos el audio configurado. Con esto llegamos al final del tutorial, espero que esta introducción a Alexa Skills, les motive a seguir explorando estas herramientas de AWS.","link":"/2019/05/17/15-Crear-un-Alexa-Skill/"},{"title":"Configurar un servidor web en AWS EC2","text":"En este tutorial configuraremos un web server utilizando EC2, probablemente una de las cosas menos complejas que podemos hacer en AWS, básicamente levantaremos una máquina virtual en EC2 para montar una página web. 1. Crear la instancia de EC2Lo primero es buscar en la consola de AWS: El servicio EC2: Una vez dentro de la consola de EC2, seleccionamos la opción Launch Instance: Escogemos alguna imagen AMI que sea Free tier elegible, de tal manera que podamos levantar la instancia sin pagar nada. El segundo paso es elegir el tipo de instancia, buscamos nuevamente que sea Free tier elegible, esta será una instancia con recursos muy básicos, pero útil para nuestros fines. Configuramos los detalles de la instancia, es importante que al ser creada la instancia se le asigne una IP pública, para ello verificamos que posea la siguiente configuración: Auto-assign Public IP: Use subnet setting (Enable). Posteriormente vienen las configuraciones de almacenamiento, acá podemos agregar más discos duros EBS si quisieramos, pero en este caso dejaremos los valores por default. Luego podemos agregar etiquetas, que básicamente son meta-data de la instancia, esto es especialmente útil cuando tenemos muchas instancias y necesitamos información sobre qué aloja cada una. Creamos un nuevo Security Group para nuestra instancia asegurándonos de que en las reglas permita solicitudes hacia el puerto 22 y el puerto 80 desde cualquier origen. Creamos un nuevo key pair para nuestra instancia, estas son las llaves con las que accederemos a través de SSH a nuestra instancia de EC2. Posteriormente escogemos la opción Launch instance y luego de algunos minutos la instancia estará corriendo y lista para ser utilizada. en el campo IPv4 Public IP, podremos ver la IP pública de la instancia, que posteriormente será utilizada para conectarse a la misma. Si seleccionamos nuestra instancia y hacemos click en Connect, veremos el siguiente recuadro con las opciones e instrucciones para conectarnos a la instancia. Nosotros nos conectaremos utilizando A standalone SSH client. 2.1. Conectarse a la instancia vía SSH (Windows)Para conectarse a la instancia EC2 vía SSH en Windows es necesario descargar putty, una herramienta que puede ser utilizada como cliente SSH y cuenta con algunas otras funcionalidades. Una vez descargado procedemos a ejecutar el asistente de instalación. Una vez instalado, necesitamos convertir nuestro archivo .PEM a un archivo .PPK, para ello procedemos a abrir PuTTY Key Generator. Haciendo click en load, podemos cargar nuestra llave .PEM. Veremos un mensaje de que la llave se importó correctamente. Guardamos la llave importada sin passphrase. Nos aseguramos de que el archivo se guarde con la extensión .PPK. Al finalizar procedemos a abrir PuTTY. Ingresamos la IP pública de nuestra instancia de EC2. Desplegamos la opción Connection, posteriormente la opción SSH y por último vamos a Auth, adjuntaremos el archivo .PKK generado. Volvemos a la pestaña de sesión y guardamos la sesión con un nombre representativo, en este caso MiWebServer. Posteriormente la aplicación nos preguntará si confiamos en este host para agregar la llave a la cahe de PuTTY. Respondemos que sí, pues es nuestra instancia de EC2. Con esto estaremos conectados con nuestra instancia EC2 vía SSH desde Windows. Luego de esto ingresamos con el usuario ec2-user, no nos pedirá contraseña pues estamos usando nuestro archivo .PPK para autenticarnos. 2.2. Conectarse a la instancia vía SSH (Linux)Para conectarse a la instancia EC2 vía SSH en Linux, es necesario descargar nuestro archivo .PEM Nos movemos a la carpeta en la que se encuentra el archivo: 1cd /home/erick/ Asignamos los permisos adecuados: 1chmod 400 MiNuevaKeyPair.pem Y accedemos remotamente vía SSH: 1ssh -i &quot;MiNuevaKeyPair.pem&quot; ec2-user@ec2-18-206-137-162.compute-1.amazonaws.com Con esto habremos ingresado a nuestra instancia: 3. Iniciar apache serverLo siguiente será iniciar apache server, en nuestro caso la instancia de EC2 que escogimos ya lo tenía instalado, si la instancia no lo tuviera tendríamos que instalarlo. Para arrancarlo ejecutamos el siguiente comando: 1sudo service httpd start Luego validamos que el servicio esté corriendo ejecutando: 1sudo service httpd status 4. Publicar nuestra páginaCreamos un archivo index.html en la carpeta /var/www/html/index.html Para ello ejecutamos el comando: 1nano /var/www/html/index.html Posteriormente introducimos el código html de nuestra página. Salimos del editor nano con la combinación de teclas Ctrl + x, al salir nos preguntará si queremos guardar nuestros cambios, respondemos que sí. Por último si accedemos a la IP pública de nuestro servidor desde un navegador veremos la página recién creada. Con esto llegamos al final de nuestro tutorial.","link":"/2019/05/21/16-Configurar-un-servidor-web-en-AWS-EC2/"},{"title":"Mi primer proyecto utilizando Jison (Linux)","text":"Se desarrollará un intérprete que recibe como entrada varias expresiones aritméticas y presenta como salida el resultado de dichas expresiones. Las tecnologías a utilizar son: Jison: Generador de analizadores léxicos y sintácticos. Nodejs: Es un entorno en tiempo de ejecución, multiplataforma, capaz de ejecutar javascript fuera de un explorador. Ubuntu 18.04: Sistema operativo. Visual Studio Code: Es un editor de código ligero pero poderoso. Viene con soporte integrado para JavaScript, Nodejs, entre otros. El proyecto completo lo pueden descargar del siguiente enlace: Mi primer proyecto utilizando Jison con Nodejs (Ubuntu) JisonJison toma una gramática libre de contexto como entrada y produce código JavaScript capaz de parsear el lenguaje descrito por dicha gramática. Una vez se tenga el script generado podemos usarlo para parsear la entrada y aceptarla, rechazarla o ejecutar acciones con base en la entrada. Si se está familiarizado con Bison, Yacc o algún otro similar ya se está listo para iniciar. Jison genera tanto el analizador léxico como el analizador sintáctico. La principal tarea de un analizador léxico es leer los caracteres de entrada del programa fuente, agruparlos en lexemas y producir como salida una secuencia de tokens. Un token es un par que consiste en un nombre de token y un valor de atributo opcional. Un lexema es una secuencia de caracteres en el programa fuente, que coinciden con el patrón para un token y que el analizador léxico identifica como una instancia de este tóken. Un patrón es una descripción de la forma que pueden tomar los lexemas de un token. El analizador sintáctico obtiene una cadena de tokens del analizador léxico y verifica que dicha cadena pueda generarse con la gramática para el lenguaje fuente. Una gramática proporciona una especificación precisa y fácil de entender de un lenguaje de programación. En Jison se definen tanto el analizador léxico como el sintáctico. Esto es una gran ventaja pues podemos trabajar en una sola herramienta. Pre-requisitosPara este ejemplo hace falta que tengamos instalado: Nodejs npm Para instalar Nodejs en Ubuntu basta con ejecutar el siguiente comando: 1$ sudo apt install nodejs Para verificar que la instalación haya sido correcta ejecutamos el siguiente comando: 1$ nodejs --version Luego procedemos a instalar npm. Para esto ejecutamos el siguiente comando: 1$ sudo apt install npm Y verificamos la instalación con el siguiente comando: 1$ npm --version Instalar JisonInstalamos Jison con el siguiente comando: 1$ sudo npm install jison -g La bandera -g nos sirve para indicar que instalaremos Jison de manera global, es decir, estará disponible en cualquier directorio del sistema. Crear nuestro proyectoUsaremos npm para crear nuestro proyecto. Primero crearemos un nuevo folder, en este caso lo llamaremos ProyectoJisonUbuntu. Para esto abrimos una nueva terminal, nos ubicamos donde queremos crear el proyecto y ejecutamos el siguiente comando: 1$ mkdir ProyectoJisonUbuntu Y luego ingresamos al directorio con el siguiente comando: 1$ cd ProyectoJisonUbuntu Ahora procedemos a iniciar el proyecto con npm. Para esto ejecutamos el siguiente comando: 1$ npm init -y Con esto habremos iniciado el proyecto. La bandera -y sirve para seleccionar valores por defecto en los parámetros de inicialización. Ahora nos pasamos a nuestro editor de texto, en este caso usaremos Visual Studio Code. Ejecutamos el siguiente comando para abrir Code con nuestro proyecto directamente. 1$ code . Code se desplegará con nuestro proyecto llamado ProyectoJisonUbuntu Nótese que únicamente contiene el archivo package.json el cual fue creado por el comando npm init. Procedemos a crear un nuevo archivo llamado gramatica.jison Código Fuente para el analizador léxico y sintácticoEn el archivo gramática.jison le indicamos a Jison la descripción de nuestra gramática. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071/** * Ejemplo mi primer proyecto con Jison utilizando Nodejs en Ubuntu *//* Definición Léxica */%lex%options case-insensitive%%&quot;Evaluar&quot; return 'REVALUAR';&quot;;&quot; return 'PTCOMA';&quot;(&quot; return 'PARIZQ';&quot;)&quot; return 'PARDER';&quot;[&quot; return 'CORIZQ';&quot;]&quot; return 'CORDER';&quot;+&quot; return 'MAS';&quot;-&quot; return 'MENOS';&quot;*&quot; return 'POR';&quot;/&quot; return 'DIVIDIDO';/* Espacios en blanco */[ \\r\\t]+ {}\\n {}[0-9]+(&quot;.&quot;[0-9]+)?\\b return 'DECIMAL';[0-9]+\\b return 'ENTERO';&lt;&lt;EOF&gt;&gt; return 'EOF';. { console.error('Este es un error léxico: ' + yytext + ', en la linea: ' + yylloc.first_line + ', en la columna: ' + yylloc.first_column); }/lex/* Asociación de operadores y precedencia */%left 'MAS' 'MENOS'%left 'POR' 'DIVIDIDO'%left UMENOS%start ini%% /* Definición de la gramática */ini : instrucciones EOF;instrucciones : instruccion instrucciones | instruccion | error { console.error('Este es un error sintáctico: ' + yytext + ', en la linea: ' + this._$.first_line + ', en la columna: ' + this._$.first_column); };instruccion : REVALUAR CORIZQ expresion CORDER PTCOMA { console.log('El valor de la expresión es: ' + $3); };expresion : MENOS expresion %prec UMENOS { $$ = $2 *-1; } | expresion MAS expresion { $$ = $1 + $3; } | expresion MENOS expresion { $$ = $1 - $3; } | expresion POR expresion { $$ = $1 * $3; } | expresion DIVIDIDO expresion { $$ = $1 / $3; } | ENTERO { $$ = Number($1); } | DECIMAL { $$ = Number($1); } | PARIZQ expresion PARDER { $$ = $2; }; Explicación del código fuente para el analizador léxicoIniciamos indicando que queremos iniciar con la definición léxica, posteriormente agregamos las opciones que deseamos. En este caso indicamos que nuestro analizador no distinguirá diferencias entre mayúsculas y minúsculas. 1234/* Definición Léxica */%lex%options case-insensitive A diferencia de otras herramientas, Jison por defecto cuenta la posición de línea y columna de los caracteres y acepta el conjunto de caracteres unicode. Luego escribimos los patrones para los tokens que deseamos reconocer. Para cada uno de ellos debemos retornar el nombre asociado al token. 12345678910111213%%&quot;Evaluar&quot; return 'REVALUAR';&quot;;&quot; return 'PTCOMA';&quot;(&quot; return 'PARIZQ';&quot;)&quot; return 'PARDER';&quot;[&quot; return 'CORIZQ';&quot;]&quot; return 'CORDER';&quot;+&quot; return 'MAS';&quot;-&quot; return 'MENOS';&quot;*&quot; return 'POR';&quot;/&quot; return 'DIVIDIDO'; Jison también soporta el uso de expresiones regulares para identificar patrones. En las siguientes instrucciones escribimos una expresión regular para identificar espacios en blanco e indicamos que al ser reconocidos no hacemos nada. Esto se hace a través de un par de llaves vacíos. 123/* Espacios en blanco */[ \\r\\t]+ {}\\n {} Escribimos expresiones regulares para identificar enteros y decimales. 12[0-9]+(&quot;.&quot;[0-9]+)?\\b return 'DECIMAL';[0-9]+\\b return 'ENTERO'; Las últimas dos expresiones son para reconocer el fin de la entrada y caracteres no válidos. 1234&lt;&lt;EOF&gt;&gt; return 'EOF';. { console.error('Este es un error léxico: ' + yytext + ', en la linea: ' + yylloc.first_line + ', en la columna: ' + yylloc.first_column); }/lex En caso de encontrarse con un error léxico lo desplegamos en consola. Explicación del código fuente para el analizador sintácticoOtra de las ventajas de Jison es que en el mismo archivo podemos definir nuestro análisis sintáctico haciendo uso de los tokens previamente definidos en la sección del analizador léxico. Primeramente definimos la asociatividad y precedencia de los operadores, ya que la gramática escrita es ambigua, es necesario definir una precedencia para que el analizador no entre en conflicto al analizar, en este caso la precedencia es la misma que la de los operadores aritméticos, la precedencia más baja la tienen la suma y la resta, luego están la multiplicación y la división que tienen una precedencia más alta y por último está el signo menos de las expresiones negativas que tendría la precedencia más alta 12345/* Asociación de operadores y precedencia */%left 'MAS' 'MENOS'%left 'POR' 'DIVIDIDO'%left UMENOS Debemos indicarle a Jison cual será nuestro símbolo Inicial. 1%start ini Finalmente, escribimos nuestras producciones, aquí vemos otra de las ventajas de Jison, cada No Terminal no debe definirse previamente, esto lo hace más práctico pero a la vez se debe de tener más cuidado con errores de escritura. 12345678910111213141516171819202122232425262728%% /* Definición de la gramática */ini : instrucciones EOF;instrucciones : instruccion instrucciones | instruccion | error { console.error('Este es un error sintáctico: ' + yytext + ', en la linea: ' + this._$.first_line + ', en la columna: ' + this._$.first_column); };instruccion : REVALUAR CORIZQ expresion CORDER PTCOMA { console.log('El valor de la expresión es: ' + $3); };expresion : MENOS expresion %prec UMENOS { $$ = $2 *-1; } | expresion MAS expresion { $$ = $1 + $3; } | expresion MENOS expresion { $$ = $1 - $3; } | expresion POR expresion { $$ = $1 * $3; } | expresion DIVIDIDO expresion { $$ = $1 / $3; } | ENTERO { $$ = Number($1); } | DECIMAL { $$ = Number($1); } | PARIZQ expresion PARDER { $$ = $2; }; Al final de cada producción se puede incluir código javascript entre llaves “{ &lt;código javascript&gt; }”. Para sintetizar un valor asociado al no terminal de lado izquierdo de la producción hacemos uso de la variable $$. Esta variable es propia de Jison. Como podemos ver, para cada producción del no terminal “expresion” sintetizamos el valor de la operación aritmética o el valor del token aceptado. La variable $$ puede tomar cualquier valor, recordemos que Jison al estar basado en javascript el tipo puede ser dinámico. Nótese el terminal EOF, que indica el fin de la entrada, debe agregarse en nuestra gramática luego de haber reconocido nuestra entrada, esto indicará que hemos terminado. Si se omite este terminal obtendremos una excepción cuando nuestro analizador alcance el final del archivo. Por último, podemos manejar también las producciones de error para el manejo de errores sintácticos. El archivo de compilaciónPara facilitar la compilación de nuestra gramática y poder obtener el script para nuestro parser procedemos a escribir un archivo sh. Para esto creamos un nuevo archivo en Code llamado compilar.sh con el siguiente contenido: 1234567#!/bin/bashecho &quot;Procesando gramática...&quot;jison gramatica.jisonecho &quot;Gramática procesada...&quot; Para ejecutar nuestro script ejecutamos el siguiente comando en la terminal: 1$ sh compilar.sh Nos debe aparecer el siguiente resultado: Si hubiese algún error debemos revisar que nuestra gramática esté correcta. El comando nos generará el script en un archivo llamado gramatica.js en nuestro proyecto. Este es el script que utilizaremos para procesar nuestros archivos de entrada. Creando un archivo de entrada para nuestro analizadorCreamos un nuevo archivo de texto utilizando nuestro editor llamado entrada.txt. El contenido de este archivo es el siguiente: 12345Evaluar[1+1];Evaluar[1+1*2];Evaluar[-(1+1*6/3-5+7)];Evaluar[-(1+1*6/3-5+1*-2)];Evaluar[-(1.6+1.45)]; Script PrincipalNecesitamos de un script que nos ayude a leer el archivo de entrada e invocar a nuestro parser con su contenido. Para esto creamos un nuevo archivo de texto y lo nombramos parser.js. Su contenido es el siguiente: 12345678var fs = require('fs'); var parser = require('./gramatica');fs.readFile('./entrada.txt', (err, data) =&gt; { if (err) throw err; parser.parse(data.toString());}); Hacemos uso de la librería fs de Nodejs para leer archivos y también de nuestro parser. Esto lo hacemos a través de la función require. Luego invocamos al método readFile el cual lee nuestro archivo de entrada ‘entrdata.txt’. Este método devuelve dos parámetros, err el cual indica si hubo algún error y data, que almacena el contenido del archivo. Validamos que no haya ocurrido error y con el contenido de nuestro archivo de entrada invocamos a nuestro parser. Para ejecutar este script corremos el siguiente comando: 1$ node parser Como podemos ver, obtenemos la salida esperada. Acerca del autor:Este tutorial fue elaborado por el Auxiliar de Cátedra Rainman Sián, como contribución al curso de Organización de Lenguajes y Compiladores 2 de la Universidad de San Carlos de Guatemala. Fuentes consultadas:Compiladores, principios, técnicas y herramientas. Aho, Lam, Sethi y Ullman. Segunda Edición.","link":"/2019/07/21/17-Mi-primer-proyecto-utilizando-Jison-Linux/"},{"title":"Mi primer proyecto utilizando Gold Parser","text":"Se desarrollará un intérprete que recibe como entrada varias expresiones aritméticas y presenta como salida el resultado de dichas expresiones evaluadas. Las tecnologías a utilizar son: Gold Parser Builder: Generador de analizadores léxicos y sintácticos diseñado para funcionar en múltiples lenguajes de programación. Visual Studio 2017: Entorno de desarrollo integrado para programar Visual Basic y C#, entre otros. Windows 10: Sistema operativo El proyecto completo puede descargarse del siguiente enlace: Mi primer proyecto utilizando Gold Parser Gold ParserGold Parser es un generador de analizadores léxicos y sintácticos que soporta lenguajes tales como C#, COBOL, DELPHI, Visual Basic, Java entre otros. Este programa realiza de manera conjunta el análisis léxico y sintáctico, por lo que no tenemos la necesidad de recurrir a ningún programa externo. La principal tarea de un analizador léxico es leer los caracteres de entrada del programa fuente, agruparlos en lexemas y producir como salida una secuencia de tokens. Un token es un par que consiste en un nombre de token y un valor de atributo opcional. Un lexema es una secuencia de caracteres en el programa fuente, que coinciden con el patrón para un token y que el analizador léxico identifica como una instancia de este tóken. Un patrón es una descripción de la forma que pueden tomar los lexemas de un token. El analizador sintáctico obtiene una cadena de tokens del analizador léxico y verifica que dicha cadena pueda generarse con la gramática para el lenguaje fuente. Una gramática proporciona una especificación precisa y fácil de entender de un lenguaje de programación. Pre-requisitos Gold Parser Builder Este programa puede descargarse de la página oficial de Gold Parser Descomprimimos el archivo ZIP descargado y ejecutamos el archivo setup.exe que encontraremos dentro de los files descomprimidos. Esto nos desplegará el asistente de instalación, en la primera ventana no debemos de seleccionar nada, por lo que únicamente presionaremos el botón de siguiente. Posteriormente, se nos preguntará en qué ruta deseamos instalar Gold Parser, en este caso dejaremos la ruta por defecto que es “C:\\Program Files (x86)\\Gold Parser Builder”, seleccionar si queremos instalarlo para todos los usuarios o solo para nosotros, en este caso seleccionaremos “Everyone” para que todos los usuarios puedan utilizarlo. Damos click en siguiente para continuar con la instalación. Luego se nos mostrará una ventana que pide nuestra confirmación para continuar con la instalación de Gold Parser, hacemos click en siguiente. Por último se nos mostrará la ventana de confirmación que indica que Gold Parser fue instalado correctamente. Generando nuestro analizador léxico y sintáctico con Gold ParserHacemos clic en el botón de Windows y buscamos “gold parser builder”. Ejecutamos la aplicación Gold Parser Builder y tendremos un ambiente de trabajo como el que se muestra a continuación. Lo primero que debemos hacer para comenzar a trabajar con Gold Parser Builder es definir la gramática, el ejemplo que inspiró este tutorial fue realizado con Jlex y Cup: Mi primer proyecto utilizando Jlex y Cup (Windows) La gramática planteada para Jlex y Cup era ambigua y dicha ambigüedad se resolvía indicando de forma explicita la precedencia de los operadores aritméticos: 123precedence left MAS,MENOS;precedence left POR,DIVIDIDO;precedence right UMENOS; Cup permite definir la precedencia y asociatividad de los operadores de forma explícita, en el caso de Gold Parser, esta opción no está disponible, por lo que es necesario utilizar una gramática no ambigua que respete la precedencia y asociatividad de los operadores. Tomando en cuenta lo anterior, se propone la siguiente gramática escrita con la sintaxis propia de Gold Parser: 123456789101112131415161718192021222324252627282930&quot;Name&quot; = 'Mi Primer Proyecto en Gold Parser'&quot;Author&quot; = 'Luis Lizama'&quot;Version&quot; = '1.0' &quot;About&quot; = 'Ejemplo de una gramática simple que reconoce expresiones aritméticas'&quot;Case Sensitive&quot; = False &quot;Start Symbol&quot; = &lt;Statements&gt; DECIMAL = {Digit}+'.'{Digit}+ENTERO = {Digit}+&lt;Statements&gt; ::= &lt;Statement&gt; &lt;Statements&gt; | &lt;Statement&gt;&lt;Statement&gt; ::= Evaluar '[' &lt;Expression&gt; ']'';' &lt;Expression&gt; ::= &lt;Expression&gt; '+' &lt;Mult Exp&gt; | &lt;Expression&gt; '-' &lt;Mult Exp&gt; | &lt;Mult Exp&gt; &lt;Mult Exp&gt; ::= &lt;Mult Exp&gt; '*' &lt;Negate Exp&gt; | &lt;Mult Exp&gt; '/' &lt;Negate Exp&gt; | &lt;Negate Exp&gt; &lt;Negate Exp&gt; ::= '-' &lt;Value&gt; | &lt;Value&gt; &lt;Value&gt; ::= ENTERO | DECIMAL | '(' &lt;Expression&gt; ')' Toda la documentación relacionada con la sintaxis de Gold Parser puede encontrarse en la página oficial. Una vez tengamos lista nuestra gramática, la ingresamos en la ventana Grammar de la aplicación Gold Parser Builder (para esto basta con copiar y pegar la gramática mostrada anteriormente). Luego procedemos a guardar la gramática seleccionando la opción “File” → “Save”, el archivo resultante tendrá extensión GRM, que es una extensión propia de Gold Parser. El archivo GRM con la gramática utilizada para este ejemplo está disponible en la carpeta Gramática del repositorio de este ejemplo. Posteriormente seleccionamos la opción “Project” → “Analyze the Grammar”, esto analizará la gramática y nos mostrará los conflictos si existieran. Debemos corregir todos los errores antes de continuar, para este ejemplo no había ninguno. Esto podemos confirmarlo en la parte inferior de nuestro editor de Gold Parser Builder. Si existiesen errores o notificaciones se nos mostrarán en una ventana emergente de la siguiente manera: En este caso no teníamos errores, así que podemos proseguir con la creación de las tablas para el análisis LALR. Esto lo hacemos seleccionando la opción “Project” → “Create LALR Parse Tables” Podemos confirmar que nuestras tablas LALR fueron creadas exitosamente en la parte inferior de nuestro editor de Gold Parser Builder. Durante la creación de las tablas LALR es posible de que se detecten conflictos de desplazamiento-reducción y el asistente no nos permita continuar, en este caso debemos resolver estos conflictos y luego continuar. Por el contrario, si no tenemos conflictos que resolver, podemos continuar al último paso, crear las tablas del autómata finito determinista que será el encargado de realizar el análisis léxico. Para ello seleccionamos la opción “Project” → “Create DFA Lexer Tables”. Podemos confirmar que nuestras tablas para el autómata finito determinista fueron creadas exitosamente en la parte inferior de nuestro editor de Gold Parser Builder. Por último, procedemos a guardar todas las tablas, estas serán importadas posteriormente en nuestro programa para poder realizar el análisis léxico y sintáctico del texto recibido como entrada. Para ello seleccionamos la opción “Project” → “Save the Tables”. Se nos mostrará una ventana para que indiquemos la ruta en la cual deseamos almacenar las tablas, la seleccionamos y damos click en aceptar, con esto habremos generado un archivo EGT, esta ventana se cerrará y Gold Parser nos mostrará un mensaje diciendo que se guardaron las tablas correctamente. EGT es una extensión propia de Gold parser. El archivo EGT con las tablas generado para este ejemplo está disponible en la carpeta Gramática del repositorio de este ejemplo. Una de las principales ventajas de Gold Parser es que tiene un módulo de test que permite visualizar el proceso de análisis de una forma detallada. Para utilizar el módulo de test, hacemos click en el ícono correspondiente, que tiene un pequeño cheque verde. O bien seleccionando la opción “Window” → “Test Grammar” Esto nos desplegará una ventana de test en la que podemos ingresar en el lado izquiero una entrada y posteriormente evaluar paso a paso esta entrada con el botón verde de ejecutar que se encuentra en la parte inferior izquierda, esto nos permitirá ver el progreso del análisis en el panel derecho con el detalle de cada estado. Luego de este pequeño paréntesis para explorar el módulo de test de Gold Parser continuaremos con nuestro proyecto. El siguiente paso es crear el esqueleto de un programa, para ello seleccionamos “Project” → “Create a Skeleton Program…”. Se nos desplegarán varias opciones para generar el esqueleto, para este ejemplo en específico utilizaremos Visual Basic .NET y como motor Cock .NET DLL. Seleccionaremos la opción de crear y nos mostrará una ventana desde la cual podremos seleccionar la ruta en la cual queremos guardar el esqueleto de nuestro programa. Obtendremos como resultado un archivo con extensión VB. El archivo VB generado con el esqueleto está disponible en la carpeta Gramática del repositorio de este ejemplo. Esto es todo lo que haremos en Gold Parser, de acá en adelante utilizaremos Visual Studio. Abrimos Visual Studio. Seleccionamos “File” → “New” → “Project”, una vez abierto el wizard para crear nuevos proyectos seleccionamos el apartado “Visual Basic” → “Windows Desktop” → “Console App (.NET Framework)” y le pondremos como nombre Calculadora. Para poder utilizar el esqueleto que generamos en Gold Parser en el proyecto que acabamos de crear necesitaremos importar la librería .NET DLL que realiza el proceso de análisis, esta libería debe descargarse en la página oficial. Luego de descargar y descomprimir la librería obtendremos el archivo “Gold Engine.dll” que es el que debemos importar en nuestro proyecto. Con el proyecto creado debemos de pegar el archivo de las tablas de análisis generadas en Gold Parser (Expresiones aritméticas.egt) y la librería que acabamos de descargar (GOLD Engine.dll) en la carpeta Calculadora/Calculadora/bin/debug de nuestro proyecto. También debemos de pegar el esqueleto que generamos con Gold Parser (Expresiones aritméticas.vb) en la carpeta principal de nuestro proyecto. Regresamos a Visual Studio y desde el explorador de soluciones debemos de realizar dos procedimientos. El primero es importar el archivo que contiene el esqueleto generado en Gold Parser (Expresiones aritméticas.vb), para ello hacemos click derecho sobre el nombre de nuestro proyecto “Add” → “Existing Item…”. Luego seleccionamos el archivo de nuestro esqueleto. Veremos que ahora aparece en el explorador de soluciones. El segundo procedimiento a realizar en el explorador de soluciones es importar la librería que acabamos de pegar en nuestra carpeta debug, para hacerlo daremos click derecho en “References” → “Add Reference…” Esto nos desplegara una nueva ventana, seleccionamos la opción “Browse…” y seleccionamos nuestro archivo .dll y daremos click en aceptar. Por último, abrimos el archivo que contiene el esqueleto que generamos con Gold Parser (Expresiones aritméticas.vb) y dentro de las líneas de código buscar el método con el nombre Setup. Es la única instrucción que posee este método, debemos cambiar el nombre del archivo gramar.egt por el nombre de nuestro archivo de tablas (Expresiones aritméticas.egt), es de suma importancia que hayamos pegado nuestras tablas en la carpeta debug, de otra manera nuestro programa no las podrá encontrar y nos arrojará un error en tiempo de ejecución. Estas son todas las configuraciones que debemos de realizar para poder utilizar Gold Parser, de acá en adelante, el tutorial se enfoca en explicar el funcionamiento de los archivos que se generaron anteriormente. Creando un archivo de entrada para nuestro analizadorCreamos un nuevo archivo de texto llamado entrada.txt. El contenido de este archivo es el siguiente: 12345Evaluar[1+1];Evaluar[1+1*2];Evaluar[-(1+1*6/3-5+7)];Evaluar[-(1+1*6/3-5+1*-2)];Evaluar[-(1.6+1.45)]; Este archivo de entrada será creado en la carpeta Calculadora/Calculadora/bin/debug de nuestro proyecto. Utilizando el esqueleto generado con Gold ParserEn los pasos anteriores nos enfocamos en la definición de la gramática y las configuraciones que tenemos que realizar para poder utilizar los archivos que generamos con Gold Parser, pero no hemos programado ningún tipo de instrucción dentro de nuestro programa. Gold Parser se centra en generar un árbol de análisis sintáctico, de esta manera nosotros podremos recorrer este árbol como sea más conveniente, es por ello que no nos permite incrustar acciones semánticas al momento de definir la gramática, debemos de realizarlo directamente en el esqueleto generado, este esqueleto será modificado según convenaga para lograr nuestro objetivo. El archivo VB generado con el esqueleto (Expresiones aritméticas.vb) modificado con las acciones necesarias para evaluar las expresiones aritméticas, además de estar en la carpeta principal del proyecto dentro del repositorio, está disponible en la carpeta Gramática. Podremos notar que el esqueleto generado, en su método parse, posee una serie de estados los cuales por defecto tienen comentado su funcionamiento, los estados que alteraremos en este ejemplo son: LexicalError : Reportar errores léxicos. SyntaxError : Reportar errores sintácticos. Accept : Crear la raíz de nuestro árbol de análisis sintáctico. Definiremos una variable Root de tipo Gold.Reduction que será la raíz de nuestro árbol. Adicionalmente, podremos notar que el archivo también posee una función denominada CreateNewObject que posee una serie de casos los cuales tienen comentado a que producción de la gramática pertenecen, es aquí donde debemos de introducir las acciones semánticas que deseamos que se ejecuten al momento de reducir por cada producción. Esta función CreateNewObject viene definida únicamente como una plantilla, pero podremos darle la funcionalidad que nosotros deseemos. Para este ejemplo en específico se le cambió el nombre por “GetValue” ya que lo que necesitamos al final es obtener el valor resultante de evaluar cada expresión aritmética. Los métodos de nuestro parser son estáticos y no es necesario crear una instancia parser, pero si es necesario ejecutar el método Setup para que cargue las tablas de análisis. El programa por defecto está configurado para leer el archivo entrada.txt en la carpeta Calculadora/Calculadora/bin/debug del proyecto. A continuación se muestra el resultado de ejecutar el archivo de entrada que preparamos anteriormente. Como podemos ver, obtenemos la salida esperada. Acerca del autor:Este tutorial fue elaborado por el Auxiliar de Cátedra Luis Lizama, como contribución al curso de Organización de Lenguajes y Compiladores 2 de la Universidad de San Carlos de Guatemala. Fuentes consultadas:Compiladores, principios, técnicas y herramientas. Aho, Lam, Sethi y Ullman. Segunda Edición.","link":"/2019/07/22/18-Mi-Primer-Proyecto-Utilizando-GOLD-Parser-Windows/"},{"title":"Mi primer proyecto utilizando Irony","text":"Se desarrollará un intérprete que recibe como entrada varias expresiones aritméticas y presenta como salida el resultado de dichas expresiones evaluadas. Las tecnologías a utilizar son: Irony: Generador de analizadores léxicos y sintácticos que retorna un AST (Abstract Syntax Tree). Visual Studio 2017: Entorno de desarrollo integrado utilizado para programar en C#. Windows 10: Sistema Operativo. Irony.dll: DLL que permite la integración de Irony con C#. El proyecto completo puede descargarse del siguiente enlace: Mi primer proyecto utilizando Irony IronyIrony es un kit de desarrollo para implementar lenguajes en la plataforma .NET. A diferencia de la mayoría de las soluciones de estilo yacc / lex existentes, Irony no emplea ninguna generación de scanner (analizador léxico) o parser (analizador sintáctico) a partir de especificaciones gramaticales escritas en un meta-lenguaje especializado. En Irony, la gramática del lenguaje se codifica directamente en C# utilizando la sobrecarga de operadores para expresar construcciones gramaticales. Los módulos de scanner y parser de Irony utilizan la gramática codificada como una clase de C# para controlar el proceso de análisis. En la página principal de Irony, se anuncia que el proyecto se ha movido a un repositorio en GitHub. Analizador léxico (Scanner)La principal tarea de un analizador léxico es leer los caracteres de entrada del programa fuente, agruparlos en lexemas y producir como salida una secuencia de tokens. Un token es un par que consiste en un nombre de token y un valor de atributo opcional. Un lexema es una secuencia de caracteres en el programa fuente, que coinciden con el patrón para un token y que el analizador léxico identifica como una instancia de este tóken. Un patrón es una descripción de la forma que pueden tomar los lexemas de un token. Analizador sintáctico (Parser)El analizador sintáctico obtiene una cadena de tokens del analizador léxico y verifica que dicha cadena pueda generarse con la gramática para el lenguaje fuente. Una gramática proporciona una especificación precisa y fácil de entender de un lenguaje de programación. Pre-requisitos Obtención del archivo Irony.DDL El proyecto de Irony anteriormente mencionado es un proyecto de C#, el cual contiene la aplicación de Irony, sin embargo, a nosotros únicamente nos interesa las librerías que este proyecto genera, para obtener dichas librerías debemos seguir los siguientes pasos: Descargar el repositorio completo de Irony desde GitHub. Descomprimimos el repositorio e ingresamos a la carpeta Irony.Interpreter Dentro de la carpeta Irony.Interpreter, encontraremos el proyecto 015.Irony.Interpreter.csproj, debemos abrir este proyecto con Visual Studio. Al tener abierto el proyecto en Visual Studio, procedemos a dar click derecho en el nombre del proyecto → “Build Solution” en el nombre del . Luego de haber ejecutado exitosamente la opción “Build Solution” se creará la carpeta bin/Debug dentro de la carpeta del proyecto Irony.Interpreter. Encontraremos en esta carpeta generada dos carpetas: net40, netstandard2.0. Nosotros escogeremos la carpeta net40, que corresponde a .NET Framework 4.0, nosotros escogeremos esta que sería la versión más reciente, que además es compatible con el proyecto que crearemos en Visual Studio 2017. Dentro de la carpeta net40 encontraremos el archivo Irony.dll, que utilizaremos en nuestro proyecto. Creación del proyecto en el que utilizaremos Irony Abrimos Visual Studio y seleccionamos la opción “File” → “New” → “Project…”. Una vez abierto el wizard para crear nuevos proyectos seleccionamos el apartado “Visual C#” → “Windows Desktop” → “Console App (.NET Framework)” y le pondremos como nombre ProyectoIronyCS. Posteriormente creamos una carpeta lib dentro de nuestro proyecto, para ello vamos al explorador de soluciones y hacemos click derecho en el nombre del proyecto, “Add” → “New Folder”. En la carpeta lib recién creada, pegamos el archivo Irony.dll anteriormente generado. Luego de pegar el archivo Irony.dll, volvemos al explorador de soluciones y damos click derecho en la carpeta lib, “Add” → “Existing Item…”. Buscamos el archivo Irony.dll que acabamos de pegar en la carpeta lib y lo agregamos. Importamos la librería Irony.dll que acabamos de pegar en nuestra carpeta lib, para hacerlo daremos click derecho en “References” → “Add Reference…” Esto nos desplegara una nueva ventana, seleccionamos la opción “Browse…” y seleccionamos nuestro archivo .dll y daremos click en aceptar. Creación de la gramática La creación de la gramática se realiza por medio de un archivo .cs, para ello agregaremos primero una carpeta a la solución con el nombre de analizador, esto no es completamente necesario, lo hacemos para tener el código organizado.Para crear la carpeta es clic derecho sobre el nombre de nuestro proyecto en el explorador de soluciones. “Add” → “New Folder”, le asignamos el nombre “analizador”. Dentro de la carpeta creamos una nueva clase de nombre “Gramatica” que contendrá toda la gramática para Irony, para ello hacemos click derecho sobre la carpeta “Add” → “Class”. En la clase “Gramatica” incorporamos el código de la gramática correspondiente a este ejemplo, dicho código puede consultarse en el repositorio. Explicación de la gramática creada A continuación se explican los principales elementos de la clase gramática: Se importan las librerías de Irony a utilizar 12using Irony.Ast;using Irony.Parsing; Nos aseguramos de que la clase “Gramatica” herede de la clase “Grammar” de Irony.Parsing. 1class Gramatica : Grammar Una de las principales características de Irony es poder organizar todo en regiones, para crear una región se debe escribir el nombre de la región de la siguiente manera: Se comienza la región con “#region ” seguido del nombre de la región Se finaliza la región con “#endregion” Para la gramática anterior se definen las siguientes regiones: ER: Expresiones regulares de los tokens que nuestra gramática reconocerá. Terminales: Conjunto de terminales que serán utilizados en nuestra gramática, que no fueron aceptados por ninguna de las expresiones regulares definidas anteriormente. No terminales: Conjunto de no terminales que serán utilizados en nuestra gramática. Gramática: Región donde se define la gramática. Preferencia: Configuraciones especiales necesarias para el uso de Irony. La gramática debe reconocer números enteros y decimales, por lo que creamos las expresiones regulares para reconocer estos tokens. Para ello se crean objetos del tipo “RegexBasedTerminal”, el cual recibirá de parámetros: el nombre con que se va a reducir y la expresión regular a cumplir. 1var NUMERO = new NumberLiteral(&quot;Numero&quot;); Posteriormente se escriben los terminales, para estos no es necesario escribir expresiones regulares pues son caracteres simples o bien palabras reservadas por esta razón es que no se incluyeron en la región ER. Para definir los terminales se crean variables instanciadas con la función “ToTerm”, que recibe de parámetro el símbolo terminal con el que debe de cumplir, para el ejemplo se definieron los siguientes: 12345678910var REVALUAR = ToTerm(&quot;Evaluar&quot;);var PTCOMA = ToTerm(&quot;;&quot;);var PARIZQ = ToTerm(&quot;(&quot;);var PARDER = ToTerm(&quot;)&quot;);var CORIZQ = ToTerm(&quot;[&quot;);var CORDER = ToTerm(&quot;]&quot;);var MAS = ToTerm(&quot;+&quot;);var MENOS = ToTerm(&quot;-&quot;);var POR = ToTerm(&quot;*&quot;);var DIVIDIDO = ToTerm(&quot;/&quot;); Se agrega precedencia a los operadores aritméticos, esto se hace con la función “RegisterOperators” que recibe como parámetro el nivel de precedencia y la lista de terminales que corresponde a dicho nivel. 12RegisterOperators(1, MAS, MENOS);RegisterOperators(2, POR, DIVIDIDO); Se crean los No Terminales para nuestra gramática, para esta declaración se deben crear objetos de tipo “NonTerminal” que en su constructor recibe de parámetro el nombre del no terminal. 1234NonTerminal ini = new NonTerminal(&quot;ini&quot;);NonTerminal instruccion = new NonTerminal(&quot;instruccion&quot;);NonTerminal instrucciones = new NonTerminal(&quot;instrucciones&quot;);NonTerminal expresion = new NonTerminal(&quot;expresion&quot;); Con lo anterior definido, se crea la gramática, para ello es importante resaltar los siguientes puntos: Toda producción debe iniciar con el nombre de algún no terminal previamente declarado y el atributo Rule “Produccion.Rule”. Se finalizan las producciones con punto y coma. Se pueden tener diferentes producciones en un solo no terminal, para ello cada una de ellas se separa con un “|”. Para concatenar terminales o no terminales a la producción se debe usar siempre el signo “+”. Gramática utilizada: 1234567891011121314ini.Rule = instrucciones;instrucciones.Rule = instruccion + instrucciones | instruccion;instruccion.Rule = REVALUAR + CORIZQ + expresion + CORDER + PTCOMA;expresion.Rule = MENOS + expresion | expresion + MAS + expresion | expresion + MENOS + expresion | expresion + POR + expresion | expresion + DIVIDIDO + expresion | NUMERO | PARIZQ + expresion + PARDER; Para finalizar, es necesario declarar nuestra producción de inicio, para ello asignamos al atributo Root el no terminal con el cual comenzara nuestra gramática. 1this.Root = ini; Recorrido del AST Para realizar este recorrido se crea la clase “Sintactico” dentro de la carpeta analizador, tal como creamos la clase “Gramatica”: El código de la clase “Sintactico”, puede consultarse en el repositorio. A continuación analizaremos el contenido de la clase “Sintactico”, pero antes de continuar es necesario tener presentes los siguientes conceptos de Irony: ParseTree: AST devuelto por Irony que será posteriormente recorrido y analizado. ParseTreeNode: Cada uno de los nodos del ParseTree, el atributo mas importante de este nodo es: ChildNodes: Atributo de cada ParseTreeNode, este atributo es de tipo Array y contiene todas las cualidades de una lista, tales como Count, ElementAt, etc. Si esta lista esta vacía significa que el nodo es un nodo hoja, caso contrario es un subárbol. Como ya hemos mencionado, Irony no acepta acciones entre sus producciones, se limita a devolver el AST (Abstract Syntax Tree) que arma luego de ser aceptada la cadena de entrada. Dentro de la clase “Sintactico”, podemos encontrar el método analizar para cargar el árbol y disparar el recorrido de dicho árbol a través de una llamada al método instrucciones a la que se le manda el nodo raíz del árbol. 1234567891011public void analizar(String cadena){ Gramatica gramatica = new Gramatica(); LanguageData lenguaje = new LanguageData(gramatica); Parser parser = new Parser(lenguaje); ParseTree arbol = parser.Parse(cadena); ParseTreeNode raiz = arbol.Root; instrucciones(raiz.ChildNodes.ElementAt(0));} En el método tenemos lo siguiente: Declarar un objeto de la clase que contiene nuestra gramática, en este caso será un objeto de la clase “Gramatica”. Crear un objeto de la clase “LanguageData”, el cual recibirá de parámetro la variable de nuestra gramática. Crear un objeto de la clase “Parser”, el cual recibirá de parámetro la variable de la clase “LenguageData”. Obtener el AST (Abstract Syntax Tree) de la entrada procesada creando un objeto de la clase “ParseTree”. Obtener la raíz del árbol con el atributo “root” del ParseTree, este es un objeto de tipo “ParseTreeNode” y contiene toda la información del nodo, en este caso el nodo raíz. Invocar el método instrucciones enviándole como parámetro el nodo raíz del AST. Para recorrer el AST (Abstract Syntax Tree) es importante comprender cómo está armado según la gramática definida. Para la entrada: “Evaluar[1+1];”, por ejemplo, el árbol que arma nuestra gramática es: Analizando la imagen con la estructura del árbol tenemos que: Los No terminales se guardan en el nodo únicamente con el nombre que se les dio para reducir al momento de declararlos. Los Terminales se guardan junto a un Keyword. Los Token dados con expresiones regulares, guardan el valor original con que coincidió la ER, seguido del nombre que se le dio para reducir. Teniendo lo anterior en cuenta creamos dentro de la clase “Sintactico” un set de funciones representativas para cada producción, estas siempre recibirán como parámetro el nodo padre y usaran la información almacenada en los nodos para ejecutar las acciones correspondientes. Para las producciones del no terminal “instrucciones”, tenemos la siguiente función: 12345678910public void instrucciones(ParseTreeNode actual) { if (actual.ChildNodes.Count == 2) { instruccion(actual.ChildNodes.ElementAt(0)); instrucciones(actual.ChildNodes.ElementAt(1)); } else { instruccion(actual.ChildNodes.ElementAt(0)); }} En nuestra gramática, el no terminal “instrucciones”, contaba con 2 posibles producciones, una en la cual tenia dos hijos y en la otra solamente uno, con esta información y usando la propiedad ChildNodes, hacemos el recorrido de esa producción, haciendo llamadas a otras funciones según el no terminal encontrado. Para la producción del no terminal “instruccion”, tendremos la siguiente función: 123public void instruccion(ParseTreeNode actual) { Console.WriteLine(&quot;El valor de la expresion es: &quot; + expresion(actual.ChildNodes.ElementAt(2)));} Este no terminal posee solamente una producción, por lo cual no es necesario evaluar condiciones para determinar qué método debe ejecutar posteriormente. Este método imprime “El valor de la expresión es:”, seguido del resultado que nos devuelve la llamada a expresión. Para la producción de “expresion”, tendremos la siguiente función: 1234567891011121314151617181920212223242526public double expresion(ParseTreeNode actual) { if (actual.ChildNodes.Count == 3) { string tokenOperador = actual.ChildNodes.ElementAt(1).ToString().Split(' ')[0]; switch (tokenOperador) { case &quot;+&quot;: return expresion(actual.ChildNodes.ElementAt(0)) + expresion(actual.ChildNodes.ElementAt(2)); case &quot;-&quot;: return expresion(actual.ChildNodes.ElementAt(0)) - expresion(actual.ChildNodes.ElementAt(2)); case &quot;*&quot;: return expresion(actual.ChildNodes.ElementAt(0)) * expresion(actual.ChildNodes.ElementAt(2)); case &quot;/&quot;: return expresion(actual.ChildNodes.ElementAt(0)) / expresion(actual.ChildNodes.ElementAt(2)); default: return expresion(actual.ChildNodes.ElementAt(1)); } } else if (actual.ChildNodes.Count == 2) { return -1 * expresion(actual.ChildNodes.ElementAt(1)); } else { return Double.Parse(actual.ChildNodes.ElementAt(0).ToString().Split(' ')[0]); }} Como en los casos anteriores, debemos plantear condiciones para determinar qué producción se está reconociendo, estas condiciones pueden basarse en la cantidad de hijos de la producción. Si tiene un hijo se trata de un número entero o decimal, por lo cual retornamos únicamente el valor del número. Si tiene dos hijos es la producción de “menos &lt;expresión&gt;” por lo cual multiplicamos el valor de la expresión por menos uno. Si tiene 3 hijos puede tratarse de una suma, resta, multiplicación o división, para determinar de cuál se trata, recogemos el valor del hijo de en medio que contiene el operador y ejecutamos según corresponda, esto se hace dentro de la sentencia switch del método. Interpretación del archivo de entrada Esta interpretación se ejecuta dentro del método Main de la clase “Program” que se creo automáticamente en nuestro proyecto. En esta clase se importa la referencia a la carpeta analizador para poder usar la clase Sintactico recién creada: 1using ProyectoIronyCS.sol.com.analizador; Y en el método Main encontramos lo siguiente: 123string text = System.IO.File.ReadAllText(Path.Combine(AppDomain.CurrentDomain.BaseDirectory, @&quot;..\\..\\input&quot;, &quot;entrada.txt&quot;));Sintactico sintac = new Sintactico();sintac.analizar(text); Estos comandos realizan las siguientes acciones: Cargar el contenido del archivo “entrada.txt” que debe ser creado dentro de la carpeta /input que también debemos crear dentro de nuestro proyecto. Crear el analizador sintáctico a utilizar Analizar el texto del archivo de entrada El archivo de “entrada.txt” tiene el siguiente contenido: 12345Evaluar[1+1];Evaluar[1+1*2];Evaluar[-(1+1*6/3-5+7)];Evaluar[-(1+1*6/3-5+1*-2)];Evaluar[-(1+1)]; Y tras analizarlo con nuestra solución genera la siguiente salida: Como podemos ver, obtenemos la salida esperada. Y el AST que formaría dicha entrada sería: Acerca del autor:Este tutorial fue elaborado por el Auxiliar de Cátedra Julio Arango, como contribución al curso de Organización de Lenguajes y Compiladores 2 de la Universidad de San Carlos de Guatemala. Fuentes consultadas:Compiladores, principios, técnicas y herramientas. Aho, Lam, Sethi y Ullman. Segunda Edición.","link":"/2019/07/24/19-Mi-primer-proyecto-utilizando-Irony-Windows/"},{"title":"Intérprete sencillo utilizando Jison con Nodejs (Ubuntu)","text":"Funcionamiento de la aplicaciónEn este tutorial se desarrolla un intérprete que recibe como entrada un archivo de texto que contiene varias sentencias de un lenguaje de programación diseñado especialmente para esta aplicación. Primero se hace análisis léxico y sintáctico de dicha entrada, durante el análisis sintáctico se carga en memoria un Árbol de Sintaxis Abstracta (AST) que se utiliza posteriormente para ejecutar las sentencias. El analizador se genera con Jison utilizando Nodejs en Ubuntu 18.04. El proyecto completo puede descargarse del siguiente enlace: Intérprete sencillo utilizando Jison con Nodejs (Ubuntu) Todo el código del proyecto está documentado con comentarios que contienen los detalles de su funcionamiento. Si se desea una introducción sobre el uso de Jison con Nodejs pueden visitar el post: Mi primer proyecto utilizando Jison (Linux) en el cual se describe los pre-requisitos y cómo crear un proyecto utilizando npm. El lenguaje de entradaDentro de la carpeta del proyecto, hay un archivo de entrada llamado entrada.txt en el cual se muestran ejemplos de todas las funciones del lenguaje diseñado para esta aplicación, al leerlo se puede tener una idea clara de las funciones con las que el lenguaje cuenta, este archivo contiene lo siguiente: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364/****************************************** * Ejemplo desarrollado por Erick Navarro * * GitHub Page: ericknavarro.github.io * * Septiembre - 2015 * ******************************************///Se imprime el encabezadoimprimir(&quot;Tablas de&quot; &amp; &quot; multiplicar&quot;);//Se declara la variable a, de tipo numeronumero a;//Se asigna a la variable a el valor 0a=0;//Se declara la variable c, de tipo numeronumero c;//Se asigna a la variable c el valor 0c=1;//Se imprime un separadorimprimir(&quot;----------------&quot;);/** * Se imprimen las tablas del 1 al 5 y * para cada tabla, se imprimen los resultados * desde el uno hasta el 5, esto se hace con * dos ciclos while anidados. **/mientras(a&lt;4+c){ a=a+1; numero b; b=0; mientras(b&lt;4+c){ b=b+1; imprimir(a &amp; &quot; * &quot; &amp; b &amp; &quot; = &quot; &amp; a * b); } imprimir(&quot;----------------&quot;);}//Se asigna a la variable a el valor de 11a=11;/** * La variable b ya había sido declarada pero * dentro del ámbito del primer ciclo while, * entonces no existe en este ámbito por lo que * debe declararse. **/numero b;//Se asigna valor de 12 a b y valor de 13 a cb=12;c=13;/** * Se evalua si el valor de la variable a es * mayor que 10, si el b es mayor que 11 y si * el de c es mayor que 12. **/If(a&gt;10){ imprimir(&quot;a es mayor que 10.&quot;); if(b&gt;11){ imprimir(&quot;a es mayor que 10 y b es mayor que 11.&quot;); if(c&gt;12){ imprimir(&quot;a es mayor que 10, b es mayor que 11 y c es mayor que 12.&quot;); } }}else{ imprimir(&quot;a es menor o igual que 10.&quot;);} Como se puede observar, el lenguaje acepta: Comentarios simples, es decir de una sola línea (//) Comentarios múltiples, es decir de más de una línea (/* */) Concatenación de cadenas, mediante el operador &amp; Función Imprimir: Recibe como parámetro una cadena e imprime su valor en consola. Declaración de variables: Únicamente se acepta definición de variables de tipo numero incluyendo enteros y decimales. Asignación de variables: A cualquier variable se le puede asignar cualquier expresión que tenga como resultado un número. Instrucción Mientras: Tiene el comportamiento clásico del ciclo while, ejecuta el ciclo mientras la expresión booleana que recibe sea verdadera. Esta instrucción soporta anidamiento. Instrucción If e If-Else: Tiene el comportamiento clásico de las sentencias de selección If e If-Else, evalúa la expresión booleana y ejecuta el bloque de instrucciones en If si es verdadera. En caso contrario y si existe un bloque Else se ejecuta este bloque de instrucciones. Estas instrucciones también soportan anidamiento. Expresiones aritméticas: Se soportan las expresiones aritméticas binarias: suma, resta, multiplicación y división. También la expresión unaria: negación. Adicionalmente se soporta expresiones agrupadas en paréntesis. Se maneja la precedencia habitual de las expresiones aritméticas. Expresiones booleanas: Comparan dos expresiones que tengan como resultado un número y soportan unicamente los operados mayor que y menor que (&lt;, &gt;). El analizador léxico y sintáctico En el archivo gramatica.jison detallamos la estructura del lenguaje utilizando Jison. A continuación detallaremos los aspectos más relevantes. Sobre el analizador léxico El analizador léxico define los patrones para los tokens que deseamos reconocer. Hacemos uso de expresiones regulares para identificar números, cadenas y comentarios. 1234\\&quot;[^\\&quot;]*\\&quot; { yytext = yytext.substr(1,yyleng-2); return 'CADENA'; }[0-9]+(&quot;.&quot;[0-9]+)?\\b return 'DECIMAL';[0-9]+\\b return 'ENTERO';([a-zA-Z])[a-zA-Z0-9_]* return 'IDENTIFICADOR'; Nótese que los comentarios son tratados de la misma manera que los espacios en blanco, no retornamos ningún valor. 123\\s+ // se ignoran espacios en blanco&quot;//&quot;.* // comentario simple línea[/][*][^*]*[*]+([^/*][^*]*[*]+)*[/] // comentario multiple líneas Sobre el analizador sintáctico El objetivo principal de nuestro analizador sintáctico es validar que la entrada sea válida y, si lo es, construir el AST (Abstract Syntax Tree). Para lograr esto hacemos uso de funciones utilitarias definidas en un API externa. Esta API contiene toda la lógica necesaria para crear el AST, la idea es centralizar toda esta funcionalidad en un solo lugar, evitando redundancia de funcionalidad y así evitar cometer errores. Esto también es posible gracias a Nodejs ya que nos permite incluir esta funcionalidad en nuestro script para generar nuestro parser. La API de Instrucciones Una de las ventajas de usar Nodejs con Jison es que podemos exportar porciones de scripts de un archivo hacia otro. Para nuestra API definimos constantes y funciones que nos ayudan durante la construcción del AST. Nuestra API se encuentra en el archivo instrucciones.js. El uso de constantes es altamente recomendado, a través de estos podemos evitar bugs durante el desarrollo. Para este tutorial definimos constantes para los tipos de valores que soporta nuestro lenguaje: números, cadenas e identificadores. También definimos constantes para los tipos de operaciones soportadas y las instrucciones válidas. 12345678910111213141516171819202122232425262728// Constantes para los tipos de 'valores' que reconoce nuestra gramática.const TIPO_VALOR = { NUMERO: 'VAL_NUMERO', IDENTIFICADOR: 'VAL_IDENTIFICADOR', CADENA: 'VAL_CADENA',}// Constantes para los tipos de 'operaciones' que soporta nuestra gramática.const TIPO_OPERACION = { SUMA: 'OP_SUMA', RESTA: 'OP_RESTA', MULTIPLICACION: 'OP_MULTIPLICACION', DIVISION: 'OP_DIVISION', NEGATIVO: 'OP_NEGATIVO', MAYOR_QUE: 'OP_MAYOR_QUE', MENOR_QUE: 'OP_MENOR_QUE', CONCATENACION: 'OP_CONCATENACION'};// Constantes para los tipos de 'instrucciones' válidas en nuestra gramática.const TIPO_INSTRUCCION = { IMPRIMIR: 'INSTR_IMPRIMIR', MIENTRAS: 'INSTR_MIENTRAS', DECLARACION: 'INSTR_DECLARACION', ASIGNACION: 'INSTR_ASIGANCION', IF: 'INSTR_IF', IF_ELSE: 'INSTR_ELSE'} Seguidamente, tenemos la definición de una función llamada nuevaOperacion. Nótese que esta función está fuera de nuestra API, es decir no es pública, es para uso interno. Esta función crea objetos genéricos para las operaciones. 123456789101112131415/** * Esta función se encarga de crear objetos tipo Operación. * Recibe como parámetros el operando izquierdo y el operando derecho. * También recibe como parámetro el tipo del operador * @param {*} operandoIzq * @param {*} operandoDer * @param {*} tipo */function nuevaOperacion(operandoIzq, operandoDer, tipo) { return { operandoIzq: operandoIzq, operandoDer: operandoDer, tipo: tipo }} La definición de funciones con tareas genéricas también es recomendable para evitar errores. Finalmente, está la definición de nuestra API. En nuestra API tenemos tres tipos de funciones: Funciones para Operaciones. Funciones para Valores Funciones para Instrucciones. Cada una de estas funciones representa un Nodo en el AST. Las funciones para operaciones hacen uso de nuestra función privada, de esta forma logramos que nuestros objetos de tipo Operación tengan la misma estructura. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113/** * El objetivo de esta API es proveer las funciones necesarias para la construcción de operaciones e instrucciones. */const instruccionesAPI = { /** * Crea un nuevo objeto tipo Operación para las operaciones binarias válidas. * @param {*} operandoIzq * @param {*} operandoDer * @param {*} tipo */ nuevoOperacionBinaria: function(operandoIzq, operandoDer, tipo) { return nuevaOperacion(operandoIzq, operandoDer, tipo); }, /** * Crea un nuevo objeto tipo Operación para las operaciones unarias válidas * @param {*} operando * @param {*} tipo */ nuevoOperacionUnaria: function(operando, tipo) { return nuevaOperacion(operando, undefined, tipo); }, /** * Crea un nuevo objeto tipo Valor, esto puede ser una cadena, un número o un identificador * @param {*} valor * @param {*} tipo */ nuevoValor: function(valor, tipo) { return { tipo: tipo, valor: valor } }, /** * Crea un objeto tipo Instrucción para la sentencia Imprimir. * @param {*} expresionCadena */ nuevoImprimir: function(expresionCadena) { return { tipo: TIPO_INSTRUCCION.IMPRIMIR, expresionCadena: expresionCadena }; }, /** * Crea un objeto tipo Instrucción para la sentencia Mientras. * @param {*} expresionLogica * @param {*} instrucciones */ nuevoMientras: function(expresionLogica, instrucciones) { return { tipo: TIPO_INSTRUCCION.MIENTRAS, expresionLogica: expresionLogica, instrucciones: instrucciones }; }, /** * Crea un objeto tipo Instrucción para la sentencia Declaración. * @param {*} identificador */ nuevoDeclaracion: function(identificador) { return { tipo: TIPO_INSTRUCCION.DECLARACION, identificador: identificador } }, /** * Crea un objeto tipo Instrucción para la sentencia Asignación. * @param {*} identificador * @param {*} expresionNumerica */ nuevoAsignacion: function(identificador, expresionNumerica) { return { tipo: TIPO_INSTRUCCION.ASIGNACION, identificador: identificador, expresionNumerica: expresionNumerica } }, /** * Crea un objeto tipo Instrucción para la sentencia If. * @param {*} expresionLogica * @param {*} instrucciones */ nuevoIf: function(expresionLogica, instrucciones) { return { tipo: TIPO_INSTRUCCION.IF, expresionLogica: expresionLogica, instrucciones: instrucciones } }, /** * Crea un objeto tipo Instrucción para la sentencia If-Else. * @param {*} expresionLogica * @param {*} instruccionesIfVerdadero * @param {*} instruccionesIfFalso */ nuevoIfElse: function(expresionLogica, instruccionesIfVerdadero, instruccionesIfFalso) { return { tipo: TIPO_INSTRUCCION.IF_ELSE, expresionLogica: expresionLogica, instruccionesIfVerdadero: instruccionesIfVerdadero, instruccionesIfFalso: instruccionesIfFalso } }} Para poder utilizar las constantes y el API fuera de este archivo utilizamos la instrucción “module.exports” con el cual exportamos todo lo que deseamos que sea público 123456// Exportamos nuestras constantes y nuestra APImodule.exports.TIPO_OPERACION = TIPO_OPERACION;module.exports.TIPO_INSTRUCCION = TIPO_INSTRUCCION;module.exports.TIPO_VALOR = TIPO_VALOR;module.exports.instruccionesAPI = instruccionesAPI; Construcción del AST Para construir el AST durante nuestro análisis sintáctico importamos nuestra API y las constantes. Esto lo hacemos dentro de los símbolos “%{“ y “}%” en el archivo gramatica.jison 12345%{ const TIPO_OPERACION = require('./instrucciones').TIPO_OPERACION; const TIPO_VALOR = require('./instrucciones').TIPO_VALOR; const instruccionesAPI = require('./instrucciones').instruccionesAPI;%} Una vez importemos nuestras constantes y funciones ya podemos hacer uso de ellas en la gramática. Por ejemplo, para la construcción de operaciones aritméticas hacemos uso de la función nuevoOperacionBinaria de nuestra API de Instrucciones, pasamos como parámetros los operandos y el tipo operación (utilizando nuestras constantes). 1234567891011expresion_numerica : MENOS expresion_numerica %prec UMENOS { $$ = instruccionesAPI.nuevoOperacionUnaria($2, TIPO_OPERACION.NEGATIVO); } | expresion_numerica MAS expresion_numerica { $$ = instruccionesAPI.nuevoOperacionBinaria($1, $3, TIPO_OPERACION.SUMA); } | expresion_numerica MENOS expresion_numerica { $$ = instruccionesAPI.nuevoOperacionBinaria($1, $3, TIPO_OPERACION.RESTA); } | expresion_numerica POR expresion_numerica { $$ = instruccionesAPI.nuevoOperacionBinaria($1, $3, TIPO_OPERACION.MULTIPLICACION); } | expresion_numerica DIVIDIDO expresion_numerica { $$ = instruccionesAPI.nuevoOperacionBinaria($1, $3, TIPO_OPERACION.DIVISION); } | PARIZQ expresion_numerica PARDER { $$ = $2; } | ENTERO { $$ = instruccionesAPI.nuevoValor(Number($1), TIPO_VALOR.NUMERO); } | DECIMAL { $$ = instruccionesAPI.nuevoValor(Number($1), TIPO_VALOR.NUMERO); } | IDENTIFICADOR { $$ = instruccionesAPI.nuevoValor($1, TIPO_VALOR.IDENTIFICADOR); }; También hacemos uso de la función nuevoValor para las expresiones con valor. El proceso es el mismo para las Instrucciones, cada producción de tipo Instrucción invoca a su función designada en nuestra API. 12345678910instruccion : RIMPRIMIR PARIZQ expresion_cadena PARDER PTCOMA { $$ = instruccionesAPI.nuevoImprimir($3); } | RMIENTRAS PARIZQ expresion_logica PARDER LLAVIZQ instrucciones LLAVDER { $$ = instruccionesAPI.nuevoMientras($3, $6); } | RNUMERO IDENTIFICADOR PTCOMA { $$ = instruccionesAPI.nuevoDeclaracion($2); } | IDENTIFICADOR IGUAL expresion_numerica PTCOMA { $$ = instruccionesAPI.nuevoAsignacion($1, $3); } | RIF PARIZQ expresion_logica PARDER LLAVIZQ instrucciones LLAVDER { $$ = instruccionesAPI.nuevoIf($3, $6); } | RIF PARIZQ expresion_logica PARDER LLAVIZQ instrucciones LLAVDER RELSE LLAVIZQ instrucciones LLAVDER { $$ = instruccionesAPI.nuevoIf($3, $6, $10); } | error { console.error('Este es un error sintáctico: ' + yytext + ', en la linea: ' + this._$.first_line + ', en la columna: ' + this._$.first_column); }; Finalmente, una vez que hayamos reconocido toda la entrada, construimos un arreglo con cada uno de los nodos. Este será nuestro AST. 1234567891011ini : instrucciones EOF { // cuado se haya reconocido la entrada completa retornamos el AST return $1; };instrucciones : instrucciones instruccion { $1.push($2); $$ = $1; } | instruccion { $$ = [$1]; }; Para generar el parser ejecutamos el script compilar.sh dentro de nuestro proyecto 1$ sh compilar.sh Esto generará el script gramatica.js con el cual ya podremos procesar nuestro archivo de entrada. La tabla de símbolos La tabla de símbolos es la que permite el almacenamiento y recuperación de los valores de las variables. Para su implementación hacemos uso de una clase, ya que necesitaremos más de una instancia de tabla de símbolos. Cada ámbito tiene acceso únicamente a su propia tabla de símbolos y a la de los niveles superiores. Definimos las constantes para los tipos de datos, en este tutorial se hace uso únicamente del tipo de dato numérico. 1234// Constantes para los tipos de datos.const TIPO_DATO = { NUMERO: 'NUMERO'} Se define una función para crear objetos de tipo Símbolo. 12345678910111213/** * Función que crea objetos de tipo Símbolo. * @param {*} id * @param {*} tipo * @param {*} valor */function crearSimbolo(id, tipo, valor) { return { id: id, tipo: tipo, valor: valor }} La clase TS define las estructura de una tabla de símbolos y sus funciones para agregar, modificar y obtener símbolos. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/** * Clase que representa una Tabla de Símbolos. */class TS { /** * El costructor recibe como parámetro los simbolos de la tabla padre. * @param {*} simbolos */ constructor (simbolos) { this._simbolos = simbolos; } /** * Función para gregar un nuevo símbolo. * Esta función se usa en la sentencia de Declaración. * @param {*} id * @param {*} tipo */ agregar(id, tipo) { const nuevoSimbolo = crearSimbolo(id, tipo); this._simbolos.push(nuevoSimbolo); } /** * Función para actualizar el valor de un símbolo existente. * Esta función se usa en la sentencia de Asignación. * @param {*} id * @param {*} valor */ actualizar(id, valor) { const simbolo = this._simbolos.filter(simbolo =&gt; simbolo.id === id)[0]; if (simbolo) simbolo.valor = valor; else throw 'ERROR: variable: ' + id + ' no ha sido definida'; } /** * Función para obtener el valor de un símbolo existente. * @param {*} id */ obtener(id) { const simbolo = this._simbolos.filter(simbolo =&gt; simbolo.id === id)[0]; if (simbolo) return simbolo.valor; else throw 'ERROR: variable: ' + id + ' no ha sido definida'; } /** * Función getter para obtener los símbolos. */ get simbolos() { return this._simbolos; }} Finalmente, exportamos las constantes y la clase 1234// Exportamos las constantes y la clase.module.exports.TIPO_DATO = TIPO_DATO;module.exports.TS = TS; Construcción del Intérprete La definición del Intérprete se encuentra en el archivo interprete.js. Para iniciar con la implementación, primero importamos el parser, las constantes del AST y de la Tabla de Símbolos. 1234567891011var fs = require('fs'); var parser = require('./gramatica');// Constantes para operaciones, instrucciones y valoresconst TIPO_INSTRUCCION = require('./instrucciones').TIPO_INSTRUCCION;const TIPO_OPERACION = require('./instrucciones').TIPO_OPERACION;const TIPO_VALOR = require('./instrucciones').TIPO_VALOR;// Tabla de Simbolosconst TIPO_DATO = require('./tabla_simbolos').TIPO_DATO;const TS = require('./tabla_simbolos').TS; Seguidamente, obtenemos el AST a partir del archivo de entrada. 12345678910111213let ast;try { // leemos nuestro archivo de entrada const entrada = fs.readFileSync('./entrada.txt'); // invocamos a nuestro parser con el contendio del archivo de entradas ast = parser.parse(entrada.toString()); // imrimimos en un archivo el contendio del AST en formato JSON fs.writeFileSync('./ast.json', JSON.stringify(ast, null, 2));} catch (e) { console.error(e); return;} Nótese que se escribe el contenido del AST en un archivo llamado ast.json en formato JSON, esto no es necesario, pero es una forma de ver el contenido del AST en un formato entendible. El contenido del formato JSON se puede visualizar en cualquier herramienta. Por ejemplo la extensión de Google Chrome JSON Viewer Awesome. El cual cuenta con una vista gráfica y nos permite visualizar el AST así como también navegar por sus nodos La función principal del intérprete es de reconocer cada instrucción instrucción y ejecutarla, para esto es necesario recorrer el AST; es por ello que se ha definido la función procesarBloque el cual itera las instrucciones en un ámbito y las ejecuta. Para iniciar con la ejecución se crea la tabla de símbolos para el ámbito global y se invoca la función procesarBloque con la raíz del AST y la tabla de símbolos del ámbito global. 123456789101112131415161718192021222324252627282930313233343536373839// Creación de una tabla de simbolos GLOBAL para iniciar con el interpreteconst tsGlobal = new TS([]);// Procesamos las instrucciones reconocidas en nuestro ASTprocesarBloque(ast, tsGlobal);/** * Este es el método principal. Se encarga de recorrer las instrucciones en un bloque, * identificarlas y procesarlas * @param {*} instrucciones * @param {*} tablaDeSimbolos */function procesarBloque(instrucciones, tablaDeSimbolos) { instrucciones.forEach(instruccion =&gt; { if (instruccion.tipo === TIPO_INSTRUCCION.IMPRIMIR) { // Procesando Instrucción Imprimir procesarImprimir(instruccion, tablaDeSimbolos); } else if (instruccion.tipo === TIPO_INSTRUCCION.MIENTRAS) { // Procesando Instrucción Mientras procesarMientras(instruccion, tablaDeSimbolos); } else if (instruccion.tipo === TIPO_INSTRUCCION.DECLARACION) { // Procesando Instrucción Declaración procesarDeclaracion(instruccion, tablaDeSimbolos); } else if (instruccion.tipo === TIPO_INSTRUCCION.ASIGNACION) { // Procesando Instrucción Asignación procesarAsignacion(instruccion, tablaDeSimbolos); } else if (instruccion.tipo === TIPO_INSTRUCCION.IF) { // Procesando Instrucción If procesarIf(instruccion, tablaDeSimbolos); } else if (instruccion.tipo === TIPO_INSTRUCCION.IF_ELSE) { // Procesando Instrucción If Else procesarIfElse(instruccion, tablaDeSimbolos); } else { throw 'ERROR: tipo de instrucción no válido: ' + instruccion; } });} Existe una función para procesar cada instrucción. Las sentencias Mientras, If e If-Else crean nuevas tablas de símbolos antes de procesar las instrucciones dentro de sus bloques de instrucciones. Estas nuevas tablas de símbolos se inicializan con los valores de la tabla de símbolo actual y al terminar la ejecución de la sentencia los valores son eliminados ya que la instancia se crea localmente en el cuerpo de la función. 1234567891011121314151617181920212223242526272829303132333435363738/** * Función que se encarga de procesar la instrucción Mientras */function procesarMientras(instruccion, tablaDeSimbolos) { while (procesarExpresionLogica(instruccion.expresionLogica, tablaDeSimbolos)) { const tsMientras = new TS(tablaDeSimbolos.simbolos); procesarBloque(instruccion.instrucciones, tsMientras); }}/** * Función que se encarga de procesar la instrucción If */function procesarIf(instruccion, tablaDeSimbolos) { const valorCondicion = procesarExpresionLogica(instruccion.expresionLogica, tablaDeSimbolos); if (valorCondicion) { const tsIf = new TS(tablaDeSimbolos.simbolos); procesarBloque(instruccion.instrucciones, tsIf); }}/** * Función que se encarga de procesar la instrucción If-Else * @param {*} instruccion * @param {*} tablaDeSimbolos */function procesarIfElse(instruccion, tablaDeSimbolos) { const valorCondicion = procesarExpresionLogica(instruccion.expresionLogica, tablaDeSimbolos); if (valorCondicion) { const tsIf = new TS(tablaDeSimbolos.simbolos); procesarBloque(instruccion.instruccionesIfVerdadero, tsIf); } else { const tsElse = new TS(tablaDeSimbolos.simbolos); procesarBloque(instruccion.instruccionesIfFalso, tsElse); }} Las sentencias de Declaración y Asignación agregan y modifican valores de la tabla de símbolos. La sentencia Imprimir muestra el valor de una cadena en la consola. 12345678910111213141516171819202122232425262728/** * Función que se encarga de procesar la instrucción Imprimir * @param {*} instruccion * @param {*} tablaDeSimbolos */function procesarImprimir(instruccion, tablaDeSimbolos) { const cadena = procesarExpresionCadena(instruccion.expresionCadena, tablaDeSimbolos); console.log('&gt; ' + cadena);}/** * Función que se encarga de procesar la instrucción Declaración * @param {*} instruccion * @param {*} tablaDeSimbolos */function procesarDeclaracion(instruccion, tablaDeSimbolos) { tablaDeSimbolos.agregar(instruccion.identificador, TIPO_DATO.NUMERO);}/** * Función que se encarga de procesar la instrucción Asignación * @param {*} instruccion * @param {*} tablaDeSimbolos */function procesarAsignacion(instruccion, tablaDeSimbolos) { const valor = procesarExpresionNumerica(instruccion.expresionNumerica, tablaDeSimbolos) tablaDeSimbolos.actualizar(instruccion.identificador, valor);} Finalmente, todas las sentencias descritas anteriormente hacen uso de las operaciones numéricas, con cadenas y lógicas las cuales hacen uso de la tabla de símbolos para obtener valores de las variables. Para las expresiones numéricas evaluamos el tipo de operación y con base en ellos resolvemos el valor apropiado. 123456789101112131415161718192021222324252627282930313233343536373839404142/** * De acuerdo con nuestra gramática, aqui, expresión puede ser una operación aritmética binaria (SUMA, RESTA, MULTIPLICACION, DIVISION), * una operación aritmética unaria (NEGATIVO) o un valor correspondiente a un NUMERO o a un IDENTIFICADOR * @param {*} expresion * @param {TS} tablaDeSimbolos * Evaluamos cada caso para resolver a un valor tipo número de acuerdo al tipo de operación. */function procesarExpresionNumerica(expresion, tablaDeSimbolos) { if (expresion.tipo === TIPO_OPERACION.NEGATIVO) { // Es un valor negado. // En este caso necesitamos procesar el valor del operando para poder negar su valor. // Para esto invocamos (recursivamente) esta función para sesolver el valor del operando. const valor = procesarExpresionNumerica(expresion.operandoIzq, tablaDeSimbolos); // resolvemos el operando // Retornamos el valor negado. return valor * -1; } else if (expresion.tipo === TIPO_OPERACION.SUMA || expresion.tipo === TIPO_OPERACION.RESTA || expresion.tipo === TIPO_OPERACION.MULTIPLICACION || expresion.tipo === TIPO_OPERACION.DIVISION) { // Es una operación aritmética. // En este caso necesitamos procesar los operandos antes de realizar la operación. // Para esto incovacmos (recursivamente) esta función para resolver los valores de los operandos. const valorIzq = procesarExpresionNumerica(expresion.operandoIzq, tablaDeSimbolos); // resolvemos el operando izquierdo. const valorDer = procesarExpresionNumerica(expresion.operandoDer, tablaDeSimbolos); // resolvemos el operando derecho. if (expresion.tipo === TIPO_OPERACION.SUMA) return valorIzq + valorDer; if (expresion.tipo === TIPO_OPERACION.RESTA) return valorIzq - valorDer; if (expresion.tipo === TIPO_OPERACION.MULTIPLICACION) return valorIzq * valorDer; if (expresion.tipo === TIPO_OPERACION.DIVISION) return valorIzq / valorDer; } else if (expresion.tipo === TIPO_VALOR.NUMERO) { // Es un valor numérico. // En este caso únicamente retornamos el valor obtenido por el parser directamente. return expresion.valor; } else if (expresion.tipo === TIPO_VALOR.IDENTIFICADOR) { // Es un identificador. // Obtenemos el valor de la tabla de simbolos return tablaDeSimbolos.obtener(expresion.valor); } else { throw 'ERROR: expresión numérica no válida: ' + expresion; }} Para las expresiones con cadenas también validamos el tipo de operación para verificar si es necesario una operación de concatenación. En cualquier caso se resuelve la cadena. También es posible concatenar valores numéricos, para esto resolvemos la expresión apoyándonos de la función para procesar expresiones numéricas. 12345678910111213141516171819202122232425262728/** * De acuerdo con nuestra gramática, aqui, expresión puede ser una operacion CONCATENACION, CADENA o una expresión numérica * @param {*} expresion * @param {TS} tablaDeSimbolos * Evaluamos cada caso para resolver a un valor tipo cadena de acuerdo al tipo de operación. */function procesarExpresionCadena(expresion, tablaDeSimbolos) { if (expresion.tipo === TIPO_OPERACION.CONCATENACION) { // Es una operación de concatenación. // En este caso necesitamos procesar los operandos antes de realizar la concatenación. // Para esto invocamos (recursivamente) esta función para resolver los valores de los operandos. const cadIzq = procesarExpresionCadena(expresion.operandoIzq, tablaDeSimbolos); // resolvemos el operando izquierdo. const cadDer = procesarExpresionCadena(expresion.operandoDer, tablaDeSimbolos); // resolvemos el operando derecho. // Retornamos el resultado de la operación de concatenación. return cadIzq + cadDer; } else if (expresion.tipo === TIPO_VALOR.CADENA) { // Es una cadena. // En este caso únicamente retornamos el valor obtenido por el parser directamente. return expresion.valor; } else { // Es una epresión numérica. // En este caso invocamos la función que se encarga de procesar las expresiones numéricas // y retornamos su valor en cadena. return procesarExpresionNumerica(expresion, tablaDeSimbolos).toString() }} Al igual que las expresiones con cadena, las expresiones lógicas también se apoya en la función que procesa expresiones numéricas para poder evaluar las condiciones booleanas. 1234567891011121314/** * De acuerdo con nuestra gramática, aqui, expresión puede ser una operación lógica MAYOR QUE o MENOR QUE * @param {*} expresion * @param {TS} tablaDeSimbolos * Evaluamos cada caso para resolver a un valor tipo booleando de acuerdo al tipo de operación. */function procesarExpresionLogica(expresion, tablaDeSimbolos) { // En este caso necesitamos procesar los operandos antes de realizar la comparación. const valorIzq = procesarExpresionNumerica(expresion.operandoIzq, tablaDeSimbolos); // resolvemos el operando izquierdo. const valorDer = procesarExpresionNumerica(expresion.operandoDer, tablaDeSimbolos); // resolvemos el operando derecho. if (expresion.tipo === TIPO_OPERACION.MAYOR_QUE) return valorIzq &gt; valorDer; if (expresion.tipo === TIPO_OPERACION.MENOR_QUE) return valorIzq &lt; valorDer;} Para ejecutar nuestro intérprete y procesar el archivo de entrada ejecutamos el siguiente comando: 1$ node interprete Y veremos el resultado en consola. Acerca del autor: Este tutorial fue elaborado por el Auxiliar de Cátedra Rainman Sián, como contribución al curso de Organización de Lenguajes y Compiladores 2 de la Universidad de San Carlos de Guatemala. Fuentes consultadas: Compiladores, principios, técnicas y herramientas. Aho, Lam, Sethi y Ullman. Segunda Edición.","link":"/2019/08/01/20-Interprete-sencillo-utilizando-Jison-con-Nodejs-Ubuntu/"},{"title":"Intérprete sencillo utilizando Gold Parser y Visual Basic","text":"En los cursos de compiladores de la universidad, es común que se solicite al estudiante desarrollar un intérprete, una herramienta que reciba como entrada cierto lenguaje de programación y lo ejecute, pero la mayoría de documentación al respecto solo muestra ejemplos de cosas sencillas, como una calculadora o un lenguaje que imprime cadenas en consola. Qué pasa si lo que deseamos es que se ejecuten sentencias de control como el IF o ciclos como la sentencia WHILE y que además estas sentencias soporten muchos niveles de anidamiento, que se declaren variables y se asigne valores a estas variables, que se tenga control de los ámbitos de las variables, en fin, que tenga las funciones básicas de un lenguaje de programación. No es común encontrar este tipo de ejemplos, en lo personal, puedo asegurar que nunca encontré un tutorial en el que se mostrara un ejemplo documentado y bien explicado sobre esto. Por ello es que se elaboró este ejemplo, espero que les sea útil. Funcionamiento de la aplicaciónEn este tutorial se desarrolla un intérprete sencillo que permite ejecutar un archivo de entrada que contiene sentencias tales como declaraciones de variables, sentencias de control, impresiones en consola, etc. El lenguaje de programación fue diseñado especialmente para esta aplicación, primero se hace análisis léxico y sintáctico de dicha entrada asistidos por Gold Parser. Una vez Gold Parser genera el árbol de análisis sintáctico, recorreremos dicho árbol para crear nuestro propio árbol. Todo el código se encuentra comentado, por lo que podremos entender la función específica de cada nodo del árbol. La versión original de este tutorial, realizada con JLex y Cup puede consultarse en el siguiente enlace: Intérprete sencillo utilizando Java, Jlex y Cup El proyecto completo de este ejemplo puede descargarse del siguiente enlace: Intérprete Sencillo Utilizando Gold Parser Diseño utilizado para el desarrollo de este ejemploPara este ejemplo se crea un objeto por cada una de las sentencias que reconoce nuestra gramática, cada objeto implementa la interfaz instruccion que representa un nodo en nuestro árbol. Esto nos permite tratar todas las sentencias como nodos y asignarle acciones específicas a cada uno según su tipo. Se puede entender nuestra gramática de la siguiente forma: El lenguaje de entradaDentro de la carpeta del proyecto podremos acceder a /bin/Debug y allí encontraremos un archivo de entrada llamado “entrada.txt”, en él se muestran ejemplos de todas las funciones del lenguaje diseñado para esta aplicación, al leerlo se puede tener una idea clara de las funciones con las que el lenguaje cuenta, este archivo contiene lo siguiente: Comentarios simples, es decir de una sola línea (//) Comentarios múltiples, es decir de más de una línea (/* */) Concatenación de cadenas, mediante el operador &amp; Función Imprimir: Recibe como parámetro una cadena e imprime su valor en consola. Declaración de variables: Únicamente se acepta definición de variables de tipo numero incluyendo enteros y decimales. Asignación de variables: A cualquier variable se le puede asignar cualquier expresión que tenga como resultado un número. Instrucción Mientras: Tiene el comportamiento clásico del ciclo while, ejecuta el ciclo mientras la expresión booleana que recibe sea verdadera. Esta instrucción soporta anidamiento. Instrucción If e If-Else: Tiene el comportamiento clásico de las sentencias de selección If e If-Else, evalúa la expresión booleana y ejecuta el bloque de instrucciones en If si es verdadera. En caso contrario y si existe un bloque Else se ejecuta este bloque de instrucciones. Estas instrucciones también soportan anidamiento. Expresiones aritméticas: Se soportan las expresiones aritméticas binarias: suma, resta, multiplicación y división. También la expresión unaria: negación. Adicionalmente se soporta expresiones agrupadas en paréntesis. Se maneja la precedencia habitual de las expresiones aritméticas. Expresiones booleanas: Comparan dos expresiones que tengan como resultado un número y soportan unicamente los operados mayor que y menor que (&lt;, &gt;). La gramatica utilizada para este ejemplo puede encontrarse en la carpeta Gramatica, en el archivo Gramatica.grm. Gold Parser permite la definición de expresiones regulares con las que podremos definir algunos tokens del programa, tales como: Entero acepta todos los numero que no poseen punto decimal Decimal acepta todo tipo de números decimales Car Acepta todos los caracteres imprimibles que pueden venir dentro de una cadena con la excepción de las comillas dobles Cadena Acepta un conjunto de caracteres delimitados por comillas dobles ID Head Acepta todas las letras del alfabeto además del guien bajo, se utiliza para la primera letra de los identificadores. ID Tail Acepta Todos los caracteres alfanuméricos además del guion bajo, se utiliza para todos los caracteres del identificador con la excepción de la primera letra ID Agrupa ID Head e ID Tail para poder conformar un identificador valido para nuestro lenguaje De igual manera, Gold Parser posee palabras reservadas para definir los comentarios, por lo que no tendremos que escribir una expresión regular personalizada. El resultado de la ejecuciónAl ejecutar la entrada mostrada en nuestro ejemplo, esta fue la salida obtenida: Sobre la tabla de símbolosLa tabla de símbolos es una parte importante en el proceso de ejecución del código, es en esta estructura de datos en donde guardamos información de las variables como su tipo, identificador y valor. En esta estructura podemos agregar variables, modificar los valores de las variables existentes, así como obtener sus valores. Otra alternativa más detallada es utilizar entornos, un ejemplo de esto se puede encontrar en el libro del curso (Ver Referencias) en la página 87, en donde se habla sobre tablas de símbolos por alcance, a través de entornos anidados.El manejo de entornos es sumamente importante ya que deberíamos de crear un nuevo entorno por cada alcance, de manera que los entornos superiores no tengan acceso a las variables declaradas en entornos inferiores pero los entornos inferiores puedan acceder tanto a sus variables como a las de los entornos superiores, esto funciona de manera muy similar a una pila, ya que el ultimo entorno creado debería ser el primero en ser eliminado.En este ejemplo, esto se logra mediante el método AddAll de la clase TablaSimbolos.vb, que agrega todos los símbolos del entorno anterior al final del nuevo entorno. La magia detrás de todo esto: Árbol de sintaxis abstracta (AST)Un árbol de sintaxis abstracta (AST) es una representación simplificada de la estructura sintáctica del código fuente. A nivel de programación un AST es una estructura de datos que se genera durante el proceso de análisis sintáctico.Gold Parser nos genera un árbol de análisis sintáctico, sin embargo, es mucho más práctico generar el nuestro que nos permita poder ejecutar las acciones al mismo tiempo que visitamos los nodos. Si creamos nuestro propio árbol tendremos completo control sobre nuestra gramática, tendremos código más entendible, reportes de errores más detallados y menos dolores de cabeza al tratar de encontrar un error.Como se observa en el código fuente, las únicas acciones que realizamos en el árbol de Gold Parser es retornar nodos que nos permitan generar nuestro árbol. En la producción inicial debemos crear nuestro AST, que funcionara como raíz desde la cual debemos comenzar la ejecución de nuestro programa. En este ejemplo el AST es la pieza más importante, porque al recorrerlo pueden ejecutarse las acciones del código de entrada y ese es el principal objetivo de la aplicación. Esta se conforma únicamente de dos paquetes: Análisis: Este paquete únicamente contiene la clase SkeletonProgram, que es el que nos genera Gold Parser por defecto y sobre el archivo que crearemos nuestro AST. Árbol: Posee todas las clases necesarias que nos permiten crear nuestro AST, así como la interfaz operación que es la que permite tratar a todos los nodos del árbol como uno mismo. Además, es importante destacar que existe un archivo más que se encuentra en la carpeta raíz de nuestro programa, es la clase principal que visual nos crea por defecto y en este caso se denomina Module1.Vb. Desde este archivo comienza toda la ejecución del programa y es desde donde debemos de configurar nuestro parser con el método setup (método por defecto de Gold Parser) y también donde deberemos de mandar a ejecutar las acciones de nuestro árbol con el método ejecutar una vez que estemos seguros que la entrada fue aceptada. Acerca del autor:Este tutorial fue elaborado por el Auxiliar de Cátedra Luis Lizama, como contribución al curso de Organización de Lenguajes y Compiladores 2 de la Universidad de San Carlos de Guatemala. Fuentes consultadas: Compiladores, principios, técnicas y herramientas. Aho, Lam, Sethi y Ullman. Segunda Edición. Documentación de Gold Parser","link":"/2019/08/07/21-Interprete-sencillo-utilizando-GOLD-Parser-y-Visual-Basic/"},{"title":"Intérprete sencillo utilizando Irony y C#","text":"En este tutorial se desarrolla un intérprete sencillo que permite ejecutar un archivo de entrada que contiene sentencias tales como declaración de variables, sentencias de control, impresiones en consola, etc. El lenguaje de programación fue diseñado especialmente para este ejemplo. El proyecto cuenta con comentarios que explican su funcionamiento. Las tecnologías a utilizar son: Irony: Generador de analizadores léxicos y sintácticos que retorna un AST (Abstract Syntax Tree). Visual Studio 2017: Entorno de desarrollo integrado utilizado para programar en C#. Windows 10: Sistema Operativo. Irony.dll: DLL que permite la integración de Irony con C#. El proyecto completo de este ejemplo puede descargarse del siguiente enlace: Intérprete Sencillo Utilizando Irony Si desean una pequeña introducción a Irony pueden revisar el post: Mi primer proyecto utilizando Irony En el que se explica paso a paso como utilizar esta herramienta. El lenguaje de entradaDentro de la carpeta del proyecto podremos acceder a /input y allí encontraremos un archivo de entrada llamado “entrada.txt”, en él se muestran ejemplos de todas las funciones del lenguaje diseñado para esta aplicación, al leerlo se puede tener una idea clara de las funciones con las que el lenguaje cuenta, este archivo contiene lo siguiente: Comentarios simples, es decir de una sola línea (//) Comentarios múltiples, es decir de más de una línea (/* */) Concatenación de cadenas, mediante el operador &amp; Función Imprimir: Recibe como parámetro una cadena e imprime su valor en consola. Declaración de variables: Únicamente se acepta definición de variables de tipo numero incluyendo enteros y decimales. Asignación de variables: A cualquier variable se le puede asignar cualquier expresión que tenga como resultado un número. Instrucción Mientras: Tiene el comportamiento clásico del ciclo while, ejecuta el ciclo mientras la expresión booleana que recibe sea verdadera. Esta instrucción soporta anidamiento. Instrucción If e If-Else: Tiene el comportamiento clásico de las sentencias de selección If e If-Else, evalúa la expresión booleana y ejecuta el bloque de instrucciones en If si es verdadera. En caso contrario y si existe un bloque Else se ejecuta este bloque de instrucciones. Estas instrucciones también soportan anidamiento. Expresiones aritméticas: Se soportan las expresiones aritméticas binarias: suma, resta, multiplicación y división. También la expresión unaria: negación. Adicionalmente se soporta expresiones agrupadas en paréntesis. Se maneja la precedencia habitual de las expresiones aritméticas. Expresiones booleanas: Comparan dos expresiones que tengan como resultado un número y soportan unicamente los operados mayor que y menor que (&lt;, &gt;). El resultado de la ejecuciónAl ejecutar la entrada mostrada en nuestro ejemplo, esta fue la salida obtenida: Tabla de símbolosLa tabla de símbolos es una parte importante en el proceso de ejecución del código, es en esta estructura de datos en donde guardamos información de las variables como su tipo, identificador y valor. En esta estructura podemos agregar variables, modificar los valores de las variables existentes, así como obtener sus valores. EntornosEl manejo de entornos es sumamente importante ya que deberíamos de crear un nuevo entorno por cada alcance, de manera que los entornos superiores no tengan acceso a las variables declaradas en entornos inferiores pero los entornos inferiores puedan acceder tanto a sus variables como a las de los entornos superiores, esto funciona de manera muy similar a una pila, ya que el ultimo entorno creado debería ser el primero en ser eliminado. En este ejemplo, esto se logra mediante el creando una tabla local para cada sentencia ejecutada que posea un ámbito propio, como el If, While, etc. Luego de crear la tabla local se agregan todos los símbolos de la tabla del ámbioto padre y se utiliza esta tabla local como tabla principal, al terminar de ejecutar la sentencia esta tabla local desaparece, pues fue declarada dentro de la sentencia que se ejecuta. Árbol de análisis abstracto ASTUn árbol de sintaxis abstracta (AST) es una representación simplificada de la estructura sintáctica del código fuente. A nivel de programación un AST es una estructura de datos que se genera durante el proceso de análisis sintáctico.En el código de Irony lo vamos armando por medio de listas de instrucciones, donde cada sentencia es una instrucción y en el bloque contenido en esta sentencia tendríamos otra lista de instrucciones, armando así un árbol en donde cada nodo es un objeto que implementa la interfaz instrucción y puede contener múltiples hijos que serían otros objetos que implementan la interfaz instrucción, que serían otras instrucciones. El código de nuestro proyecto está organizado en dos paquetes: analizador: que contiene los archivos de Irony. arbol: que contiene todas las clases que forman parte del AST, que se utiliza como estructura primaria en la aplicación. Teniendo únicamente una clase afuera que seria la clase principal de la aplicación Program.cs. Acerca del autor:Este tutorial fue elaborado por el Auxiliar de Cátedra Julio Arango, como contribución al curso de Organización de Lenguajes y Compiladores 2 de la Universidad de San Carlos de Guatemala. Fuentes consultadas: Compiladores, principios, técnicas y herramientas. Aho, Lam, Sethi y Ullman. Segunda Edición.","link":"/2019/08/07/22-Interprete-sencillo-utilizando-Irony-con-CS/"},{"title":"Mi primer proyecto utilizando PLY con Python 3","text":"Se desarrollará un intérprete que recibe como entrada varias expresiones aritméticas y presentando como salida el resultado de dichas expresiones. Las tecnologías a utilizar son: PLY: Generador de analizadores léxicos y sintácticos. Python 3: Es un lenguaje de programación interpretado de alto nivel. Visual Studio Code: Es un editor de código ligero pero poderoso. Existen complementos para trabajar con este lenguaje. El proyecto completo lo pueden descargar del siguiente enlace Mi primer proyecto utilizando PLY PLYPLY es una implementación en Python de lex y yacc, herramientas populares para la construcción de compiladores. La principal tarea de un analizador léxico es leer los caracteres de entrada del programa fuente, agruparlos en lexemas y producir como salida una secuencia de tokens. Un token es un par que consiste en un nombre de token y un valor de atributo opcional. Un lexema es una secuencia de caracteres en el programa fuente, que coinciden con el patrón para un token y que el analizador léxico identifica como una instancia de este token. Un patrón es una descripción de la forma que pueden tomar los lexemas de un token. El analizador sintáctico obtiene una cadena de tokens del analizador léxico y verifica que dicha cadena pueda generarse con la gramática para el lenguaje fuente. Una gramática proporciona una especificación precisa y fácil de entender de un lenguaje de programación. En PLY se definen los patrones de los diferentes tokens que se desean reconocer, esto se hace a través de expresiones regulares. Mientras que las producciones y acciones para formar la gramática se definen a través de funciones. Pre-requisitos Python 3 PLY Instalamos PLYPara hacer uso de PLY en nuestro proyecto no hacemos instalación como tal, lo que necesitamos es descargar el archivo ply-3.11.tar.gz (versión 3.11 al momento de escribir este tutorial) de la página oficial de PLY y lo que hacemos es copiar el fólder “ply” a nuestro proyecto. Crear nuestro proyectoPrimero crearemos un nuevo fólder, en este caso lo llamaremos PROYECTOPLY. Luego lo abrimos en nuestro editor de texto, en este caso usaremos Visual Studio Code. Finalmente procedemos a crear un nuevo archivo llamado gramatica.py donde escribiremos nuestro compilador. Los directorios “pycache“, al igual que los archivos “parser.out” y “parsetab.py” son generados por Python los cuales pueden ser excluidos en nuestro controlador de versiones. En este caso, los agregamos a nuestro .gitignore. 123parser.outparsetab.py**/__pycache__/** El directorio “ply” es el que descargamos y utilizaremos para construir nuestro compilador. Código Fuente para el analizador léxico y sintácticoEn el archivo gramatica.py tenemos la construcción de nuestro compilador. Explicación del código fuente para el analizador léxicoLo primero que debemos hacer es definir el listado de tokens que vamos a reconocer ya asignarlo a la variable tokens 1234567891011121314tokens = ( 'REVALUAR', 'PARIZQ', 'PARDER', 'CORIZQ', 'CORDER', 'MAS', 'MENOS', 'POR', 'DIVIDIDO', 'DECIMAL', 'ENTERO', 'PTCOMA') Luego escribimos los patrones para los tokens que definimos. Existen dos formas de definir las reglas de nuestros tokens. La primera, es con expresiones regulares, agregamos el prefijo “t_” al token que queremos definir y luego le especificamos la expresión regular, para esto se hace uso del módulo re de Python. 1234567891011# Tokenst_REVALUAR = r'Evaluar't_PARIZQ = r'\\('t_PARDER = r'\\)'t_CORIZQ = r'\\['t_CORDER = r'\\]'t_MAS = r'\\+'t_MENOS = r'-'t_POR = r'\\*'t_DIVIDIDO = r'/'t_PTCOMA = r';' La otra forma es a través de funciones, esto nos sirve para manipular el valor del token que procesamos. Por ejemplo para los valores numéricos los retornamos con el tipo apropiado, hacer validaciones, etc. 1234567891011121314151617def t_DECIMAL(t): r'\\d+\\.\\d+' try: t.value = float(t.value) except ValueError: print(&quot;Floaat value too large %d&quot;, t.value) t.value = 0 return tdef t_ENTERO(t): r'\\d+' try: t.value = int(t.value) except ValueError: print(&quot;Integer value too large %d&quot;, t.value) t.value = 0 return t Es importante definir también los caracteres que se van a ignorar. 12# Caracteres ignoradost_ignore = &quot; \\t&quot; Las funciones también llevan el prefijo “t_” antes del nombre del token que queremos procesar. La función recibe un parámetro, “t” en nuestro ejemplo, este contiene el valor del token. Retornamos el valor ya procesado que deseamos, o no retornar nada si lo que deseamos es ignorar el token (por ejemplo: comentarios, contadores, etc.). 1234567def t_newline(t): r'\\n+' t.lexer.lineno += t.value.count(&quot;\\n&quot;) def t_error(t): print(&quot;Illegal character '%s'&quot; % t.value[0]) t.lexer.skip(1) Finalmente construimos el analizador léxico haciendo uso de las librerías de PLY 123# Construyendo el analizador léxicoimport ply.lex as lexlexer = lex.lex() Explicación del código fuente para el analizador sintácticoOtra de las ventajas de Python es que en el mismo archivo podemos definir nuestro análisis sintáctico haciendo uso de los tokens previamente definidos en la sección del analizador léxico. Primeramente definimos la asociatividad y precedencia de los operadores, ya que la gramática escrita es ambigua, es necesario definir una precedencia para que el analizador no entre en conflicto al analizar, en este caso la precedencia es la misma que la de los operadores aritméticos, la precedencia más baja la tienen la suma y la resta, luego están la multiplicación y la división que tienen una precedencia más alta y por último está el signo menos de las expresiones negativas que tendría la precedencia más alta. 123456# Asociación de operadores y precedenciaprecedence = ( ('left','MAS','MENOS'), ('left','POR','DIVIDIDO'), ('right','UMENOS'), ) Ahora procedemos a escribir nuestras producciones, aquí vemos otra de las ventajas de Python, las acciones semánticas de nuestras producciones se hacen en forma de funciones. Las características de estas funciones son: El nombre inicia con el prefijo “_p”. El complemento del nombre queda a nuestra discreción Tiene un único parámetro “t” el cual es una tupla, en cada posición tiene el valor de los terminales y no terminales de la producción. Haciendo uso del docstring de las funciones de Python especificamos las producciones que serán procesadas por la función. En el cuerpo de la función definimos la funcionalidad que deseamos Por ejemplo: 123456def p_expresion_evaluar(t): 'expresion : expresion MAS expresion' # ^ ^ ^ ^ # t[0] t[1] t[2] t[3] t[0] = t[1] + t[3] Sintetizamos en p[0] (expresion) el valor del resultado de sumar loo valores de p[1] (expresion) y p[3]. A continuación el código completo de nuestras producciones: 12345678910111213141516171819202122232425262728293031323334# Definición de la gramáticadef p_instrucciones_lista(t): '''instrucciones : instruccion instrucciones | instruccion '''def p_instrucciones_evaluar(t): 'instruccion : REVALUAR CORIZQ expresion CORDER PTCOMA' print('El valor de la expresión es: ' + str(t[3]))def p_expresion_binaria(t): '''expresion : expresion MAS expresion | expresion MENOS expresion | expresion POR expresion | expresion DIVIDIDO expresion''' if t[2] == '+' : t[0] = t[1] + t[3] elif t[2] == '-': t[0] = t[1] - t[3] elif t[2] == '*': t[0] = t[1] * t[3] elif t[2] == '/': t[0] = t[1] / t[3]def p_expresion_unaria(t): 'expresion : MENOS expresion %prec UMENOS' t[0] = -t[2]def p_expresion_agrupacion(t): 'expresion : PARIZQ expresion PARDER' t[0] = t[2]def p_expresion_number(t): '''expresion : ENTERO | DECIMAL''' t[0] = t[1]def p_error(t): print(&quot;Error sintáctico en '%s'&quot; % t.value) Por último, podemos manejar también las producciones de error para el manejo de errores sintácticos. Ahora construimos el analizador sintáctico,la funcionalidad para leer el archivo y enviarle su contenido a nuestro compilador. 1234567import ply.yacc as yaccparser = yacc.yacc()f = open(&quot;./entrada.txt&quot;, &quot;r&quot;)input = f.read()print(input)parser.parse(input) Creando un archivo de entrada para nuestro analizadorCreamos un nuevo archivo de texto utilizando nuestro editor llamado entrada.txt. El contenido de este archivo es el siguiente: 12345Evaluar[1+1];Evaluar[1+1*2];Evaluar[-(1+1*6/3-5+7)];Evaluar[-(1+1*6/3-5+1*-2)];Evaluar[-(1.6+1.45)]; Ejecución Para ejecutar este script corremos el siguiente comando: 1$ python3 .\\gramatica.py Como podemos ver, obtenemos la salida esperada. Acerca del autor:Este tutorial fue elaborado por el Auxiliar de Cátedra Rainman Sián, como contribución al curso de Organización de Lenguajes y Compiladores 2 de la Universidad de San Carlos de Guatemala. Fuentes consultadas:Compiladores, principios, técnicas y herramientas. Aho, Lam, Sethi y Ullman. Segunda Edición.","link":"/2020/02/10/24-Mi-primer-proyecto-utilizando-PLY/"},{"title":"Mi primer proyecto utilizando JavaCC","text":"Se desarrollará un intérprete que recibe como entrada varias expresiones aritméticas y presenta como salida el resultado de dichas expresiones. Las tecnologías para utilizar son: JavaCC: Generador de analizadores léxicos y sintácticos. Windows 10: Sistema operativo. Netbeans 8.2: IDE (entorno de desarrollo integrado) Java 8: Lenguaje de programación. El proyecto completo del ejemplo puede descargarse del siguiente enlace: Mi primer proyecto utilizando JavaCC JavaCCJava Compiler Compiler es un generador de analizadores para utilizar en java. Este generador es una herramienta que lee la especificación gramatical y la convierte en un programa de java que puede reconocer coincidencias con la gramática. Además del generador de analizadores en sí, JavaCC proporciona otras capacidades estándar relacionadas con la generación de analizadores, como la construcción de árboles (a través de una herramienta llamada JJTree incluida con JavaCC), acciones y depuración. Todo lo que se necesita para ejecutar un analizador JavaCC, una vez generado, es Java Runtime Environment (JRE). Características JavaCC utiliza un analizador descendente lo que permite el uso de gramáticas más generales. Por defecto JavaCC genera un analizador LL(1), aunque JavaCC ofrece capacidades de anticipación sintáctica para resolver ambigüedades. JavaCC permite la utilización de BNF Extendido, o lo que vendría siendo utilizar expresiones regulares tanto en la parte léxica como gramatical. JavaCC permite la utilización de estados para manejar de mejor forma las expresiones regulares. Para más información visitar la página oficial de JavaCC. PrerrequisitosPara este este ejemplo necesitamos las siguientes herramientas Java Development Kit (JDK) NetBeans (o cualquier IDE de nuestro agrado) JavaCC Agregar jdk a las variables de entornoDebemos asegurarnos de que la carpeta bin del JDK haya sido agregada a nuestra variable de entorno Path, para ello vamos a la configuración de dicha variable de entorno Clic derecho en Este equipo Propiedades Configuración avanzada del sistema Variables de entorno Variable Path Editar y si no existe agregamos la ruta a la carpeta bin del JDK, que en mi caso es: 1C:\\Program Files\\Java\\jdk1.8.0_211\\bin Descarga e instalación de JavaCCNos dirigimos a la página oficial de JavaCC, al ingresar hacemos clic sobre el botón de Download[Version].zip Una vez descargado el archivo, lo extraemos y podremos ver el siguiente contenido: El archivo que nos interesa es javacc.jar que se encuentra en la carpeta bootstrap: Por conveniencia, vamos a trasladar el archivo .jar a la carpeta C:/javacc, sin embargo, podría guardarse en otra ubicación. Más adelante le daremos uso a nuestro archivo javacc.jar. Crear el proyecto utilizando NetBeansComo mencionamos vamos a utilizar NetBeans, sin embargo podría usarse cualquier otro IDE. Vamos a mostrar la creación del proyecto y su estructura. Seleccionamos la opción de nuevo proyecto. Ahora seleccionamos el tipo de proyecto, en este caso Java Application y damos clic en siguiente. Por último, agregamos el nombre del proyecto y finalizamos. Vemos el resultado de la creación del proyecto. A continuación, creamos un nuevo paquete llamado Analizador, produciendo el siguiente resultado. Dentro de este paquete vamos a crear un nuevo archivo llamado Gramatica.jj, este archivo contendrá la gramática para reconocer el lenguaje que vamos a realizar. Para facilitar la compilación de la gramática vamos a crear un archivo compilarGramatica.bat, con el siguiente contenido, siempre en el paquete Analizador. 12java -cp C:\\javacc\\javacc.jar javacc Gramatica.jjpause Lo que indican estas sentencias: Agregar el archivo jar al classpath mediante el argumento -cp (classpath) – -cp C:\\javacc\\javacc.jar (o la ubicación de nuestro archivo javacc.jar) Ejecutar java – java Pasar el main del archivo jar – javacc Pasar la gramática a compilar – Gramatica.jj Evitar que se cierre la ventana de comando para ver el resultado – pause Nota: utilizamos el argumento classpath para indicarle a java donde debe buscar los paquetes y clases a ejecutar, mas información en el siguiente link. Construcción del lenguaje en JavaCCLuego de esta introducción vamos a construir una programa que reconozca un lenguaje compuesto por una lista de instrucciones Evaluar que reciben una expresión aritmética para ser evaluada, por ejemplo: 1Evaluar [3*4-2*9] Explicación de la estructura del archivo Gramatica.jj Sección de opciones: Esta sección es opcional, el área de opciones permite especificar algunas directrices que ayuden a JavaCC a generar analizadores léxico-sintácticos más eficientes y adaptados a las necesidades concretas del desarrollador. Existen muchas, si quieres conocerlas mejor puedes verificar la página 132 del libro Compiladores, de Sergio Gálvez Rojas Y Miguel Ángel Mora Mata. En este caso particular utilizamos solamente dos: Ignore_Case = true, para no hacer distinción entre mayúsculas y minúsculas. Static = false, para que los métodos que genere la compilación no sean estáticos. 1234options {IGNORE_CASE = true;STATIC = false;} Clausulas PARSER_BEGIN – PARSER_END: Sirven para indicarle a JavaCC el nombre de nuestra clase principal, así como para englobar tanto a esta como a cualquier otra que se quiera incluir de apoyo. En este ejemplo no definimos ningun método main, solo una clase llamada gramática para nuestro parser, por supuesto que esta clase gramática es la que debemos utilizar para invocar a nuestro parser, y el main lo incluimos fuera de este para tener un código más claro. 123456PARSER_BEGIN(Gramatica)/** Analizador de expresiones aritmeticas sencillas. */package Analizador; public class Gramatica {}PARSER_END(Gramatica) Sección para definición léxica: Esta sección contendrá los tokens permitidos por nuestro lenguaje, contiene distintas clausulas, pero las que utilizamos son: Token: Constituyen los tokens que nuestro analizador va a reconocer, generalmente aquí se incluyen todos los terminales de nuestro lenguaje, aunque también se pueden utilizar tokens en la definición sintáctica sin haberlos definido en esta sección. Skip: En esta sección se incluyen los tokens que se van a ignorar durante el análisis, por ejemplo, los espacios o saltos de línea. 1234567891011121314151617181920212223/** Lexico */SKIP : { &quot; &quot; | &quot;\\t&quot; | &quot;\\r&quot; | &quot;\\n&quot;}TOKEN : { &lt;NUMERO: ([&quot;0&quot;-&quot;9&quot;])+&gt; | &lt;DECIMAL: ([&quot;0&quot;-&quot;9&quot;])+&quot;.&quot;([&quot;0&quot;-&quot;9&quot;])+&gt; | &lt;EVALUAR: &quot;Evaluar&quot;&gt; | &lt;PCOMA: &quot;;&quot;&gt; | &lt;PARENI: &quot;(&quot;&gt; | &lt;PAREND: &quot;)&quot;&gt; | &lt;CORI: &quot;[&quot;&gt; | &lt;CORD: &quot;]&quot;&gt; | &lt;MAS: &quot;+&quot;&gt; | &lt;MENOS: &quot;-&quot;&gt; | &lt;POR: &quot;*&quot;&gt; | &lt;DIV: &quot;/&quot;&gt;}/** Fin Lexico */ Sección para definición sintáctica: Aquí vamos a definir las producciones para nuestro analizador, estas están definidas como funciones. A continuación explicamos la estructura: Como buena práctica es recomendable agregar en un comentario la producción en formato BNF para que sea más fácil entender la producción actual, ya que las reglas sintácticas en JavaCC pueden ser un poco confusas. La definición de un método incluye: 123&lt;TIPO&gt; &lt;NOMBRE&gt; () : {Sección para código de java, generalmente para declaraciones}{Producciones, estas pueden incluir notación de expresiones regulares} Si quisiéramos invocar a otra producción, agregamos su llamada a método y para obtener su valor lo hacemos de la siguiente manera 123456/** Instruccion -&gt; evaluar [ Expresion ]; */void Instruccion() :{double e;}{&lt;EVALUAR&gt; &lt;CORI&gt; e=Expresion() &lt;CORD&gt; &lt;PCOMA&gt; {System.out.println(&quot;El valor de la expresion es: &quot;+e);}} En tal caso necesitásemos obtener el valor de un terminal, debemos utilizar el atributo image, ya que cada terminal es un objeto de tipo Token, para obtenerlo hacemos lo siguiente 123456789double Primitivo() :{double e;}{ &lt;NUMERO&gt; {return Double.parseDouble(token.image);} | &lt;DECIMAL&gt; {return Double.parseDouble(token.image);} | &lt;PARENI&gt; e=Expresion() &lt;PAREND&gt; {return e;}} Algo a tomar en cuenta es que, podemos declarar variables de tipo Token y asignarlas al terminal, esto es por si tuviéramos varios terminales en una misma producción y así sepamos diferenciar cada uno. Compilación de la gramáticaUna vez finalizado nuestro archivo Gramatica.jj, vamos a compilar este para generar los archivos necesarios para su ejecución, vamos a utilizar el archivo compilarGramatica.bat creado al inicio. Al ejecutar el archivo veremos lo siguiente: Como resultado de esto, en nuestro paquete analizador se crearon los siguientes archivos Gramatica.java: Este archivo contiene las funciones de cada no terminal de la sección sintáctica GramaticaConstanst.java: Esta interfaz contiene las constantes de tipo entero que identifican a cada token de nuestro lenguaje y son asignadas a las variables kind. GramaticaTokenManager.java: Se encarga de reconocer los tokens durante el análisis léxico. ParseException.java: Se utiliza para lanzar los errores durante el análisis sintáctico. TokenMgrError.java: Se encarga de manejar los errores léxicos. Token.java: Representa cada token definido en nuestra sección léxica. Clase PrincipalPor último, vamos a invocar a nuestro parser en el método main, para utilizar nuestro parser basta con crear la clase Gramatica y pasar por parámetro nuestro archivo de entrada, luego de crear la instancia invocamos al método inicial que en nuestro caso sería el método analizar. 123456789101112131415161718192021222324252627282930313233package proyectojavacc;import Analizador.Gramatica;import Analizador.ParseException;import Analizador.TokenMgrError;import java.io.BufferedReader;import java.io.FileNotFoundException;import java.io.FileReader;import java.util.logging.Level;import java.util.logging.Logger;/** * * @author Pavel */public class ProyectoJavaCC { /** * @param args the command line arguments */ public static void main(String[] args) { try { Gramatica parser = new Gramatica(new BufferedReader(new FileReader(&quot;./entrada.txt&quot;))); parser.Analizar(); } catch (ParseException e) { System.err.println(e.getMessage()); } catch (FileNotFoundException e) { Logger.getLogger(ProyectoJavaCC.class.getName()).log(Level.SEVERE, &quot;Error al intentar leer el archivo.&quot;, e); } catch(TokenMgrError e){ System.err.println(e.getMessage()); } } } Ejecución del archivo de entradaEl archivo que vamos a utilizar debe encontrarse dentro de la carpeta de nuestro proyecto. Y su contenido es el siguiente: 12345Evaluar[1+1];Evaluar[1+1*2];Evaluar[-(1+1*6/3-5+7)];Evaluar[-(1+1*6/3-5+1*-2)];Evaluar[-(1+1)]; Ejecutamos nuestro programa y vemos la siguiente salida: Acerca del autor:Este tutorial fue elaborado por el Auxiliar de Cátedra Pavel Vásquez, como contribución al curso de Organización de Lenguajes y Compiladores 2 de la Universidad de San Carlos de Guatemala. Fuentes consultadas Java a tope: Compiladores JavaCC: Repositorio JavaCC: Documentación Java: Classpath","link":"/2020/02/10/23-Mi-primer-proyecto-utilizando-JavaCC/"},{"title":"Intérprete sencillo utilizando JavaCC","text":"De no estar familiarizado con la herramienta JavaCC, se recomienda al lector seguir el siguiente tutorial: Mi primer proyecto utilizando JavaCC El desarrollo con JavaCC resulta sencillo, pero la legibilidad de la gramática puede llegar a ser un inconveniente si no se trata con la atención debida, sin embargo, el resto de las funcionalidades que nos ofrece JavaCC son un buen aliciente para utilizarlo, por lo tanto en esta ocasión vamos a desarrollar un intérprete, este contendrá la ejecución de sentencias básicas, como declaraciones de variables, asignaciones, sentencias de control, funciones y demás. El proyecto completo del ejemplo puede descargarse del siguiente enlace: Intérprete sencillo utilizando JavaCC Conceptos básicos Intérprete: Es un tipo común de procesador de lenguaje. En vez de producir un programa destino como una traducción, el intérprete ejecuta directamente las operaciones especificadas en el programa de origen (fuente) con las entradas proporcionadas por el usuario. Árbol de sintaxis abstracta (AST): es una representación simplificada de la estructura sintáctica del código fuente. A nivel de programación un AST es una estructura de datos que se genera durante el proceso de análisis sintáctico. Lenguaje de entradaEn la raíz del proyecto hay un archivo llamado entrada.txt, este contiene un ejemplo con las instrucciones que el lenguaje soporta. Listado instrucciones soportadas Declaración de variables Asignación de variables Evaluación de expresiones aritméticas, lógicas y relaciones If…elseif…else While Continue Break Return Declaración de funciones Llamadas a funciones Recursividad Funciones nativas: pie, toUpper. Pie genera una gráfica pie, y toUpper convierte a mayúsculas cierta cadena. Comentarios de una línea y multilínea Control de excepciones semánticas Estructura del archivo Gramatica.jj de JavaCCLa extensión para los archivos JavaCC es .jj, a continuación vamos a describir la estructura del archivo de JavaCC utilizado para este ejemplo. Sección de opcionesAquí vamos a indicar que no haga distinción entre mayúsculas y minúsculas, además de indicar que los métodos de nuestro archivo luego de compilados no sean estáticos. Sección de parserBegin y parserEndAquí vamos a definir el nombre de nuestro paquete, adicionalmente y muy importante todos los import de archivos que vayamos a utilizar en las acciones para generar nuestro AST. Por último vamos a crear una clase vacía, esta es la que vamos a utilizar para invocar a nuestra gramática. Sección de análisis léxicoEn este punto vamos a definir todos los tokens que vamos a utilizar en el lenguaje: Sección skipContendrá todos los tokens que javacc va a ignorar cuando los reconozca, por ejemplo los comentarios o saltos de línea, espacios en blanco, etc. 1234567SKIP : { &quot; &quot; | &quot;\\t&quot; | &quot;\\r&quot; | &quot;\\n&quot; | &lt;&quot;//&quot; (~[&quot;\\n&quot;, &quot;\\r&quot;])*&gt;} Sección de tokenEn esta sección cada vez que se reconozca un lexema este generará un nuevo objeto de tipo token. 12345TOKEN : { &lt;NUMERO: ([&quot;0&quot;-&quot;9&quot;])+&gt; | &lt;DECIMAL: ([&quot;0&quot;-&quot;9&quot;])+&quot;.&quot;([&quot;0&quot;-&quot;9&quot;])+&gt; | &lt;ENTERO: &quot;Numero&quot;&gt;} Sección moreSección utilizada para la creación de estados. 123456789MORE :{ &quot;\\&quot;&quot; :STRING_STATE}&lt;STRING_STATE&gt; MORE:{ &lt;~[&quot;\\&quot;&quot;]&gt;} Sección de análisis sintácticoAquí vamos a definir la gramática y agregar las acciones correspondientes para generar nuestro AST. Ciertas producciones van a generar una clase que tiene cierta funcionalidad donde se indica lo que la ejecución deberá hacer. Veamos el caso del while 1234567/** While -&gt; while(condicion) instrucciones */AST Mientras() :{AST e; ArrayList&lt;AST&gt; ins;}{ &lt;MIENTRAS&gt; &lt;PARENI&gt; e=Expresion() &lt;PAREND&gt; ins=Bloque() {return new Mientras(e, ins, token.beginLine, token.beginColumn);}} Con esta gramática observamos lo siguiente, tenemos dos variables: AST e ArrayList ins AST es nuestra clase abstracta asociada con la variable e que contendrá la condición de nuestro while, y el arraylist contendrá una lista de estas clases, esto con el fin de tener una lista de instrucciones.Como sabemos un while necesita de una condición y una lista de instrucciones, lo cual se cumple en el diseño planteado, por lo tanto vamos a retornar una instancia de la clase Mientras. Luego de retornar nuestra clase Mientras, el analizador se encarga de continuar la reducción nuestras producciones, y agregar esta clase a una lista de instrucciones ya que la clase Mientras es una instrucción en sí misma.Al finalizar el análisis de la entrada se debería generar un árbol, que básicamente contiene una lista de instrucciones, y estas instrucciones pueden ser mientras, imprimir, llamadas, etc.Esta es la idea general detrás de las acciones del análisis sintáctico, retornar clases que van a formar un AST, que nos servirá para el análisis semántico y para la ejecución de nuestras instrucciones. Análisis semántico y ejecución de códigoAquí nos vamos a encargar de verificar que lo que ejecutemos tenga sentido, vamos a retomar el ejemplo de la clase Mientras, específicamente la sobre-escritura del método interpretar: 123456789101112131415161718192021222324252627282930313233@Overridepublic Object interpretar(Tabla tabla, Arbol tree) { Object valorCondicion = false; do { Tabla t = new Tabla(tabla); valorCondicion = condicion.interpretar(t, tree); if (valorCondicion instanceof Excepcion) { return valorCondicion; } if (!(valorCondicion instanceof Boolean)) { Excepcion ex = new Excepcion(&quot;Semantico&quot;, &quot;Se esperaba un valor booleano para la condicion&quot;, fila, columna); tree.getExcepciones().add(ex); return ex; } Object result = null; if ((Boolean) valorCondicion) { for (AST m : instrucciones) { result = m.interpretar(t, tree); if (result instanceof Retorno || result instanceof Excepcion) { return result; } if(result instanceof Detener){ return null; } if(result instanceof Continue){ break; } } } } while ((Boolean) valorCondicion); return null;} Se sobre-escribe la función interpretar que viene desde nuestra clase abstracta AST, cada clase que herede de AST le dará un distinto comportamiento a este método en base a lo que se quiere realizar. En este caso necesitamos darle el comportamiento de un while, haciendo lo siguiente: Declaramos una variable que almacenara nuestra condición Iniciamos un ciclo doWhile con la condición establecida en la variable creada anteriormente En las instrucciones del do, crearemos un nuevo ámbito para nuestro mientras Obtenemos el valor de la condición y lo asignamos a la variable creada al inicio Si el valor obtenido es una excepción vamos a retornar este valor para que sea reportado. Si continua la ejecución vamos ahora a verificar que el valor obtenido sea de tipo booleano, sino fuera un booleano vamos a generar una nueva excepción y la vamos a retornar para que sea reportada. Si la condición fuera valida vamos a tener un if con esta condición y si el valor fuera true inicia la ejecución de cada instrucción en nuestra lista Si fuera false, simplemente ignora el if y nuestro doWhile termina Dentro del for para recorrer las instrucciones nos encontramos que en cada iteración debemos verificar que lo que obtenemos de valor no sea una excepción ya que si lo fuera la debemos retornar para que sea reportada. Además verificamos si fuera un break, continue o return para saber que hacer en cada caso. Por ejemplo si fuera retorno vamos a devolver el valor como tal, si fuera un continue únicamente tenemos que ir a la siguiente iteración por lo que cortamos la iteración del ciclo interno donde estamos para que no se sigan ejecutando el resto de las instrucciones y si fuera un break debemos terminar la ejecución del mientras por lo tanto terminamos la ejecución de nuestro doWhile.Esta sería la lógica para un ciclo while, y así lo haremos con todas las instrucciones, cada una tendrá una implementación distinta. **Clases importantes del proyecto **Estas clases son clave para el desarrollo de nuestro intérprete y se explicarán a continuación Clase abstracta ASTContiene los atributos y métodos que tendrán las instrucciones en común, además el método interpretar que será sobre-escrito en cada implementación, la finalidad de esta clase es poder modelar clases de distintos tipos que comparten un comportamiento cómun que en este caso sería que se pueden interpretar. Clase símboloEsta clase nos sirve como nodo para crear nuestras variables, vemos que contiene tipo, identificador y valor, aunque esto puede variar dependiendo del tipo de interprete que estemos construyendo. Clase tablaEsta a tener la función de tabla de símbolos, aquí vamos a almacenar nuestras variables y funciones, nuestras variables las vamos a almacenar en un hashmap y las funciones en un arraylist. Contamos con métodos que nos ayudaran a obtener, guardar variables, obtener y guardar funciones. Clase árbolEs la clase que nos devuelve el análisis sintáctico contiene las instrucciones que deberán ser ejecutadas, la lista de excepción que vamos a reportar y la tabla global para cuando ejecutemos las llamadas a funciones. Clase tipoAquí es donde vamos a definir los tipos que contendrá nuestro interprete. Clase funciónComo cualquier otra instrucción, extiende de la clase AST, y recibe una lista de parámetros y el nombre de la función y una lista de instrucciones.Y para la ejecución únicamente necesitamos recorrer la lista de instrucciones ejecutando el método interpretar asociado a cada una de estas. Creación de funciones nativasPara funciones nativas es muy sencillo, únicamente debemos extender de la clase función y modificar el comportamiento por cualquier otro que deseemos. Tomamos de ejemplo la función nativa aMayuscula, esta recibe en su constructor los mismos datos que la funciones y únicamente se va a diferenciar en el método interpretar donde le daremos una lógica distinta. 123456789101112131415@Overridepublic Object interpretar(Tabla tabla, Arbol tree) { Simbolo simbolo = tabla.getVariable(&quot;toUpper%%parametro1&quot;); if (simbolo == null) { Excepcion ex = new Excepcion(&quot;Semantico&quot;, &quot;No se ha encontrado la variable &quot; + this.nombre + &quot;.&quot;, fila, columna); tree.getExcepciones().add(ex); return ex; } if (!simbolo.getTipo().equals(new Tipo(Tipo.Tipos.CADENA))) { Excepcion ex = new Excepcion(&quot;Semantico&quot;, &quot;El tipo de los parametros no coinciden.&quot;, fila, columna); tree.getExcepciones().add(ex); return ex; } return (simbolo.getValor() + &quot;&quot;).toUpperCase();} Ejecución de la entradaPara ejecutar la entrada debemos instanciar nuestra gramática, esto sucede en la clase UIController, específicamente dentro del método Ejecutar: 123Gramatica parser = new Gramatica(new BufferedReader(new StringReader(entrada.getText())));Arbol arbol = parser.Analizar();EjecutarInstrucciones(arbol); Como mencionamos el resultado de ejecutar nuestra gramática nos devolverá un objeto de tipo Arbol, lo enviamos a un método para tratarlo.En este método pasamos la consola de la interfaz a nuestro árbol para imprimir cosas, crear la tabla global y asignarla a nuestro árbol, crear las funciones nativas.Luego recorremos por primera vez nuestras instrucciones en búsqueda de funciones para declararlas, pero solamente funciones no otra instrucción.Luego recorremos por segunda vez nuestras instrucciones y las ejecutamos utilizando el siempre confiable método interpretar obtenido gracias a nuestra clase abstracta AST. Específicamente con el método EjecutarInstrucciones, de la clase UIController: 1234567891011121314151617181920212223242526272829303132333435private void EjecutarInstrucciones(Arbol tree) { tree.setConsola(consola); tree.setGrupo(groupChart); Tabla tabla = new Tabla(null); tree.setGlobal(tabla); crearNativas(tabla); // Recorrido 1 para insertar funciones tree.getInstrucciones().forEach(m -&gt; { if (m instanceof Funcion) { tabla.setFuncion((Funcion) m); } }); tree.getInstrucciones().forEach(m -&gt; { if (!(m instanceof Funcion)) { Object result = m.interpretar(tabla, tree); if (result instanceof Excepcion) { ((Excepcion) result).imprimir(tree.getConsola()); } if (result instanceof Detener) { Excepcion ex = new Excepcion(&quot;Semantico&quot;, &quot;Sentencia break fuera de ciclo.&quot;, m.fila, m.columna); tree.getExcepciones().add(ex); ex.imprimir(tree.getConsola()); } else if (result instanceof Retorno) { Excepcion ex = new Excepcion(&quot;Semantico&quot;, &quot;Sentencia retorno fuera de funcion.&quot;, m.fila, m.columna); tree.getExcepciones().add(ex); ex.imprimir(tree.getConsola()); } } }); tree.getExcepciones().forEach(m -&gt; { System.out.println(&quot;&quot; + m.toString()); });} Iniciando funciones nativasPara las funciones nativas recordemos deben ser creadas antes de iniciar la ejecución de nuestro interprete. Esta creación de las funciones nativas se encuentra en clase UIController, específicamente en el método crearNativas: 12345678910111213141516171819public void crearNativas(Tabla t){ Tipo tipo = new Tipo(Tipo.Tipos.CADENA); String nombre = &quot;toUpper&quot;; ArrayList&lt;AST&gt; parametros = new ArrayList&lt;&gt;(); parametros.add(new Declaracion(tipo, &quot;toUpper%%parametro1&quot;, null, -1, -1)); ArrayList&lt;AST&gt; instrucciones = new ArrayList&lt;&gt;(); aMayuscula am = new aMayuscula(tipo, nombre, parametros, instrucciones, -1, -1); t.setFuncion(am); tipo = new Tipo(Tipo.Tipos.CADENA); nombre = &quot;pie&quot;; parametros = new ArrayList&lt;&gt;(); parametros.add(new Declaracion(new Tipo(Tipos.LISTA), &quot;pie%%parametro1&quot;, null, -1, -1)); parametros.add(new Declaracion(new Tipo(Tipos.LISTA), &quot;pie%%parametro2&quot;, null, -1, -1)); parametros.add(new Declaracion(new Tipo(Tipos.CADENA), &quot;pie%%parametro3&quot;, null, -1, -1)); instrucciones = new ArrayList&lt;&gt;(); pieChart pc = new pieChart(tipo, nombre, parametros, instrucciones, -1, -1); t.setFuncion(pc);} Como observamos aquí creamos las funciones nativas de toUpper y pie que mencionamos al inicio. Además los parámetros tienen un nombre especial para que no se confundan con otras variables, al terminar de crearlas las agregamos a nuestra lista de funciones. Una vez explicado esto procedemos a ejecutar nuestro programa, vemos que contamos con un boton para ejecutar y 2 pestañas, 1 de consola y la otra donde se muestran nuestras graficas: Agregamos y ejecutamos la entrada proporcionada que produce lo siguiente en la sección de la consola: Y en la sección de grafica: Con esto damos por finalizado la explicación de este pequeño proyecto. Conclusiones Como pudimos observar el desarrollo de un interprete es largo, pero a su vez es ordenado. Las gramáticas en javaCC pueden ser poco legibles pero altamente sencillas de crear. Dry, don’t repeat yourself: si usamos esta filosofía podemos reducir la cantidad de código hecho, por ejemplo en nuestra clase abstracta agregamos código común para todas las clases que la heredan, o con las funciones nativas únicamente heredamos de algo que ya existía, hay que tratar en la manera de lo posible reutilizar el código existente. Algo que no se explico porque no era parte del tutorial, pero que es muy útil fue que la interfaz esta hecha en JavaFX, esta nos proporciona una manera más sencilla de utilizar los componentes de la interfaz con nuestra lógica utilizando el modelo MVC. La utilización de estados en JavaCC nos puede ayudar en casos donde necesitemos crear tokens más complejos. Acerca del autor:Este tutorial fue elaborado por el Auxiliar de Cátedra Pavel Vásquez, como contribución al curso de Organización de Lenguajes y Compiladores 2 de la Universidad de San Carlos de Guatemala. Fuentes consultadas: Compiladores, principios, técnicas y herramientas. Aho, Lam, Sethi y Ullman. Segunda Edición.","link":"/2020/03/07/25-Interprete-sencillo-utilizando-Javacc/"},{"title":"Intérprete sencillo utilizando PLY con Python 3","text":"Funcionamiento de la aplicaciónEn este tutorial se desarrolla un intérprete que recibe como entrada un archivo de texto que contiene varias sentencias de un lenguaje de programación diseñado especialmente para esta aplicación. Primero se hace análisis léxico y sintáctico de dicha entrada, durante el análisis sintáctico se carga en memoria un Árbol de Sintaxis Abstracta (AST) que se utiliza posteriormente para ejecutar las sentencias. El analizador se genera con PLY utilizando Python 3 en Ubuntu 18.04. El proyecto completo puede descargarse del siguiente enlace: Intérpete sencillo utilizando PLY con Python 3 Todo el código del proyecto está documentado con comentarios que contienen los detalles de su funcionamiento. Si se desea una introducción sobre el uso de PLY con Python pueden visitar el post: Mi primer proyecto utilizando PLY con Python 3, en el cual se describen los pre-requisitos y los pasos para la creación del proyecto. El lenguaje de entradaDentro de la carpeta del proyecto, hay un archivo de entrada llamado entrada.txt en el cual se muestran ejemplos de todas las funciones del lenguaje diseñado para esta aplicación, al leerlo se puede tener una idea clara de las funciones con las que el lenguaje cuenta, este archivo contiene lo siguiente: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758//Se imprime el encabezadoimprimir(&quot;Tablas de&quot; &amp; &quot; multiplicar&quot;);//Se declara la variable a, de tipo numeronumero a;//Se asigna a la variable a el valor 0a=0;//Se declara la variable c, de tipo numeronumero c;//Se asigna a la variable c el valor 0c=1;//Se imprime un separadorimprimir(&quot;----------------&quot;);/** * Se imprimen las tablas del 1 al 5 y * para cada tabla, se imprimen los resultados * desde el uno hasta el 5, esto se hace con * dos ciclos while anidados. **/mientras(a&lt;4+c){ a=a+1; numero b; b=0; mientras(b&lt;4+c){ b=b+1; imprimir(a &amp; &quot; * &quot; &amp; b &amp; &quot; = &quot; &amp; a * b); } imprimir(&quot;----------------&quot;);}//Se asigna a la variable a el valor de 11a=11;/** * La variable b ya había sido declarada pero * dentro del ámbito del primer ciclo while, * entonces no existe en este ámbito por lo que * debe declararse. **/numero b;//Se asigna valor de 12 a b y valor de 13 a cb=12;c=13;/** * Se evalua si el valor de la variable a es * mayor que 10, si el b es mayor que 11 y si * el de c es mayor que 12. **/If(a&gt;10){ imprimir(&quot;a es mayor que 10.&quot;); if(b&gt;11){ imprimir(&quot;a es mayor que 10 y b es mayor que 11.&quot;); if(c&gt;12){ imprimir(&quot;a es mayor que 10, b es mayor que 11 y c es mayor que 12.&quot;); } }}else{ imprimir(&quot;a es menor o igual que 10.&quot;);} Como se puede observar, el lenguaje acepta: Comentarios simples, es decir de una sola línea (//) Comentarios múltiples, es decir de más de una línea (/* */) Concatenación de cadenas mediante el operador &amp; Función Imprimir. Recibe como parámetro una cadena e imprime su valor en consola. Declaración de variables. Únicamente se acepta definición de variables de tipo numero incluyendo enteros y decimales. Asignación de variables. A cualquier variable se le puede asignar cualquier expresión que tenga como resultado un número. Instrucción Mientras. Tiene el comportamiento clásico del ciclo while, ejecuta el ciclo mientras la expresión booleana que recibe sea verdadera. Esta instrucción soporta anidamiento. Instrucción If e If-Else. Tiene el comportamiento clásico de las sentencias de selección If e If-Else, evalúa la expresión booleana y ejecuta el bloque de instrucciones en If si es verdadera. En caso contrario y si existe un bloque Else se ejecuta este bloque de instrucciones. Estas instrucciones también soportan anidamiento. Expresiones aritméticas. Se soportan las expresiones aritméticas binarias: suma, resta, multiplicación y división. También la expresión unaria: negación. Adicionalmente se soporta expresiones agrupadas en paréntesis. Se maneja la precedencia habitual de las expresiones aritméticas. Expresiones booleanas. Comparan dos expresiones que tengan como resultado un número y soportan unicamente los operados Mayor Que y Menor que (&lt;, &gt;). El analizador léxico y sintácticoEn el archivo gramatica.py detallamos la estructura del lenguaje utilizando PLY. A continuación detallaremos los aspectos más relevantes. Sobre el analizador léxicoEl analizador léxico define los patrones para los tokens que deseamos reconocer. Hacemos uso de expresiones regulares para identificar números, cadenas y comentarios. Para esto hacemos uso del módulo re de Python 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899reservadas = { 'numero' : 'NUMERO', 'imprimir' : 'IMPRIMIR', 'mientras' : 'MIENTRAS', 'if' : 'IF', 'else' : 'ELSE'}tokens = [ 'PTCOMA', 'LLAVIZQ', 'LLAVDER', 'PARIZQ', 'PARDER', 'IGUAL', 'MAS', 'MENOS', 'POR', 'DIVIDIDO', 'CONCAT', 'MENQUE', 'MAYQUE', 'IGUALQUE', 'NIGUALQUE', 'DECIMAL', 'ENTERO', 'CADENA', 'ID'] + list(reservadas.values())# Tokenst_PTCOMA = r';'t_LLAVIZQ = r'{'t_LLAVDER = r'}'t_PARIZQ = r'\\('t_PARDER = r'\\)'t_IGUAL = r'='t_MAS = r'\\+'t_MENOS = r'-'t_POR = r'\\*'t_DIVIDIDO = r'/'t_CONCAT = r'&amp;'t_MENQUE = r'&lt;'t_MAYQUE = r'&gt;'t_IGUALQUE = r'=='t_NIGUALQUE = r'!='def t_DECIMAL(t): r'\\d+\\.\\d+' try: t.value = float(t.value) except ValueError: print(&quot;Float value too large %d&quot;, t.value) t.value = 0 return tdef t_ENTERO(t): r'\\d+' try: t.value = int(t.value) except ValueError: print(&quot;Integer value too large %d&quot;, t.value) t.value = 0 return tdef t_ID(t): r'[a-zA-Z_][a-zA-Z_0-9]*' t.type = reservadas.get(t.value.lower(),'ID') # Check for reserved words return tdef t_CADENA(t): r'\\&quot;.*?\\&quot;' t.value = t.value[1:-1] # remuevo las comillas return t # Comentario de múltiples líneas /* .. */def t_COMENTARIO_MULTILINEA(t): r'/\\*(.|\\n)*?\\*/' t.lexer.lineno += t.value.count('\\n')# Comentario simple // ...def t_COMENTARIO_SIMPLE(t): r'//.*\\n' t.lexer.lineno += 1# Caracteres ignoradost_ignore = &quot; \\t&quot;def t_newline(t): r'\\n+' t.lexer.lineno += t.value.count(&quot;\\n&quot;) def t_error(t): print(&quot;Illegal character '%s'&quot; % t.value[0]) t.lexer.skip(1)# Construyendo el analizador léxicoimport ply.lex as lexlexer = lex.lex() Nótese que los comentarios, saltos de líneas y espacios en blanco son ignorados (no retornan ningún valor). Otro aspecto importante a destacar es que las palabras reservadas son tratadas como Identificadores, esto se debe a que PLY da precedencia a las expresiones regulares más generales. Por ejemplo, la palabra reservada “Imprimir” siempre hará match con la expresión regular de Identificador, por lo que si se define de la forma t_IMPRIMIR = r'imprimir' nunca será alcanzado. Esto lo hace con la finalidad de hacer el proceso de parsing más eficiente al tener menos expresiones regulares que evaluar. Sobre el analizador sintácticoEl objetivo principal de nuestro analizador sintáctico es validar que la entrada sea válida y, si lo es, construir el AST. Para lograr esto hacemos uso de la programación orientada a objetos. Específicamente haremos uso del polimorfismo para la construcción de nuestro árbol. Las clases utilizadas para construir las diferentes instrucciones que componen nuestro AST, están definidas en el archivo instrucciones.py. Clases para Instrucciones Primero definimos una clase abstracta Instruccion, esto nos permitirá abstraer las Instrucciones que soporta nuestro lenguaje: 12class Instruccion: '''This is an abstract class''' Seguidamente, definimos una clase concreta para cada una de las formas posibles que puede tomar Instruccion: 12345678910111213141516171819class Imprimir(Instruccion) : ''' Esta clase representa la instrucción imprimir. La instrucción imprimir únicamente tiene como parámetro una cadena ''' def __init__(self, cad) : self.cad = cadclass Mientras(Instruccion) : ''' Esta clase representa la instrucción mientras. La instrucción mientras recibe como parámetro una expresión lógica y la lista de instrucciones a ejecutar si la expresión lógica es verdadera. ''' def __init__(self, expLogica, instrucciones = []) : self.expLogica = expLogica self.instrucciones = instrucciones Por ejemplo, para la clase Imprimir vemos que extiende de Instruccion y que su única propiedad es la cadena que se va imprimir. Esta propiedad, cadena, es de tipo ExpresionCadena como veremos más adelante. De la misma forma, la instrucción Mientras extiende de Instruccion y sus propiedades son la expresión lógica a evaluar y el set de instrucciones a ejecutar mientras la condición sea verdadera. expLogica es de tipo ExpresionLogica e instrucciones es una lista, y sus elementos son de tipo Instrucción. El proceso es similar para las instrucciones de Definición y Asignación 123456789101112131415161718class Definicion(Instruccion) : ''' Esta clase representa la instrucción de definición de variables. Recibe como parámetro el nombre del identificador a definir ''' def __init__(self, id) : self.id = idclass Asignacion(Instruccion) : ''' Esta clase representa la instrucción de asignación de variables Recibe como parámetro el identificador a asignar y el valor que será asignado. ''' def __init__(self, id, expNumerica) : self.id = id self.expNumerica = expNumerica Finalmente, completamos nuestras instrucciones con If e If-Else 1234567891011121314151617181920212223class If(Instruccion) : ''' Esta clase representa la instrucción if. La instrucción if recibe como parámetro una expresión lógica y la lista de instrucciones a ejecutar si la expresión lógica es verdadera. ''' def __init__(self, expLogica, instrucciones = []) : self.expLogica = expLogica self.instrucciones = instruccionesclass IfElse(Instruccion) : ''' Esta clase representa la instrucción if-else. La instrucción if-else recibe como parámetro una expresión lógica y la lista de instrucciones a ejecutar si la expresión lógica es verdadera y otro lista de instrucciones a ejecutar si la expresión lógica es falsa. ''' def __init__(self, expLogica, instrIfVerdadero = [], instrIfFalso = []) : self.expLogica = expLogica self.instrIfVerdadero = instrIfVerdadero self.instrIfFalso = instrIfFalso Clases para ExpresionesDe la misma manera que manejamos las instrucciones manejaremos las expresiones. Definimos 3 clases abstractas que representan los 3 tipos de expresiones soportadas por nuestro lenguaje: Expresiones Aritméticas, Expresiones con Cadenas y Expresiones Lógicas, todas ellas definidas dentro del archivo expresiones.py. También haremos uso de enumeraciones para definir constantes de nuestras operaciones, esto es altamente recomendado para evitar bugs durante el desarrollo. 12345678910111213from enum import Enumclass OPERACION_ARITMETICA(Enum) : MAS = 1 MENOS = 2 POR = 3 DIVIDIDO = 4class OPERACION_LOGICA(Enum) : MAYOR_QUE = 1 MENOR_QUE = 2 IGUAL = 3 DIFERENTE = 4 Iniciamos definiendo nuestra clase ExpresionNumerica de tipo abstracta y será nuestra clase base para las expresiones numéricas. 1234class ExpresionNumerica: ''' Esta clase representa una expresión numérica ''' Las formas que puede tomar nuestra clase ExpresionNumerica son las siguientes: ExpresionBinaria. Representa una operación aritmética binaria, la clase recibe los 2 operados: exp1 y exp2, ambos de tipos ExpresionNumérica. Y recibe el operador el cual es un calor de nuestro enum definidos anteriormente. ExpresionNegativo. Representa la operación aritmética unaria de negación. Únicamente recibe como parámetro la expresión que se negara, esta es también de tipo ExpresionNumerica ExpresionNumero. Representa un valor terminal numérico. El parámetro val contiene el valor extraído por el analizador léxico. ExpresionIdentificador. Representa un identificador. El parámetro id representa el nombre de la variable que se desea operar. 1234567891011121314151617181920212223242526272829303132333435class ExpresionBinaria(ExpresionNumerica) : ''' Esta clase representa la Expresión Aritmética Binaria. Esta clase recibe los operandos y el operador ''' def __init__(self, exp1, exp2, operador) : self.exp1 = exp1 self.exp2 = exp2 self.operador = operadorclass ExpresionNegativo(ExpresionNumerica) : ''' Esta clase representa la Expresión Aritmética Negativa. Esta clase recibe la expresion ''' def __init__(self, exp) : self.exp = expclass ExpresionNumero(ExpresionNumerica) : ''' Esta clase representa una expresión numérica entera o decimal. ''' def __init__(self, val = 0) : self.val = valclass ExpresionIdentificador(ExpresionNumerica) : ''' Esta clase representa un identificador. ''' def __init__(self, id = &quot;&quot;) : self.id = id Ahora, siguiendo el proceso anterior, definimos nuestras expresiones con cadenas. 12345678910111213141516171819202122232425262728293031class ExpresionCadena : ''' Esta clase representa una Expresión de tipo cadena. '''class ExpresionConcatenar(ExpresionCadena) : ''' Esta clase representa una Expresión de tipo cadena. Recibe como parámetros las 2 expresiones a concatenar ''' def __init__(self, exp1, exp2) : self.exp1 = exp1 self.exp2 = exp2class ExpresionDobleComilla(ExpresionCadena) : ''' Esta clase representa una cadena entre comillas doble. Recibe como parámetro el valor del token procesado por el analizador léxico ''' def __init__(self, val) : self.val = valclass ExpresionCadenaNumerico(ExpresionCadena) : ''' Esta clase representa una expresión numérica tratada como cadena. Recibe como parámetro la expresión numérica ''' def __init__(self, exp) : self.exp = exp Y finalmente, definimos nuestras expresiones lógicas 12345678910class ExpresionLogica() : ''' Esta clase representa la expresión lógica. Esta clase recibe los operandos y el operador ''' def __init__(self, exp1, exp2, operador) : self.exp1 = exp1 self.exp2 = exp2 self.operador = operador Construcción del ASTPara construir el AST durante nuestro análisis sintáctico importamos nuestras clases de instrucciones y expresiones. Esto también incluye nuestros enum para las constantes, esto se hará en el archivo gramatica.py. 1234# Definición de la gramáticafrom expresiones import *from instrucciones import * Una vez importados podemos hacer uso de ellas en la gramática. Por ejemplo, para la construcción de operaciones aritméticas hacemos uso de nuestras clases de tipo ExpresionNumerica, pasamos como parámetros los operandos y el tipo operación (utilizando nuestras constantes). 1234567891011121314151617181920212223242526def p_expresion_binaria(t): '''expresion_numerica : expresion_numerica MAS expresion_numerica | expresion_numerica MENOS expresion_numerica | expresion_numerica POR expresion_numerica | expresion_numerica DIVIDIDO expresion_numerica''' if t[2] == '+' : t[0] = ExpresionBinaria(t[1], t[3], OPERACION_ARITMETICA.MAS) elif t[2] == '-': t[0] = ExpresionBinaria(t[1], t[3], OPERACION_ARITMETICA.MENOS) elif t[2] == '*': t[0] = ExpresionBinaria(t[1], t[3], OPERACION_ARITMETICA.POR) elif t[2] == '/': t[0] = ExpresionBinaria(t[1], t[3], OPERACION_ARITMETICA.DIVIDIDO)def p_expresion_unaria(t): 'expresion_numerica : MENOS expresion_numerica %prec UMENOS' t[0] = ExpresionNegativo(t[2])def p_expresion_agrupacion(t): 'expresion_numerica : PARIZQ expresion_numerica PARDER' t[0] = t[2]def p_expresion_number(t): '''expresion_numerica : ENTERO | DECIMAL''' t[0] = ExpresionNumero(t[1])def p_expresion_id(t): 'expresion_numerica : ID' t[0] = ExpresionIdentificador(t[1]) El proceso es el mismo para las Instrucciones, cada producción de tipo Instrucción construye una instancia concreta de la instrucción apropiada. 1234567891011121314151617181920212223def p_instruccion_imprimir(t) : 'imprimir_instr : IMPRIMIR PARIZQ expresion_cadena PARDER PTCOMA' t[0] =Imprimir(t[3])def p_instruccion_definicion(t) : 'definicion_instr : NUMERO ID PTCOMA' t[0] =Definicion(t[2])def p_asignacion_instr(t) : 'asignacion_instr : ID IGUAL expresion_numerica PTCOMA' t[0] =Asignacion(t[1], t[3])def p_mientras_instr(t) : 'mientras_instr : MIENTRAS PARIZQ expresion_logica PARDER LLAVIZQ instrucciones LLAVDER' t[0] =Mientras(t[3], t[6])def p_if_instr(t) : 'if_instr : IF PARIZQ expresion_logica PARDER LLAVIZQ instrucciones LLAVDER' t[0] =If(t[3], t[6])def p_if_else_instr(t) : 'if_else_instr : IF PARIZQ expresion_logica PARDER LLAVIZQ instrucciones LLAVDER ELSE LLAVIZQ instrucciones LLAVDER' t[0] =IfElse(t[3], t[6], t[10]) Finalmente, una vez que hayamos reconocido toda la entrada, construimos un arreglo con cada uno de los nodos. Este será nuestro AST. 12345678910111213141516171819202122def p_init(t) : 'init : instrucciones' t[0] = t[1]def p_instrucciones_lista(t) : 'instrucciones : instrucciones instruccion' t[1].append(t[2]) t[0] = t[1]def p_instrucciones_instruccion(t) : 'instrucciones : instruccion ' t[0] = [t[1]]def p_instruccion(t) : '''instruccion : imprimir_instr | definicion_instr | asignacion_instr | mientras_instr | if_instr | if_else_instr''' t[0] = t[1] La tabla de símbolosLa tabla de símbolos es la que permite el almacenamiento y recuperación de los valores de las variables. Para su implementación hacemos uso de una clase, ya que necesitaremos más de una instancia de tabla de símbolos. Cada ámbito tiene acceso únicamente a su propia tabla de símbolos y a la de los niveles superiores, la definición de esta clase puede encontrarse en el archivo ts.py. Definimos las constantes para los tipos de datos, en este tutorial se hace uso únicamente del tipo de dato numérico. 1234from enum import Enumclass TIPO_DATO(Enum) : NUMERO = 1 Definimos una clase para los Símbolos. 1234567class Simbolo() : 'Esta clase representa un simbolo dentro de nuestra tabla de simbolos' def __init__(self, id, tipo, valor) : self.id = id self.tipo = tipo self.valor = valor La clase TablaDeSimbolos define la estructura de una tabla de símbolos y sus funciones para agregar, modificar y obtener símbolos. 1234567891011121314151617181920class TablaDeSimbolos() : 'Esta clase representa la tabla de simbolos' def __init__(self, simbolos = {}) : self.simbolos = simbolos def agregar(self, simbolo) : self.simbolos[simbolo.id] = simbolo def obtener(self, id) : if not id in self.simbolos : print('Error: variable ', id, ' no definida.') return self.simbolos[id] def actualizar(self, simbolo) : if not simbolo.id in self.simbolos : print('Error: variable ', simbolo.id, ' no definida.') else : self.simbolos[simbolo.id] = simbolo Construcción del IntérpreteLa definición del Intérprete se encuentra en el archivo principal.py Para iniciar con la implementación, primero importamos nuestra gramática, las constantes y clases de nuestro AST y la Tabla de Símbolos. 1234import gramatica as gimport ts as TSfrom expresiones import *from instrucciones import * Seguidamente, obtenemos el AST a partir del archivo de entrada. 1234567f = open(&quot;./entrada.txt&quot;, &quot;r&quot;)input = f.read()instrucciones = g.parse(input)ts_global = TS.TablaDeSimbolos()procesar_instrucciones(instrucciones, ts_global) Nótese que el AST está contenido en la variable instrucciones. La función principal del intérprete es de reconocer cada instrucción y ejecutarla, para esto es necesario recorrer el AST; es por ello que se ha definido la función procesar_instrucciones la cual itera las instrucciones en un ámbito y las ejecuta. Para iniciar con la ejecución se crea la tabla de símbolos para el ámbito global y se invoca la función procesar_instrucciones con la raíz del AST y la tabla de símbolos del ámbito global. 12345678910def procesar_instrucciones(instrucciones, ts) : ## lista de instrucciones recolectadas for instr in instrucciones : if isinstance(instr, Imprimir) : procesar_imprimir(instr, ts) elif isinstance(instr, Definicion) : procesar_definicion(instr, ts) elif isinstance(instr, Asignacion) : procesar_asignacion(instr, ts) elif isinstance(instr, Mientras) : procesar_mientras(instr, ts) elif isinstance(instr, If) : procesar_if(instr, ts) elif isinstance(instr, IfElse) : procesar_if_else(instr, ts) else : print('Error: instrucción no válida') Existe una función para procesar cada instrucción. Las sentencias Mientras, If e If-Else crean nuevas tablas de símbolos antes de procesar las instrucciones dentro de sus bloques de instrucciones. Estas nuevas tablas de símbolos se inicializan con los valores de la tabla de símbolo actual y al terminar la ejecución de la sentencia los valores son eliminados ya que la instancia se crea localmente en el cuerpo de la función. 12345678910111213141516171819def procesar_mientras(instr, ts) : while resolver_expreision_logica(instr.expLogica, ts) : ts_local = TS.TablaDeSimbolos(ts.simbolos) procesar_instrucciones(instr.instrucciones, ts_local)def procesar_if(instr, ts) : val = resolver_expreision_logica(instr.expLogica, ts) if val : ts_local = TS.TablaDeSimbolos(ts.simbolos) procesar_instrucciones(instr.instrucciones, ts_local)def procesar_if_else(instr, ts) : val = resolver_expreision_logica(instr.expLogica, ts) if val : ts_local = TS.TablaDeSimbolos(ts.simbolos) procesar_instrucciones(instr.instrIfVerdadero, ts_local) else : ts_local = TS.TablaDeSimbolos(ts.simbolos) procesar_instrucciones(instr.instrIfFalso, ts_local) Las sentencias de Declaración y Asignación agregan y modifican valores de la tabla de símbolos. La sentencia Imprimir muestra el valor de una cadena en la consola. 1234567891011def procesar_imprimir(instr, ts) : print('&gt; ', resolver_cadena(instr.cad, ts))def procesar_definicion(instr, ts) : simbolo = TS.Simbolo(instr.id, TS.TIPO_DATO.NUMERO, 0) # inicializamos con 0 como valor por defecto ts.agregar(simbolo)def procesar_asignacion(instr, ts) : val = resolver_expresion_aritmetica(instr.expNumerica, ts) simbolo = TS.Simbolo(instr.id, TS.TIPO_DATO.NUMERO, val) ts.actualizar(simbolo) Finalmente, todas las sentencias descritas anteriormente hacen uso de las operaciones numéricas, con cadenas y lógicas las cuales hacen uso de la tabla de símbolos para obtener valores de las variables. Para las expresiones numéricas evaluamos el tipo de operación y con base en ellos resolvemos el valor apropiado 123456789101112131415def resolver_expresion_aritmetica(expNum, ts) : if isinstance(expNum, ExpresionBinaria) : exp1 = resolver_expresion_aritmetica(expNum.exp1, ts) exp2 = resolver_expresion_aritmetica(expNum.exp2, ts) if expNum.operador == OPERACION_ARITMETICA.MAS : return exp1 + exp2 if expNum.operador == OPERACION_ARITMETICA.MENOS : return exp1 - exp2 if expNum.operador == OPERACION_ARITMETICA.POR : return exp1 * exp2 if expNum.operador == OPERACION_ARITMETICA.DIVIDIDO : return exp1 / exp2 elif isinstance(expNum, ExpresionNegativo) : exp = resolver_expresion_aritmetica(expNum.exp, ts) return exp * -1 elif isinstance(expNum, ExpresionNumero) : return expNum.val elif isinstance(expNum, ExpresionIdentificador) : return ts.obtener(expNum.id).valor Para las expresiones con cadenas también validamos el tipo de operación para verificar si es necesario una operación de concatenación. En cualquier caso se resuelve la cadena. También es posible concatenar valores numéricos, para esto resolvemos la expresión apoyándonos de la función para procesar expresiones numéricas. 1234567891011def resolver_cadena(expCad, ts) : if isinstance(expCad, ExpresionConcatenar) : exp1 = resolver_cadena(expCad.exp1, ts) exp2 = resolver_cadena(expCad.exp2, ts) return exp1 + exp2 elif isinstance(expCad, ExpresionDobleComilla) : return expCad.val elif isinstance(expCad, ExpresionCadenaNumerico) : return str(resolver_expresion_aritmetica(expCad.exp, ts)) else : print('Error: Expresión cadena no válida') Al igual que las expresiones con cadena, las expresiones lógicas también se apoya en la función que procesa expresiones numéricas para poder evaluar las condiciones booleanas. 1234567def resolver_expreision_logica(expLog, ts) : exp1 = resolver_expresion_aritmetica(expLog.exp1, ts) exp2 = resolver_expresion_aritmetica(expLog.exp2, ts) if expLog.operador == OPERACION_LOGICA.MAYOR_QUE : return exp1 &gt; exp2 if expLog.operador == OPERACION_LOGICA.MENOR_QUE : return exp1 &lt; exp2 if expLog.operador == OPERACION_LOGICA.IGUAL : return exp1 == exp2 if expLog.operador == OPERACION_LOGICA.DIFERENTE : return exp1 != exp2 Para ejecutar nuestro intérprete y procesar el archivo de entrada ejecutamos el siguiente comando: 1$ python3 ./principal.py Y veremos el resultado en consola. Acerca del autor:Este tutorial fue elaborado por el Auxiliar de Cátedra Rainman Sián, como contribución al curso de Organización de Lenguajes y Compiladores 2 de la Universidad de San Carlos de Guatemala. Fuentes consultadas:Compiladores, principios, técnicas y herramientas. Aho, Lam, Sethi y Ullman. Segunda Edición.","link":"/2020/03/15/26-Interprete-sencillo-utilizando-PLY/"},{"title":"Mi primer proyecto utilizando Yacc y Lex","text":"Se desarrollará un intérprete que recibe como entrada varias expresiones aritméticas y presenta como salida el resultado de dichas expresiones. Las tecnologías a utilizar son: Lex: Generador de analizadores léxicos Yacc: Generador de analizadores sintácticos Ubuntu 20.04: Sistema operativo Visual Studio Code: Editor de código fuente C: Lenguaje de programación El proyecto completo del ejemplo puede descargarse en el siguient enlace: Mi primer proyecto utilizando Yacc y Lex LexLex es una herramienta que permite generar analizadore léxicos a partir de un conjunto de reglas y expresiones regulares. Desarrollado por Eric Schmidt y Mike Lesk para los sistemas Unix. Escrito en C para C, su implementación para C++ es posible, aunque no es segura ya que está mas enfocado en el trabajo con C.La principal tarea de un analizador léxico es leer los caracteres de entrada del programa fuente, agruparlos en lexemas y producir como salida una secuencia de tokens. Un token es un par que consiste en un nombre de token y un valor de atributo opcional. Un lexema es una secuencia de caracteres en el programa fuente, que coinciden con el patrón para un token y que el analizador léxico identifica como una instancia de este token. Un patrón es una descripción de la forma que pueden tomar los lexemas de un token. Para obtener más información de Lex, es recomendable visitar su página oficial. YaccYacc es un generador de analizadores sintácticos ascendentes escrito en C para C. Las siglas Yacc significan Yet Another Compiler-Compiler. Desarrollado por Stephen C. Jhonson en AT&amp;T para el sistema operativo Unix. El analizador sintáctico obtiene una cadena de tokens del analizador léxico y verifica que dicha cadena pueda generase con la gramática para el lenguaje fuente. Una gramática proporciona una especificación precisa y fácil de entender de un lenguaje de programación. Para obtener más información de Lex, es recomendable visitar su página oficial. Pre-requisitosPara este ejemplo neceistamos las siguientes herramientas: Compilador GCC Visual Studio Code (o cualquier editor de texto de nuestro agrado) Instalación y configuración de las herramientasLo primero que haremos será instalar Lex, para ello abrimos una terminal, en Ubuntu puede hacerse con la combinación de teclas Ctrl + Alt + t o en Aplicaciones → Accesorios → Terminal, una vez abierta la terminal ingresamos el comando: 1sudo apt-get install flex Autenticamos ingresando nuestra contraseña y aceptamos la descarga e instalación, con esto quedará instalado Lex. Como nos pudimos dar cuenta, la instalación de Lex se hace a través Flex que es otra herramienta de analisis léxico. Luego instalamos Yacc, ejecutando el comando: 1sudo apt-get install bison Autenticamos ingresando nuestra contraseña y aceptamos la descarga e instalación, con esto quedará instalado Yacc. Como nos pudimos dar cuenta, la instalación de Yacc se hace a través de Bison que es otra herramienta de análisis sintáctico. Crear nuestro proyectoCreamos un nuevo folder el cual será nuestro espacio de trabajo, para crearlo abrimos una terminal y ejecutamos el comando: 1mkdir ProyectoLexYacc Luego ingresamos a nuestro folder con el comando: 1cd ProyectoLexYacc Ahora nos pasamos a el editor de código, en este caso usaremos Visual Studio Code. Para abrir nuestro directorio de trabajo en Visual Studio Code ejecutamos desde la terminal el comando: 1code . El punto al final es importante, ya que le indica a Visual Studio Code que abra una nueva ventana en el directorio actual. Esto desplegará una ventana de Visual Studio Code, con nuestro proyecto llamado ProyectoLexYacc. Definimos la estructura de nuestro espacio de trabajo creando un directorio llamado src en donde estará todo nuestro código fuente. Dentro del directorio src creamos un directorio analizador, en este directorio estará todo el código relacionado con Yacc y Lex. Código fuente para el analizador léxicoEn el archivo lexer.l incluiremos todo el código que le indicará a Lex lo que debe de hacer. El código se muestra a continuación: 12345678910111213141516171819%{ #include&lt;stdio.h&gt; #include &quot;y.tab.h&quot; void yyerror(char *);%} %option noyywrap DIGIT [0-9]NUM {DIGIT}+(&quot;.&quot;{DIGIT}+)?/* Rule Section */%% {NUM} { yylval=atoi(yytext); return NUMBER; } [-()+*/;] { return *yytext; }&quot;evaluar&quot; { return EVALUAR; }[[:blank:]] ;. yyerror(&quot;Unknown character&quot;);%% Explicación código fuente para el analizador léxicoEn las primeras lineas incluimos stdio.h para la lectura de archivos, luego incluimos la cabecera y.tab.h que es el archivo que genera Yacc para nuestro analizador sintáctico. Por último declaramos la función yyerror, función propia de Lex y Yacc para el manejo de errores léxicos. 12345%{ #include&lt;stdio.h&gt; #include &quot;y.tab.h&quot; void yyerror(char *);%} Establecemos una lista de directivas propias de Lex: La directiva noyywrap le indica a Lex que unicamente leera un archivo de entrada. 1%option noyywrap Luego se escriben algunas expresiones regulares para identificar enteros y decimales. 12DIGIT [0-9]NUM {DIGIT}+(&quot;.&quot;{DIGIT}+)? Por último definimos todas las reglas léxicas, en las que indicamos los patrones que reconocerá y dentro de llaves lo que debe hacer cuando los reconozca. Para retornar nuestras reglas como tokens y que puedan ser utilizadas en el analizador sintáctico retornamos un id que le asignaremos a cada token, para los tokens de tipo símbolo retornamos la variable yytext para tener una definición más limpia y corta. En el caso de NUM adicional al token debemos regresar el valor numérico reconocido, por lo que es necesario hacer una conversión con la función atoi que convierte una cadena a un número y lo almacenamos en yyval. Para los espacios en blanco, Lex cuenta con una directiva [[:blank]] donde podemos ver que no retornamos ningún simbolo, ya que ignoramos los espacios en blanco. Luego indicamos con un punto que todo lo que no fue reconocido en las reglas anteriores será un error léxico. 12345678/* Rule Section */%% {NUM} { yylval=atoi(yytext); return NUMBER; } [-()+*/;] { return *yytext; }&quot;evaluar&quot; { return EVALUAR; }[[:blank:]] ;. yyerror(&quot;Unknown character&quot;);%% Código fuente para el analizador sintácticoEn el archivo parser.y incluiremos todo el código que le indicará a Yacc lo que debe de hacer. El código se muestra a continuación: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576%{ #include&lt;stdio.h&gt; int yylex(void); void yyerror(char *s); FILE *yyin;%} %token NUMBER EVALUAR %left '+' '-'%left '*' '/'%left NEG /* Rule Section */%% Init : Lista { return 0; };Lista : Lista EVALUAR '(' Expr ')' ';' { printf(&quot;\\nResult=%d\\n&quot;, $4); } | EVALUAR '(' Expr ')' ';' { printf(&quot;\\nResult=%d\\n&quot;, $3); };Expr : Expr '+' Expr { $$ = $1 + $3; } | Expr '-' Expr { $$ = $1 - $3; } | Expr '*' Expr { $$ = $1 * $3; } | Expr '/' Expr { $$ = $1/$3; } | '-' Expr %prec NEG { $$ = -$2; } |'(' Expr ')' { $$ = $2; } | NUMBER { $$ = $1; } ; %% //driver code void parse(FILE *file) { yyin = file; yyparse(); fclose(yyin);} void yyerror(char *s) { printf(&quot;\\n%s\\n&quot;, s); } Explicación código fuente para el analizador sintácticoEn las primeras lineas incluimos el ficherio stdio.h para la lectura de archivos, luego declarramos la función yylex, que es la encargada del analizador léxico, también declaramos la función yyerror, que utiliza Yacc para el manejo de errores sintácticos. Por último declaramos una variable de tipo FILE llamada yyin, en esta indicaremos el archivo de entrada que será analizado. 123456%{ #include&lt;stdio.h&gt; int yylex(void); void yyerror(char *s); FILE *yyin;%} Luego se definen los no terminales, a estos se les puede indicar o no un tipo, por defecto es de tipo int. Los terminales que son símbolos y no retornan ningún identificador asociado al token en el analizador léxico no se agregan en esta sección. 12/******* TERMINALES ********/%token NUMBER EVALUAR Posteriormente podemos indicar la precedencia de operadores, ya que la gramática escrita es ambigua, es necesario definir una precedencia para que el analizador no entre en conflicto. El nivel de precendencia se define del mas bajo al mas alto. La precendencia mas baja la tienen la suma y la resta, seguido por la multiplicación y división y por último tenemos el signo menos de las expresiones negativas. 123%left '+' '-'%left '*' '/'%left NEG A continuación tenemos el conjunto de reglas de escritura de la gramática o producciones. Escribimos nuestras producciones, para asignar reglas de producción lo hacemos mediante llaves “{ }”, en esta sección podemos escribir código de C. Ya que los analizadores que utiliza Yacc son ascenentes, nos permiten sintetizar atributos, para sintentizar un atributo lo hacemos a traves del identificador “$$”. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748%%Init : Lista { return 0; };Lista : Lista EVALUAR '(' Expr ')' ';' { printf(&quot;\\nResult=%d\\n&quot;, $4); } | EVALUAR '(' Expr ')' ';' { printf(&quot;\\nResult=%d\\n&quot;, $3); };Expr : Expr '+' Expr { $$ = $1 + $3; } | Expr '-' Expr { $$ = $1 - $3; } | Expr '*' Expr { $$ = $1 * $3; } | Expr '/' Expr { $$ = $1/$3; } | '-' Expr %prec NEG { $$ = -$2; } |'(' Expr ')' { $$ = $2; } | NUMBER { $$ = $1; } ; %% Como último paso, definimos la función que será llamada para inciar el análisis sintáctico, que en este caso es la función parse, esta recibe como parámetro un FILE, que será nuestro archivo de entrada a ser analizado. Por último definimos la función yyerror, la cúal será llamada si existiera un error sintáctico, esta función es propia de Yacc. 123456789void parse(FILE *file) { yyin = file; yyparse(); fclose(yyin);} void yyerror(char *s) { printf(&quot;\\n%s\\n&quot;, s); } El archivo de compilaciónEn el archivo compilar.sh, ejecutamos dos lineas, la primera indica a Lex que debe generar un analizador léxico en base al código fuente que se encuentra en el archivo Léxico. La segunda linea le indica a Yacc que genere los archivos de compilación para el analizador sintáctico en base al archvio Parser. 12lex lexer.lyacc parser.y -d Para ejecutar abrimos una terminal sobre el directorio analizador y ejecutamos lo siguiente: 1./compilar.sh Nota: Si el comando genera error, asegurese de que el archivo tenga permisos de ejecución. Este comando genera una serie de archivos que se han mencionado ya anteriormente. Los archivos que genera son los siguientes: y.tab.c y.tab.h lex.yy.c Archivo de entradaDentro de la carpeta src del proyecto, creamos un archivo de entrada llamado entrada.txt, que contendrá el archivo de enetrada que reconocerán nuestros analizadores. El archivo contiene lo siguiente: 12345evaluar(1+1);evaluar(1+1*2);evaluar(-(1+1*6/3-5+7));evaluar(-(1+1*6/3-5+1*-2));evaluar(-(1+1)); Archivo PrincipalDentro del archivo main.c, declaramos el método parse, el cúal fue definido en el analizador sintáctico. Definimos nuestro método main, en este creamos abrimos un archivo a través de FILE, indicamos la ruta del archivo de entrada y por último llamamos a nuestro método parse y le pasamos como parámetro el archivo de entrada. 12345678#include &lt;stdio.h&gt; #include &quot;analizador/y.tab.h&quot;void parse(FILE *file);void main(){ FILE *file = fopen(&quot;entrada.txt&quot;, &quot;r&quot;); parse(file); } Ejecutando nuestra aplicaciónPara ejecutar nuestra aplicación necesitamos compilar todos los archivos y generar el ejecutable. Esto lo realizamos con el compilador GCC ejecutando desde consola el siguiente comando: 1gcc main.c ./analizador/*.c Este nos genera un archivo a.out, que es el binario resultante de la compilación, este archivo lo ejecutamos desde consola y obtenemos la salida de nuestro proyecto. 1./a.out Acerca del autor:Este tutorial fue elaborado por el Auxiliar de Cátedra Erik Flores y revisado por el Catedrático Erick Navarro, como contribución al curso de Organización de Lenguajes y Compiladores 2 de la Universidad de San Carlos de Guatemala. Fuentes ConsultadasCompiladores, principios, técnicas y herramientas. Aho, Lam, Sethi y Ullman. Segunda Edición.","link":"/2020/10/01/27-Mi-primer-proyecto-utilizando-Yacc-y-Lex/"}],"tags":[{"name":"Compilers","slug":"Compilers","link":"/tags/Compilers/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"Visual Basic","slug":"Visual-Basic","link":"/tags/Visual-Basic/"},{"name":"Data Structures","slug":"Data-Structures","link":"/tags/Data-Structures/"},{"name":"S3","slug":"S3","link":"/tags/S3/"},{"name":"Route 53","slug":"Route-53","link":"/tags/Route-53/"},{"name":"CloudFront","slug":"CloudFront","link":"/tags/CloudFront/"},{"name":"Lambda","slug":"Lambda","link":"/tags/Lambda/"},{"name":"Alexa Skills","slug":"Alexa-Skills","link":"/tags/Alexa-Skills/"},{"name":"EC2","slug":"EC2","link":"/tags/EC2/"},{"name":"JavaScript","slug":"JavaScript","link":"/tags/JavaScript/"},{"name":"C#","slug":"C","link":"/tags/C/"},{"name":"Python","slug":"Python","link":"/tags/Python/"}],"categories":[{"name":"Computer Science","slug":"Computer-Science","link":"/categories/Computer-Science/"},{"name":"Compilers","slug":"Computer-Science/Compilers","link":"/categories/Computer-Science/Compilers/"},{"name":"Programming","slug":"Programming","link":"/categories/Programming/"},{"name":"Data Structures","slug":"Computer-Science/Data-Structures","link":"/categories/Computer-Science/Data-Structures/"},{"name":"AWS","slug":"AWS","link":"/categories/AWS/"},{"name":"Java","slug":"Programming/Java","link":"/categories/Programming/Java/"},{"name":"S3","slug":"AWS/S3","link":"/categories/AWS/S3/"},{"name":"Route 53","slug":"AWS/Route-53","link":"/categories/AWS/Route-53/"},{"name":"CloudFront","slug":"AWS/CloudFront","link":"/categories/AWS/CloudFront/"},{"name":"Lambda","slug":"AWS/Lambda","link":"/categories/AWS/Lambda/"},{"name":"Alexa Skills","slug":"AWS/Alexa-Skills","link":"/categories/AWS/Alexa-Skills/"},{"name":"EC2","slug":"AWS/EC2","link":"/categories/AWS/EC2/"}],"pages":[{"title":"About","text":"I am a seasoned Data Engineer with cross-industry experience, specializing in Data &amp; Analytics, Cloud Technologies, and Infrastructure as Code. I design and build scalable, cloud-native data systems that deliver timely, reliable, and consistent insights. I have led complex legacy data migration projects to modern cloud platforms, significantly improving data integrity and performance. As a versatile technical leader, I navigate both AWS and Azure ecosystems. In AWS, I work with services such as Redshift, Glue, S3, Bedrock, DynamoDB (including Vector Search), and Databricks. In Azure, I leverage Synapse Analytics, Azure Databricks, Data Lake, and AKS. I bring a strong foundation in Spark, PySpark, Python, and SQL, along with DevOps/MLOps expertise using Terraform, AWS CDK, Helm, and Docker. I ensure quality and reliability with testing frameworks like PyTest and Behave. In the LLM and Generative AI space, I design intelligent, search-enabled solutions using LangChain, LangSmith, Pinecone, and Amazon Bedrock, integrating vector databases and prompt orchestration pipelines to deliver production-ready AI experiences.","link":"/about/index.html"},{"title":"Compiladores 2","text":"Bienvenidos al curso de Organización de Lenguajes y Compiladores 2.Espero que este semestre sea enriquecedor y productivo para todos. A continuación, encontrarán información importante para su participación en este curso: 📚 Programa del curso Programa del curso 📖 Bibliografía Los siguientes archivos bibliográficos tienen configurada la siguiente política de privacidad:Cualquier usuario de Facultad de Ingeniería, USAC (ingenieria.usac.edu.gt) con el enlace puede acceder a los archivos.Esto significa que deben acceder a ellos iniciando sesión con su usuario de la facultad. Si tienen problemas con este tema, pueden avocarse a Centro de Cálculo para solventarlo. Compiladores - Principios, Técnicas y Herramientas. 2da edición. Aho, Sethi, Ullman Engineering a Compiler. 2nd edition. Cooper K., Torczon L. Modern Compiler Implementation in Java, 2nd ed. Andrew Appel Teoría de la computación. Lenguajes formales, autómatas y complejidad. J. Glenn Brookshear 👨‍🏫 Catedráticos Sección A – Ing. Bayron López – blopezw@yahoo.com Sección B+ – Ing. Edgar Sabán – edgarsaban@gmail.com Sección B- – Ing. Erick Navarro – ericknavarrodelgado@gmail.com 🧩 Artículos de interés relacionados al curso Mi primer proyecto utilizando Jlex y Cup (Linux) Mi primer proyecto utilizando Jlex y Cup (Windows) Mi primer proyecto utilizando Jison (Linux) Mi primer proyecto utilizando Gold Parser Mi primer proyecto utilizando Irony Mi primer proyecto utilizando JavaCC Mi primer proyecto utilizando PLY con Python 3 Intérprete sencillo utilizando Java, Jlex y Cup Intérprete sencillo utilizando Jison con Nodejs (Ubuntu) Intérprete sencillo utilizando Gold Parser y Visual Basic Intérprete sencillo utilizando Irony y C# Intérprete sencillo utilizando JavaCC Intérprete sencillo utilizando PLY con Python 3 🙋‍♂️ Más sobre mí GitHub Blog LinkedIn","link":"/olc2/index.html"}]}